import os
import mlflow
import streamlit as st
import openml
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
import matplotlib.pyplot as plt
from mlflow.tracking import MlflowClient
from datetime import datetime
from sklearn.impute import SimpleImputer
import time
import plotly.express as px
import plotly.graph_objects as go
from scipy.spatial import ConvexHull
from sklearn.decomposition import PCA
import streamlit.components.v1 as components

def run_mnist_clustering_app():
    st.title("·ª®ng d·ª•ng Ph√¢n c·ª•m D·ªØ li·ªáu MNIST")

    st.markdown("""
        <style>
            .inline-container {
                display: inline-flex;
                align-items: center;
                gap: 5px;
            }
        </style>
    """, unsafe_allow_html=True)

    tab_info, tab_load, tab_cluster, tab_log_info = st.tabs(["Th√¥ng tin", "T·∫£i d·ªØ li·ªáu", "Ph√¢n c·ª•m", "Theo d√µi k·∫øt qu·∫£"])

    with tab_info:
        st.header("Gi·ªõi thi·ªáu v·ªÅ Ph√¢n c·ª•m D·ªØ li·ªáu MNIST")
        st.markdown("""
        Ch√†o b·∫°n! ƒê√¢y l√† ·ª©ng d·ª•ng gi√∫p b·∫°n hi·ªÉu c√°ch ph√¢n nh√≥m c√°c ch·ªØ s·ªë vi·∫øt tay t·ª´ t·∫≠p d·ªØ li·ªáu **MNIST** ‚Äì m·ªôt t·∫≠p h·ª£p g·ªìm $70,000$ ·∫£nh, m·ªói ·∫£nh l√† m·ªôt ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$. Ch√∫ng ta s·∫Ω d√πng hai ph∆∞∆°ng ph√°p ph√¢n c·ª•m ch√≠nh: **K-means** v√† **DBSCAN**. H√£y c√πng kh√°m ph√° nh√©!
        """, unsafe_allow_html=True)

        st.subheader("1. MNIST l√† g√¨? T·∫°i sao c·∫ßn ph√¢n c·ª•m?")
        st.markdown("""
        - **MNIST**: T·∫≠p d·ªØ li·ªáu g·ªìm $70,000$ ·∫£nh ch·ªØ s·ªë vi·∫øt tay, m·ªói ·∫£nh c√≥ k√≠ch th∆∞·ªõc $28 \\times 28$ pixel (t·ªïng c·ªông $784$ ƒë·∫∑c tr∆∞ng m·ªói ·∫£nh).  
        - **M·ª•c ti√™u ph√¢n c·ª•m**:  
          - Gom c√°c ch·ªØ s·ªë gi·ªëng nhau v√†o c√πng m·ªôt nh√≥m (v√≠ d·ª•: t·∫•t c·∫£ s·ªë $1$ v√†o m·ªôt nh√≥m).  
          - Tr·ª±c quan h√≥a d·ªØ li·ªáu b·∫±ng bi·ªÉu ƒë·ªì $2D$ ho·∫∑c $3D$.  
          - Ti·∫øt ki·ªám th·ªùi gian ph√¢n t√≠ch, h·ªó tr·ª£ c√°c t√°c v·ª• nh∆∞ nh·∫≠n di·ªán ch·ªØ s·ªë sau n√†y.  
        """, unsafe_allow_html=True)

        st.subheader("Minh h·ªça d·ªØ li·ªáu MNIST")
        st.markdown("""
        D∆∞·ªõi ƒë√¢y l√† $10$ ·∫£nh m·∫´u t·ª´ t·∫≠p d·ªØ li·ªáu MNIST (t·ª´ $0$ ƒë·∫øn $9$) ƒë·ªÉ b·∫°n h√¨nh dung. M·ªói ·∫£nh l√† m·ªôt ch·ªØ s·ªë vi·∫øt tay ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n $28 \\times 28$ pixel.
        """, unsafe_allow_html=True)

        with st.spinner("ƒêang t·∫£i ·∫£nh m·∫´u..."):
            mnist = openml.datasets.get_dataset(554)
            X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute)
            
            sample_images = []
            sample_labels = []
            for digit in range(10):
                digit_indices = np.where(y == str(digit))[0]
                if len(digit_indices) > 0:
                    selected_idx = digit_indices[0]
                    sample_images.append(X.iloc[selected_idx].values)
                    sample_labels.append(y.iloc[selected_idx])
            
            fig, axes = plt.subplots(2, 5, figsize=(15, 6))
            for i, (img, label) in enumerate(zip(sample_images, sample_labels)):
                row = i // 5
                col = i % 5
                axes[row, col].imshow(img.reshape(28, 28), cmap='gray')
                axes[row, col].set_title(f'Nh√£n: {label}')
                axes[row, col].axis('off')
            plt.tight_layout()
            st.pyplot(fig)
            
            st.markdown("""
            - **Ghi ch√∫**: M·ªói ·∫£nh l√† m·ªôt ma tr·∫≠n $28 \\times 28$ pixel, v·ªõi gi√° tr·ªã t·ª´ $0$ (tr·∫Øng) ƒë·∫øn $255$ (ƒëen). Nh√£n th·ª±c t·∫ø ($0$-$9$) ch·ªâ ƒë∆∞·ª£c d√πng ƒë·ªÉ minh h·ªça, kh√¥ng s·ª≠ d·ª•ng trong ph√¢n c·ª•m.
            """, unsafe_allow_html=True)

        st.subheader("2. T√¨m hi·ªÉu v·ªÅ K-means v√† DBSCAN")
        st.markdown("Ch·ªçn m·ªôt ph·∫ßn ƒë·ªÉ xem chi ti·∫øt nh√©:")
        info_option = st.selectbox(
            "",
            ["K-means l√† g√¨?", "DBSCAN l√† g√¨?", "So s√°nh K-means v√† DBSCAN"],
            label_visibility="collapsed",
            help="Ch·ªçn ƒë·ªÉ xem th√¥ng tin chi ti·∫øt v·ªÅ t·ª´ng ph∆∞∆°ng ph√°p ho·∫∑c so s√°nh ch√∫ng."
        )
        if info_option == "K-means l√† g√¨?":
            st.subheader("üìä K-means ‚Äì Thu·∫≠t to√°n ph√¢n c·ª•m d·ª±a tr√™n kho·∫£ng c√°ch")
            st.markdown("""
            **K-means** l√† m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m kh√¥ng gi√°m s√°t (unsupervised learning) ph·ªï bi·∫øn, gi√∫p nh√≥m c√°c ƒëi·ªÉm d·ªØ li·ªáu th√†nh $K$ c·ª•m d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng v·ªÅ kho·∫£ng c√°ch. ƒê√¢y l√† m·ªôt trong nh·ªØng thu·∫≠t to√°n ph√¢n c·ª•m ƒë∆°n gi·∫£n v√† hi·ªáu qu·∫£ nh·∫•t trong th·ª±c t·∫ø.
            """, unsafe_allow_html=True)

            st.subheader("üìò 1. Kh√°i ni·ªám c∆° b·∫£n")
            st.markdown("""
            ##### üîπ **T√¢m c·ª•m (Centroid)**  
            L√† ƒëi·ªÉm trung b√¨nh c·ªßa t·∫•t c·∫£ c√°c ƒëi·ªÉm trong c·ª•m. T√¢m c·ª•m kh√¥ng nh·∫•t thi·∫øt ph·∫£i l√† m·ªôt ƒëi·ªÉm d·ªØ li·ªáu th·ª±c t·∫ø m√† ch·ªâ l√† ƒëi·ªÉm ƒë·∫°i di·ªán.

            ##### üîπ **Kho·∫£ng c√°ch Euclidean**  
            Kho·∫£ng c√°ch ph·ªï bi·∫øn ƒë·ªÉ ƒëo ƒë·ªô g·∫ßn gi·ªØa hai ƒëi·ªÉm:  
            $$ \\text{Distance}(p, q) = \\sqrt{(x_q - x_p)^2 + (y_q - y_p)^2} $$  
            - **Gi·∫£i th√≠ch**:  
              - $\\text{Distance}(p, q)$: Kho·∫£ng c√°ch gi·ªØa hai ƒëi·ªÉm $p$ v√† $q$.  
              - $p, q$: Hai ƒëi·ªÉm v·ªõi t·ªça ƒë·ªô l·∫ßn l∆∞·ª£t l√† $(x_p, y_p)$ v√† $(x_q, y_q)$.  
              - $x_p, y_p, x_q, y_q$: T·ªça ƒë·ªô $x$, $y$ c·ªßa c√°c ƒëi·ªÉm $p$ v√† $q$.  
              - $\\sqrt{}$: CƒÉn b·∫≠c hai.  
            """, unsafe_allow_html=True)

            st.subheader("üì∑ 2. Minh h·ªça qu√° tr√¨nh K-means")
            st.markdown("""
            H√¨nh ·∫£nh d∆∞·ªõi ƒë√¢y minh h·ªça c√°ch K-means ho·∫°t ƒë·ªông: D·ªØ li·ªáu ƒë∆∞·ª£c ph√¢n th√†nh c√°c c·ª•m v·ªõi t√¢m c·ª•m ƒë∆∞·ª£c ƒë√°nh d·∫•u b·∫±ng k√Ω hi·ªáu $\\times$.
            """, unsafe_allow_html=True)
            st.image("1k.png", use_container_width=True)
            st.caption("Ngu·ªìn: [https://towardsdatascience.com/K-means-a-complete-introduction-1702af9cd8c](https://towardsdatascience.com/K-means-a-complete-introduction-1702af9cd8c)")

            st.subheader("üõ†Ô∏è 3. Thu·∫≠t to√°n K-means ‚Äì C√°c b∆∞·ªõc th·ª±c hi·ªán")
            st.markdown("""
            Thu·∫≠t to√°n K-means th·ª±c hi·ªán theo c√°c b∆∞·ªõc sau:  
            1. **Kh·ªüi t·∫°o**:  
               - Ch·ªçn s·ªë l∆∞·ª£ng c·ª•m $K$.  
               - Ch·ªçn ng·∫´u nhi√™n $K$ ƒëi·ªÉm l√†m t√¢m c·ª•m ban ƒë·∫ßu (ho·∫∑c d√πng ph∆∞∆°ng ph√°p **K-means++** ƒë·ªÉ t·ªëi ∆∞u).  

            2. **G√°n ƒëi·ªÉm v√†o c·ª•m g·∫ßn nh·∫•t**:  
               - T√≠nh kho·∫£ng c√°ch t·ª´ m·ªói ƒëi·ªÉm ƒë·∫øn t·ª´ng t√¢m c·ª•m.  
               - G√°n ƒëi·ªÉm ƒë√≥ v√†o c·ª•m c√≥ t√¢m g·∫ßn nh·∫•t:  
               $$ C_i = \\{ x_j : \\text{Distance}(x_j, \\mu_i) \\leq \\text{Distance}(x_j, \\mu_k), \\ \\forall k \\} $$  
               - **Gi·∫£i th√≠ch**:  
                 - $C_i$: C·ª•m th·ª© $i$.  
                 - $x_j$: ƒêi·ªÉm d·ªØ li·ªáu.  
                 - $\\mu_i, \\mu_k$: T√¢m c·ª•m c·ªßa c·ª•m $i$ v√† c·ª•m $k$.  
                 - $\\leq$: Nh·ªè h∆°n ho·∫∑c b·∫±ng.  
                 - $\\forall k$: V·ªõi m·ªçi $k$.  

            3. **C·∫≠p nh·∫≠t l·∫°i t√¢m c·ª•m**:  
               - T√≠nh t√¢m c·ª•m m·ªõi b·∫±ng trung b√¨nh t·ªça ƒë·ªô c√°c ƒëi·ªÉm trong c·ª•m:  
               $$ \\mu_i = \\frac{1}{|C_i|} \\sum_{x_j \\in C_i} x_j $$  
               - **Gi·∫£i th√≠ch**:  
                 - $\\mu_i$: T√¢m c·ª•m c·ªßa c·ª•m $i$.  
                 - $|C_i|$: S·ªë ƒëi·ªÉm trong c·ª•m $C_i$.  
                 - $x_j$: ƒêi·ªÉm d·ªØ li·ªáu trong c·ª•m $C_i$.  
                 - $\\sum$: K√Ω hi·ªáu t·ªïng.  
                 - $\\in$: Thu·ªôc v·ªÅ.  
               - D·ªãch chuy·ªÉn t√¢m c·ª•m ƒë·∫øn v·ªã tr√≠ trung b√¨nh m·ªõi.  

            4. **L·∫∑p l·∫°i cho ƒë·∫øn khi h·ªôi t·ª•**:  
               - Ti·∫øp t·ª•c g√°n l·∫°i ƒëi·ªÉm v√†o c·ª•m g·∫ßn nh·∫•t.  
               - C·∫≠p nh·∫≠t t√¢m c·ª•m m·ªõi.  
               - **K·∫øt th√∫c**: Khi t√¢m c·ª•m kh√¥ng thay ƒë·ªïi ho·∫∑c thay ƒë·ªïi r·∫•t nh·ªè sau m·ªói l·∫ßn c·∫≠p nh·∫≠t.  
            """, unsafe_allow_html=True)

            st.subheader("üü© 4. ƒê√°nh gi√° v√† l·ª±a ch·ªçn s·ªë c·ª•m $K$")
            st.markdown("""
            ##### üîπ **Ph∆∞∆°ng ph√°p Elbow**  
            - Ch·∫°y thu·∫≠t to√°n v·ªõi c√°c gi√° tr·ªã $K$ kh√°c nhau.  
            - T√≠nh **Within-Cluster Sum of Squares (WCSS)** ‚Äì t·ªïng b√¨nh ph∆∞∆°ng kho·∫£ng c√°ch t·ª´ c√°c ƒëi·ªÉm ƒë·∫øn t√¢m c·ª•m:  
            $$ \\text{WCSS} = \\sum_{i=1}^{K} \\sum_{x_j \\in C_i} \\| x_j - \\mu_i \\|^2 $$  
            - **Gi·∫£i th√≠ch**:  
              - $\\text{WCSS}$: T·ªïng b√¨nh ph∆∞∆°ng kho·∫£ng c√°ch trong c·ª•m.  
              - $K$: S·ªë c·ª•m.  
              - $x_j$: ƒêi·ªÉm d·ªØ li·ªáu trong c·ª•m $C_i$.  
              - $\\mu_i$: T√¢m c·ª•m c·ªßa c·ª•m $C_i$.  
              - $\\| \\cdot \\|^2$: B√¨nh ph∆∞∆°ng kho·∫£ng c√°ch.  
            - V·∫Ω ƒë·ªì th·ªã $\\text{WCSS}$ theo t·ª´ng gi√° tr·ªã $K$.  
            - Ch·ªçn $K$ t·∫°i ƒëi·ªÉm g·∫•p kh√∫c (elbow point) ‚Äì n∆°i $\\text{WCSS}$ gi·∫£m ch·∫≠m l·∫°i.  
            """, unsafe_allow_html=True)

            # T·∫°o d·ªØ li·ªáu m·∫´u ƒë·ªÉ minh h·ªça ph∆∞∆°ng ph√°p Elbow
            np.random.seed(42)
            data = np.concatenate([
                np.random.normal([2, 2], 0.5, size=(30, 2)),
                np.random.normal([5, 5], 0.5, size=(30, 2)),
                np.random.normal([8, 2], 0.5, size=(30, 2))
            ])
            wcss = []
            for k in range(1, 11):
                kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
                kmeans.fit(data)
                wcss.append(kmeans.inertia_)
            fig5, ax5 = plt.subplots(figsize=(6, 4))
            ax5.plot(range(1, 11), wcss, marker='o')
            ax5.set_title("Ph∆∞∆°ng ph√°p Elbow ƒë·ªÉ ch·ªçn $K$")
            ax5.set_xlabel("S·ªë c·ª•m ($K$)")
            ax5.set_ylabel("$\\text{WCSS}$")
            ax5.grid(True)
            st.pyplot(fig5)

            st.subheader("üü™ 5. ∆Øu ƒëi·ªÉm v√† nh∆∞·ª£c ƒëi·ªÉm")
            st.markdown("""
            ##### ‚úÖ **∆Øu ƒëi·ªÉm**:  
            - D·ªÖ hi·ªÉu v√† d·ªÖ tri·ªÉn khai.  
            - T√≠nh to√°n nhanh, ngay c·∫£ v·ªõi t·∫≠p d·ªØ li·ªáu l·ªõn.  
            - K·∫øt qu·∫£ tr·ª±c quan, d·ªÖ ph√¢n t√≠ch.  

            ##### ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**:  
            - Ph·ª• thu·ªôc v√†o gi√° tr·ªã $K$.  
            - Nh·∫°y c·∫£m v·ªõi t√¢m c·ª•m kh·ªüi t·∫°o (c√≥ th·ªÉ d√πng **K-means++** ƒë·ªÉ c·∫£i thi·ªán).  
            - Kh√¥ng hi·ªáu qu·∫£ v·ªõi c√°c c·ª•m kh√¥ng h√¨nh c·∫ßu ho·∫∑c c√≥ m·∫≠t ƒë·ªô kh√¥ng ƒë·ªìng ƒë·ªÅu.  
            """, unsafe_allow_html=True)

            st.subheader("üìò 6. ·ª®ng d·ª•ng th·ª±c t·∫ø")
            st.markdown("""
            - **Ph√¢n kh√∫c kh√°ch h√†ng**: Trong ti·∫øp th·ªã.  
            - **Ph√¢n lo·∫°i vƒÉn b·∫£n**: V√† t√†i li·ªáu.  
            - **N√©n ·∫£nh**: B·∫±ng c√°ch gi·∫£m s·ªë l∆∞·ª£ng m√†u s·∫Øc.  
            - **X·ª≠ l√Ω ·∫£nh y t·∫ø**: ƒê·ªÉ ph√°t hi·ªán v√πng b·∫•t th∆∞·ªùng.  
            """, unsafe_allow_html=True)

            st.subheader("üìä 7. T·ªïng k·∫øt")
            st.markdown("""
            **K-means** l√† m·ªôt thu·∫≠t to√°n m·∫°nh m·∫Ω v√† linh ho·∫°t trong b√†i to√°n ph√¢n c·ª•m. D√π c√≥ nh∆∞·ª£c ƒëi·ªÉm khi g·∫∑p d·ªØ li·ªáu ph·ª©c t·∫°p ho·∫∑c ch·ª©a nhi·ªÖu, nh∆∞ng nh·ªù s·ª± ƒë∆°n gi·∫£n v√† t·ªëc ƒë·ªô nhanh, n√≥ v·∫´n l√† l·ª±a ch·ªçn h√†ng ƒë·∫ßu trong nhi·ªÅu b√†i to√°n th·ª±c t·∫ø. Khi k·∫øt h·ª£p v·ªõi c√°c k·ªπ thu·∫≠t nh∆∞ **Elbow Method**, **Silhouette Score**, ho·∫∑c d√πng phi√™n b·∫£n c·∫£i ti·∫øn nh∆∞ **K-means++**, ta c√≥ th·ªÉ t·ªëi ∆∞u h√≥a k·∫øt qu·∫£ ph√¢n c·ª•m r·∫•t hi·ªáu qu·∫£.
            """, unsafe_allow_html=True)

        elif info_option == "DBSCAN l√† g√¨?":
            st.subheader("üìà DBSCAN ‚Äì Ph√¢n nh√≥m d·ª±a tr√™n m·∫≠t ƒë·ªô")
            st.markdown("""
            **DBSCAN** (Density-Based Spatial Clustering of Applications with Noise) l√† m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m kh√¥ng gi√°m s√°t, ho·∫°t ƒë·ªông d·ª±a tr√™n m·∫≠t ƒë·ªô c·ªßa c√°c ƒëi·ªÉm d·ªØ li·ªáu. N√≥ n·ªïi b·∫≠t v·ªõi kh·∫£ nƒÉng t√¨m c√°c c·ª•m c√≥ h√¨nh d·∫°ng b·∫•t k·ª≥ v√† lo·∫°i b·ªè nhi·ªÖu hi·ªáu qu·∫£, kh√¥ng c·∫ßn x√°c ƒë·ªãnh tr∆∞·ªõc s·ªë l∆∞·ª£ng c·ª•m nh∆∞ K-means.
            """, unsafe_allow_html=True)

            st.subheader("üìò 1. Kh√°i ni·ªám c∆° b·∫£n")
            st.markdown("""
            DBSCAN d·ª±a tr√™n hai tham s·ªë ch√≠nh: **eps ($\\epsilon$)** v√† **minPts**, c√πng c√°c kh√°i ni·ªám quan tr·ªçng sau:  

            ##### üîπ **V√πng l√¢n c·∫≠n Epsilon ($\\epsilon$-neighborhood)**  
            L√† t·∫≠p h·ª£p c√°c ƒëi·ªÉm n·∫±m trong b√°n k√≠nh $\\epsilon$ quanh m·ªôt ƒëi·ªÉm $p$:  
            $$ N_{\\epsilon}(p) = \\{ q \\in D \\mid \\text{Distance}(p, q) \\leq \\epsilon \\} $$  
            - **Gi·∫£i th√≠ch**:  
              - $N_{\\epsilon}(p)$: V√πng l√¢n c·∫≠n c·ªßa ƒëi·ªÉm $p$.  
              - $p, q$: ƒêi·ªÉm trung t√¢m $p$ v√† ƒëi·ªÉm kh√°c $q$.  
              - $D$: T·∫≠p d·ªØ li·ªáu.  
              - $\\text{Distance}(p, q)$: Kho·∫£ng c√°ch t·ª´ $p$ ƒë·∫øn $q$.  
              - $\\epsilon$: B√°n k√≠nh t·ªëi ƒëa c·ªßa v√πng l√¢n c·∫≠n.  
              - $\\leq$: Nh·ªè h∆°n ho·∫∑c b·∫±ng.  
              - $\\in$: Thu·ªôc v·ªÅ.  

            ##### üîπ **ƒêi·ªÉm l√µi (Core Point)**  
            L√† ƒëi·ªÉm c√≥ √≠t nh·∫•t **minPts** ƒëi·ªÉm (bao g·ªìm ch√≠nh n√≥) trong v√πng $N_{\\epsilon}(p)$.

            ##### üîπ **Kh·∫£ nƒÉng ti·∫øp c·∫≠n tr·ª±c ti·∫øp m·∫≠t ƒë·ªô**  
            M·ªôt ƒëi·ªÉm $q$ ƒë∆∞·ª£c g·ªçi l√† ti·∫øp c·∫≠n tr·ª±c ti·∫øp t·ª´ $p$ n·∫øu:  
            - $q$ n·∫±m trong $N_{\\epsilon}(p)$, v√†  
            - $p$ l√† ƒëi·ªÉm l√µi (c√≥ $|N_{\\epsilon}(p)| \\geq \\text{minPts}$).

            ##### üîπ **Kh·∫£ nƒÉng ti·∫øp c·∫≠n m·∫≠t ƒë·ªô**  
            ƒêi·ªÉm $q$ ti·∫øp c·∫≠n m·∫≠t ƒë·ªô t·ª´ $p$ n·∫øu t·ªìn t·∫°i chu·ªói ƒëi·ªÉm $p_1, p_2, \\ldots, p_n$ sao cho:  
            - $p_1 = p$, $p_n = q$,  
            - M·ªói $p_{i+1}$ ti·∫øp c·∫≠n tr·ª±c ti·∫øp t·ª´ $p_i$.  
            Hai ƒëi·ªÉm c√≥ kh·∫£ nƒÉng ti·∫øp c·∫≠n m·∫≠t ƒë·ªô v·ªõi nhau s·∫Ω thu·ªôc c√πng m·ªôt c·ª•m.
            """, unsafe_allow_html=True)

            st.subheader("üîç 2. Ph√¢n lo·∫°i ƒëi·ªÉm trong DBSCAN")
            st.markdown("""
            DBSCAN chia c√°c ƒëi·ªÉm d·ªØ li·ªáu th√†nh $3$ lo·∫°i:  
            - **ƒêi·ªÉm l√µi (Core Point)**: C√≥ √≠t nh·∫•t **minPts** ƒëi·ªÉm trong v√πng $N_{\\epsilon}$.  
            - **ƒêi·ªÉm bi√™n (Border Point)**: N·∫±m trong $N_{\\epsilon}$ c·ªßa m·ªôt ƒëi·ªÉm l√µi nh∆∞ng kh√¥ng ƒë·ªß **minPts** ƒë·ªÉ t·ª± l√† ƒëi·ªÉm l√µi.  
            - **ƒêi·ªÉm nhi·ªÖu (Noise Point)**: Kh√¥ng thu·ªôc v√πng l√¢n c·∫≠n c·ªßa b·∫•t k·ª≥ ƒëi·ªÉm l√µi n√†o.  
            """, unsafe_allow_html=True)
            st.image("2db.png", caption="Ph√¢n lo·∫°i ƒëi·ªÉm - Vu√¥ng xanh: ƒëi·ªÉm l√µi, Tr√≤n ƒëen: ƒëi·ªÉm bi√™n, Tr√≤n tr·∫Øng: nhi·ªÖu (minPts = 3). Ngu·ªìn: [https://imgur.com/ohzPUif.png](https://imgur.com/ohzPUif.png)", use_container_width=True)

            st.subheader("üõ†Ô∏è 3. C√°ch DBSCAN ho·∫°t ƒë·ªông")
            st.markdown("""
            DBSCAN s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p lan truy·ªÅn ƒë·ªÉ t·∫°o c·ª•m. C√°c b∆∞·ªõc ch√≠nh:  

            1. **Ch·ªçn ƒëi·ªÉm kh·ªüi t·∫°o**: L·∫•y m·ªôt ƒëi·ªÉm b·∫•t k·ª≥ ch∆∞a duy·ªát trong t·∫≠p d·ªØ li·ªáu.  
            2. **X√°c ƒë·ªãnh ƒëi·ªÉm l√µi**:  
               - T√≠nh $N_{\\epsilon}(p)$. N·∫øu $|N_{\\epsilon}(p)| \\geq \\text{minPts}$, $p$ l√† ƒëi·ªÉm l√µi, kh·ªüi t·∫°o c·ª•m m·ªõi.  
               - N·∫øu kh√¥ng, ƒë√°nh d·∫•u $p$ l√† nhi·ªÖu (t·∫°m th·ªùi).  
            3. **Lan truy·ªÅn c·ª•m**:  
               - T·ª´ ƒëi·ªÉm l√µi $p$, ki·ªÉm tra c√°c ƒëi·ªÉm trong $N_{\\epsilon}(p)$.  
               - V·ªõi m·ªói ƒëi·ªÉm $q$ trong $N_{\\epsilon}(p)$:  
                 - N·∫øu $q$ ch∆∞a duy·ªát, t√≠nh $N_{\\epsilon}(q)$. N·∫øu $q$ l√† ƒëi·ªÉm l√µi, th√™m $N_{\\epsilon}(q)$ v√†o c·ª•m.  
               - Ti·∫øp t·ª•c lan truy·ªÅn cho ƒë·∫øn khi kh√¥ng c√≤n ƒëi·ªÉm l√µi n√†o ƒë·ªÉ m·ªü r·ªông.  
            4. **L·∫∑p l·∫°i**: Quay l·∫°i b∆∞·ªõc $1$ v·ªõi ƒëi·ªÉm ch∆∞a duy·ªát ƒë·ªÉ t·∫°o c·ª•m m·ªõi, cho ƒë·∫øn khi duy·ªát h·∫øt d·ªØ li·ªáu.  
            """, unsafe_allow_html=True)
            st.image("3db.gif", caption="Qu√° tr√¨nh lan truy·ªÅn t·∫°o c·ª•m trong DBSCAN. Ngu·ªìn: [https://imgur.com/9D6aAF2.gif](https://imgur.com/9D6aAF2.gif)", use_container_width=True)

            st.subheader("‚öôÔ∏è 4. Ch·ªçn tham s·ªë cho DBSCAN")
            st.markdown("""
            Hai tham s·ªë ch√≠nh c·∫ßn ƒëi·ªÅu ch·ªânh:  

            ##### üîπ **minPts**:  
            - S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu ƒë·ªÉ m·ªôt ƒëi·ªÉm tr·ªü th√†nh ƒëi·ªÉm l√µi.  
            - **G·ª£i √Ω**: $\\text{minPts} \\geq \\text{s·ªë chi·ªÅu d·ªØ li·ªáu} + 1$. V·ªõi d·ªØ li·ªáu l·ªõn/nhi·ªÖu, ch·ªçn gi√° tr·ªã l·ªõn h∆°n (v√≠ d·ª•: $5$-$10$).  

            ##### üîπ **Epsilon ($\\epsilon$)**:  
            - Kho·∫£ng c√°ch t·ªëi ƒëa ƒë·ªÉ c√°c ƒëi·ªÉm ƒë∆∞·ª£c xem l√† "g·∫ßn nhau".  
            - **C√°ch ch·ªçn**:  
              - V·∫Ω ƒë·ªì th·ªã **k-distance** (kho·∫£ng c√°ch ƒë·∫øn ƒëi·ªÉm l√°ng gi·ªÅng th·ª© $k$ g·∫ßn nh·∫•t, v·ªõi $k = \\text{minPts} - 1$).  
              - Ch·ªçn $\\epsilon$ t·∫°i "ƒëi·ªÉm khu·ª∑u tay" (elbow point) ‚Äì n∆°i kho·∫£ng c√°ch tƒÉng ƒë·ªôt ng·ªôt.  
            - **L∆∞u √Ω**:  
              - $\\epsilon$ nh·ªè ‚Üí Nhi·ªÅu c·ª•m nh·ªè, nhi·ªÅu nhi·ªÖu.  
              - $\\epsilon$ l·ªõn ‚Üí G·ªôp c√°c c·ª•m th√†nh m·ªôt.  
            """, unsafe_allow_html=True)

            st.subheader("üü™ 5. ∆Øu ƒëi·ªÉm v√† nh∆∞·ª£c ƒëi·ªÉm")
            st.markdown("""
            ##### ‚úÖ **∆Øu ƒëi·ªÉm**:  
            - Kh√¥ng c·∫ßn ch·ªçn s·ªë c·ª•m tr∆∞·ªõc.  
            - Ph√°t hi·ªán nhi·ªÖu t·ªët (c√°c ƒëi·ªÉm l·∫ª loi).  
            - Ph√π h·ª£p v·ªõi c·ª•m c√≥ h√¨nh d·∫°ng b·∫•t k·ª≥, m·∫≠t ƒë·ªô kh√¥ng ƒë·ªìng ƒë·ªÅu.  

            ##### ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**:  
            - Ch·∫°y ch·∫≠m h∆°n K-means v·ªõi d·ªØ li·ªáu l·ªõn (ƒë·ªô ph·ª©c t·∫°p $O(n^2)$ n·∫øu kh√¥ng t·ªëi ∆∞u).  
            - K·∫øt qu·∫£ ph·ª• thu·ªôc l·ªõn v√†o $\\epsilon$ v√† **minPts**, c·∫ßn th·ª≠ nghi·ªám ƒë·ªÉ ch·ªçn gi√° tr·ªã ph√π h·ª£p.  
            - Kh√¥ng hi·ªáu qu·∫£ n·∫øu m·∫≠t ƒë·ªô c·ª•m qu√° kh√°c bi·ªát.  
            """, unsafe_allow_html=True)

            st.subheader("üìä 6. ·ª®ng d·ª•ng v·ªõi MNIST")
            st.markdown("""
            - **Ph√¢n c·ª•m ch·ªØ s·ªë**: T√¨m c√°c nh√≥m ch·ªØ s·ªë t∆∞∆°ng t·ª± d·ª±a tr√™n ƒë·∫∑c tr∆∞ng h√¨nh ·∫£nh.  
            - **Lo·∫°i b·ªè nhi·ªÖu**: Ph√°t hi·ªán c√°c ·∫£nh b·∫•t th∆∞·ªùng ho·∫∑c kh√¥ng r√µ r√†ng.  
            - **Th·ª≠ nghi·ªám tham s·ªë**: V·ªõi MNIST ($784$ chi·ªÅu), c·∫ßn gi·∫£m chi·ªÅu (d√πng PCA) tr∆∞·ªõc khi √°p d·ª•ng DBSCAN ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ v√† ch·ªçn $\\epsilon$, **minPts** h·ª£p l√Ω.  
            """, unsafe_allow_html=True)

            st.subheader("üìò 7. T·ªïng k·∫øt")
            st.markdown("""
            **DBSCAN** l√† l·ª±a ch·ªçn m·∫°nh m·∫Ω khi b·∫°n mu·ªën ph√¢n c·ª•m d·ªØ li·ªáu c√≥ nhi·ªÖu ho·∫∑c h√¨nh d·∫°ng ph·ª©c t·∫°p m√† kh√¥ng c·∫ßn bi·∫øt tr∆∞·ªõc s·ªë c·ª•m. Tuy nhi√™n, vi·ªác ch·ªçn $\\epsilon$ v√† **minPts** l√† y·∫øu t·ªë then ch·ªët ƒë·ªÉ ƒë·∫°t k·∫øt qu·∫£ t·ªët. V·ªõi d·ªØ li·ªáu l·ªõn nh∆∞ MNIST, k·∫øt h·ª£p DBSCAN v·ªõi gi·∫£m chi·ªÅu d·ªØ li·ªáu l√† c√°ch ti·∫øp c·∫≠n hi·ªáu qu·∫£.
            """, unsafe_allow_html=True)

        elif info_option == "So s√°nh K-means v√† DBSCAN":
            st.subheader("So s√°nh K-means v√† DBSCAN")
            st.markdown("""
            D∆∞·ªõi ƒë√¢y l√† b·∫£ng so s√°nh ƒë·ªÉ b·∫°n d·ªÖ h√¨nh dung s·ª± kh√°c bi·ªát gi·ªØa K-means v√† DBSCAN:  
            | **Ti√™u ch√≠**            | **K-means**                          | **DBSCAN**                          |  
            |--------------------------|--------------------------------------|--------------------------------------|  
            | **C√°ch ho·∫°t ƒë·ªông**      | Chia d·ªØ li·ªáu th√†nh $K$ nh√≥m c·ªë ƒë·ªãnh d·ª±a tr√™n kho·∫£ng c√°ch. | T√¨m c√°c v√πng c√≥ nhi·ªÅu ƒëi·ªÉm g·∫ßn nhau, b·ªè qua ƒëi·ªÉm l·∫ª loi. |  
            | **S·ªë nh√≥m**             | Ph·∫£i ch·ªçn tr∆∞·ªõc (v√≠ d·ª•: $10$ nh√≥m).   | T·ª± ƒë·ªông t√¨m, kh√¥ng c·∫ßn ch·ªçn.        |  
            | **Tham s·ªë ch√≠nh**       | S·ªë nh√≥m ($K$).                      | Kho·∫£ng c√°ch ($\\epsilon$), s·ªë ƒëi·ªÉm t·ªëi thi·ªÉu (**minPts**). |  
            | **T·ªëc ƒë·ªô**             | Nhanh, ph√π h·ª£p d·ªØ li·ªáu l·ªõn.         | Ch·∫≠m h∆°n, ƒë·∫∑c bi·ªát v·ªõi d·ªØ li·ªáu l·ªõn. |  
            | **X·ª≠ l√Ω nhi·ªÖu**         | Kh√¥ng, t·∫•t c·∫£ ƒëi·ªÉm ƒë·ªÅu thu·ªôc nh√≥m.  | C√≥, lo·∫°i b·ªè ƒëi·ªÉm l·∫ª loi (nhi·ªÖu).    |  
            | **·ª®ng d·ª•ng v·ªõi MNIST**  | Chia $10$ ch·ªØ s·ªë th√†nh $10$ nh√≥m c·ªë ƒë·ªãnh. | T√¨m nh√≥m ch·ªØ s·ªë b·∫•t th∆∞·ªùng, lo·∫°i b·ªè nhi·ªÖu. |  
            """, unsafe_allow_html=True)

    with tab_load:
        st.header("T·∫£i D·ªØ li·ªáu MNIST")
        st.markdown("""
        Ph·∫ßn n√†y cho ph√©p t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML v√† ch·ªçn s·ªë l∆∞·ª£ng m·∫´u ƒë·ªÉ ph√¢n c·ª•m. T·ªïng c·ªông c√≥ $70,000$ m·∫´u, ng∆∞·ªùi d√πng c√≥ th·ªÉ ch·ªçn m·ªôt ph·∫ßn nh·ªè h∆°n ƒë·ªÉ gi·∫£m th·ªùi gian x·ª≠ l√Ω.
        """, unsafe_allow_html=True)

        if st.button("T·∫£i d·ªØ li·ªáu"):
            with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
                progress_bar = st.progress(0)
                status_text = st.empty()

                mnist = openml.datasets.get_dataset(554)
                progress_bar.progress(20)
                status_text.text("ƒê√£ t·∫£i 20% - ƒêang truy xu·∫•t d·ªØ li·ªáu...")

                X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute)
                progress_bar.progress(50)
                status_text.text("ƒê√£ t·∫£i 50% - ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")

                if X.isnull().values.any():
                    progress_bar.progress(70)
                    status_text.text("ƒê√£ t·∫£i 70% - ƒêang x·ª≠ l√Ω gi√° tr·ªã NaN...")
                    imputer = SimpleImputer(strategy='mean')
                    X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)

                st.session_state['full_data'] = (X, y)
                progress_bar.progress(90)
                status_text.text(f"ƒê√£ t·∫£i 90% - Ho√†n t·∫•t {X.shape[0]} m·∫´u...")

                with mlflow.start_run(run_name="Data_Load"):
                    mlflow.log_param("total_samples", X.shape[0])
                
                progress_bar.progress(100)
                status_text.text("ƒê√£ t·∫£i 100% - Ho√†n t·∫•t!")
                time.sleep(1)
                status_text.empty()
                progress_bar.empty()
                st.success("T·∫£i d·ªØ li·ªáu th√†nh c√¥ng.")
                st.write("K√≠ch th∆∞·ªõc d·ªØ li·ªáu g·ªëc:", X.shape)

        if 'full_data' in st.session_state:
            X_full, y_full = st.session_state['full_data']
            num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u:", 
                                    min_value=10, max_value=len(X_full), value=min(1000, len(X_full)), step=1)
            if st.button("X√°c nh·∫≠n s·ªë l∆∞·ª£ng m·∫´u"):
                with st.spinner(f"ƒêang x·ª≠ l√Ω {num_samples} m·∫´u..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    df = pd.concat([X_full, y_full.rename("label")], axis=1)
                    progress_bar.progress(30)
                    status_text.text("ƒê√£ x·ª≠ l√Ω 30% - ƒêang k·∫øt h·ª£p d·ªØ li·ªáu...")

                    sampled_df = df.sample(n=num_samples, random_state=42)
                    progress_bar.progress(70)
                    status_text.text("ƒê√£ x·ª≠ l√Ω 70% - ƒêang l·∫•y m·∫´u ng·∫´u nhi√™n...")

                    X_sampled = sampled_df.drop(columns=["label"])
                    y_sampled = sampled_df["label"]
                    st.session_state['data'] = (X_sampled, y_sampled)
                    progress_bar.progress(90)
                    status_text.text("ƒêang x·ª≠ l√Ω 90% - ƒêang l∆∞u tr·ªØ d·ªØ li·ªáu...")

                    with mlflow.start_run(run_name="Data_Sample"):
                        mlflow.log_param("num_samples", num_samples)
                    
                    progress_bar.progress(100)
                    status_text.text("ƒê√£ x·ª≠ l√Ω 100% - Ho√†n t·∫•t!")
                    time.sleep(1)
                    status_text.empty()
                    progress_bar.empty()
                    st.success(f"ƒê√£ ch·ªçn {num_samples} m·∫´u ƒë·ªÉ ph√¢n c·ª•m.")

    with tab_cluster:
        st.header("Ph√¢n c·ª•m D·ªØ li·ªáu")
        st.markdown("""
        Ph·∫ßn n√†y gi√∫p b·∫°n gom nh√≥m d·ªØ li·ªáu MNIST b·∫±ng K-means ho·∫∑c DBSCAN. Sau khi gom nh√≥m, b·∫°n s·∫Ω th·∫•y k·∫øt qu·∫£ tr√™n bi·ªÉu ƒë·ªì $2D$.  
        **L∆∞u √Ω**: ƒê√¢y l√† b√†i to√°n kh√¥ng gi√°m s√°t (unsupervised learning), kh√¥ng s·ª≠ d·ª•ng nh√£n (ch·ªØ s·ªë th·∫≠t) trong qu√° tr√¨nh ph√¢n c·ª•m.
        """, unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui l√≤ng t·∫£i d·ªØ li·ªáu t·ª´ tab 'T·∫£i d·ªØ li·ªáu' tr∆∞·ªõc khi th·ª±c hi·ªán ph√¢n c·ª•m.")
        else:
            X, y = st.session_state['data']
            num_samples = X.shape[0]
            st.write(f"D·ªØ li·ªáu hi·ªán t·∫°i: {num_samples} ·∫£nh, m·ªói ·∫£nh c√≥ {X.shape[1]} ƒë·∫∑c tr∆∞ng.")

            st.subheader("C·∫•u h√¨nh Ph√¢n c·ª•m")
            col1, col2 = st.columns([1, 1])

            with col1:
                cluster_method = st.selectbox(
                    "Ch·ªçn c√°ch ph√¢n c·ª•m:",
                    ["K-means", "DBSCAN"],
                    help="K-means c·∫ßn ch·ªçn s·ªë nh√≥m tr∆∞·ªõc; DBSCAN t·ª± ƒë·ªông t√¨m nh√≥m d·ª±a tr√™n m·∫≠t ƒë·ªô."
                )

            params = {}
            with col2:
                suggestion_data = {
                    "S·ªë l∆∞·ª£ng m·∫´u": ["nh·ªè h∆°n 10,000", "10,000‚Äì30,000", "l·ªõn h∆°n 30,000"],
                    "K-means (n_clusters)": ["5‚Äì10", "10‚Äì20", "20‚Äì50"],
                    "DBSCAN (epsilon)": ["2.0‚Äì4.0", "3.0‚Äì6.0", "5.0‚Äì10.0"],
                    "DBSCAN (minPts)": ["3‚Äì5", "5‚Äì10", "10‚Äì20"]
                }

                if num_samples < 10000:
                    range_idx = 0
                elif num_samples <= 30000:
                    range_idx = 1
                else:
                    range_idx = 2

                suggested_n_clusters = None
                suggested_eps = None
                suggested_min_samples = None

                if cluster_method == "K-means":
                    st.markdown("**S·ªë nh√≥m ($n_{\\text{clusters}}$)**", unsafe_allow_html=True)
                    range_str = suggestion_data["K-means (n_clusters)"][range_idx]
                    start, end = map(int, range_str.split("‚Äì"))
                    suggested_n_clusters = (start + end) // 2
                    n_clusters = st.number_input(
                        "",
                        min_value=2, max_value=50, value=suggested_n_clusters, step=1,
                        label_visibility="collapsed",
                        help=f"G·ª£i √Ω: {range_str}. Gi√° tr·ªã t·ªëi ∆∞u t·ª± ƒë·ªông: {suggested_n_clusters}"
                    )
                    params["n_clusters"] = n_clusters
                else:
                    st.markdown("**Kho·∫£ng c√°ch t·ªëi ƒëa ($\\epsilon$)**", unsafe_allow_html=True)
                    range_str_eps = suggestion_data["DBSCAN (epsilon)"][range_idx]
                    start_eps, end_eps = map(float, range_str_eps.split("‚Äì"))
                    suggested_eps = (start_eps + end_eps) / 2
                    eps = st.number_input(
                        "",
                        min_value=0.1, max_value=10.0, value=suggested_eps, step=0.1,
                        label_visibility="collapsed",
                        help=f"G·ª£i √Ω: {range_str_eps}. Gi√° tr·ªã t·ªëi ∆∞u t·ª± ƒë·ªông: {suggested_eps}"
                    )

                    st.markdown("**S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu ($\\text{minPts}$)**", unsafe_allow_html=True)
                    range_str_minpts = suggestion_data["DBSCAN (minPts)"][range_idx]
                    start_minpts, end_minpts = map(int, range_str_minpts.split("‚Äì"))
                    suggested_min_samples = (start_minpts + end_minpts) // 2
                    min_samples = st.number_input(
                        "",
                        min_value=2, max_value=20, value=suggested_min_samples, step=1,
                        label_visibility="collapsed",
                        help=f"G·ª£i √Ω: {range_str_minpts}. Gi√° tr·ªã t·ªëi ∆∞u t·ª± ƒë·ªông: {suggested_min_samples}"
                    )
                    params["eps"] = eps
                    params["min_samples"] = min_samples

            st.subheader("G·ª£i √Ω tham s·ªë t·ªëi ∆∞u d·ª±a tr√™n s·ªë l∆∞·ª£ng d·ªØ li·ªáu")
            st.markdown(
                f"D·ª±a tr√™n s·ªë l∆∞·ª£ng m·∫´u hi·ªán t·∫°i (**{num_samples} m·∫´u**), d∆∞·ªõi ƒë√¢y l√† g·ª£i √Ω tham s·ªë t·ªëi ∆∞u:",
                unsafe_allow_html=True
            )
            if cluster_method == "K-means":
                st.table({
                    "S·ªë l∆∞·ª£ng m·∫´u": suggestion_data["S·ªë l∆∞·ª£ng m·∫´u"],
                    "K-means ($n_{\\text{clusters}}$)": suggestion_data["K-means (n_clusters)"]
                })
            else:
                st.table({
                    "S·ªë l∆∞·ª£ng m·∫´u": suggestion_data["S·ªë l∆∞·ª£ng m·∫´u"],
                    "DBSCAN ($\\epsilon$)": suggestion_data["DBSCAN (epsilon)"],
                    "DBSCAN ($\\text{minPts}$)": suggestion_data["DBSCAN (minPts)"]
                })

            if st.button("B·∫Øt ƒë·∫ßu ph√¢n c·ª•m", key="run_cluster"):
                progress_bar = st.progress(0)
                status_text = st.empty()
                start_time = time.time()

                X_processed = X / 255.0

                run_name = f"{cluster_method}_Run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                with mlflow.start_run(run_name=run_name) as run:
                    if cluster_method == "K-means":
                        progress_bar.progress(10)
                        status_text.text("ƒêang ch·∫°y K-means (10%)...")
                        model = KMeans(n_clusters=n_clusters, random_state=42)
                        cluster_labels = model.fit_predict(X_processed)
                        progress_bar.progress(100)
                        status_text.text("Ho√†n t·∫•t K-means (100%)!")
                        inertia = model.inertia_
                        centroids = model.cluster_centers_
                        mlflow.log_metric("inertia", inertia)
                        mlflow.sklearn.log_model(model, "kmeans_model")
                    else:
                        progress_bar.progress(10)
                        status_text.text("ƒêang ch·∫°y DBSCAN (10%)...")
                        model = DBSCAN(eps=eps, min_samples=min_samples)
                        cluster_labels = model.fit_predict(X_processed)
                        progress_bar.progress(100)
                        status_text.text("Ho√†n t·∫•t DBSCAN (100%)!")
                        n_clusters_est = len(set(cluster_labels)) - (1 if -1 in cluster_labels else 0)
                        n_noise = list(cluster_labels).count(-1)
                        mlflow.log_metric("n_clusters", n_clusters_est)
                        mlflow.log_metric("n_noise", n_noise)
                        mlflow.sklearn.log_model(model, "dbscan_model")

                    training_time = time.time() - start_time
                    mlflow.log_params(params)
                    mlflow.log_param("cluster_method", cluster_method)
                    mlflow.log_metric("training_time_seconds", training_time)

                    run_id = run.info.run_id
                    st.session_state['latest_run'] = {
                        'run_id': run_id,
                        'run_name': run_name
                    }
                    st.session_state['cluster_labels'] = cluster_labels
                    st.success(f"Ph√¢n c·ª•m xong! Th·ªùi gian: {training_time:.2f} gi√¢y.")

                    st.subheader("K·∫øt qu·∫£ Ph√¢n c·ª•m (Bi·ªÉu ƒë·ªì 2D)")
                    pca = PCA(n_components=2)
                    X_2d = pca.fit_transform(X_processed)
                    df_plot = pd.DataFrame({
                        'PCA1': X_2d[:, 0],
                        'PCA2': X_2d[:, 1],
                        'Cluster': cluster_labels
                    })

                    fig = go.Figure()
                    colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'orange', 'purple', 'brown', 'pink', 'gray']
                    symbols = ['circle'] * len(colors)
                    unique_clusters = np.unique(cluster_labels)

                    for i, cluster in enumerate(unique_clusters):
                        if cluster == -1 and cluster_method == "DBSCAN":
                            cluster_data = df_plot[df_plot['Cluster'] == cluster]
                            fig.add_trace(go.Scatter(
                                x=cluster_data['PCA1'],
                                y=cluster_data['PCA2'],
                                mode='markers',
                                name='Nhi·ªÖu',
                                marker=dict(
                                    symbol='x',
                                    color='grey',
                                    size=8,
                                    opacity=0.5
                                ),
                                hovertemplate="PCA1: %{x:.2f}<br>PCA2: %{y:.2f}<br>C·ª•m: Nhi·ªÖu"
                            ))
                        else:
                            cluster_data = df_plot[df_plot['Cluster'] == cluster]
                            cluster_name = f'Cluster {cluster + 1}' if cluster >= 0 else f'Cluster {cluster}'
                            fig.add_trace(go.Scatter(
                                x=cluster_data['PCA1'],
                                y=cluster_data['PCA2'],
                                mode='markers',
                                name=cluster_name,
                                marker=dict(
                                    symbol=symbols[i % len(symbols)],
                                    color=colors[i % len(colors)],
                                    size=10,
                                    opacity=0.8
                                ),
                                customdata=[cluster_name] * len(cluster_data),
                                hovertemplate="PCA1: %{x:.2f}<br>PCA2: %{y:.2f}<br>C·ª•m: %{customdata}"
                            ))

                    if cluster_method == "K-means":
                        centroids_2d = pca.transform(centroids)
                        fig.add_trace(go.Scatter(
                            x=centroids_2d[:, 0],
                            y=centroids_2d[:, 1],
                            mode='markers',
                            name='Centroids',
                            marker=dict(
                                symbol='star',
                                color='yellow',
                                size=15,
                                opacity=1.0
                            )
                        ))

                    fig.update_layout(
                        title="K·∫øt qu·∫£ Ph√¢n c·ª•m (PCA 2D)",
                        xaxis_title="PCA1",
                        yaxis_title="PCA2",
                        legend_title="C·ª•m",
                        template='plotly_white',
                        width=900,
                        height=600,
                        hovermode='closest',
                        showlegend=True,
                        margin=dict(l=50, r=50, t=50, b=50)
                    )
                    st.plotly_chart(fig, use_container_width=True)

                    st.subheader("Hi·ªÉu bi·ªÉu ƒë·ªì n√†y nh∆∞ th·∫ø n√†o?")
                    if cluster_method == "K-means":
                        st.markdown(f"""
                        - **Bi·ªÉu ƒë·ªì**: M·ªói ƒëi·ªÉm l√† m·ªôt ·∫£nh ch·ªØ s·ªë, ƒë∆∞·ª£c gi·∫£m t·ª´ $784$ chi·ªÅu xu·ªëng $2$ chi·ªÅu (d√πng PCA).  
                        - **M√†u s·∫Øc**: M·ªói c·ª•m c√≥ m·ªôt m√†u ri√™ng (v√≠ d·ª•: Cluster 1 l√† xanh d∆∞∆°ng, Cluster 2 l√† xanh l√°).  
                        - **T√¢m c·ª•m**: ƒêi·ªÉm v√†ng (h√¨nh ng√¥i sao) l√† trung t√¢m c·ªßa m·ªói c·ª•m, ƒë·∫°i di·ªán cho trung b√¨nh c·ªßa c√°c ƒëi·ªÉm trong c·ª•m.  
                        - **R√™ chu·ªôt**: R√™ chu·ªôt v√†o ƒëi·ªÉm ƒë·ªÉ xem gi√° tr·ªã PCA1, PCA2, v√† c·ª•m.  
                        - **√ù nghƒ©a**: K-means chia d·ªØ li·ªáu th√†nh ${n_clusters}$ c·ª•m. L√Ω t∆∞·ªüng l√† m·ªói c·ª•m ch·ª©a c√°c ƒëi·ªÉm d·ªØ li·ªáu t∆∞∆°ng t·ª± nhau d·ª±a tr√™n ƒë·∫∑c tr∆∞ng h√¨nh ·∫£nh.  
                        """, unsafe_allow_html=True)
                    else:
                        noise_percentage = (n_noise / num_samples * 100) if num_samples > 0 else 0
                        st.markdown(f"""
                        - **Bi·ªÉu ƒë·ªì**: M·ªói ƒëi·ªÉm l√† m·ªôt ·∫£nh ch·ªØ s·ªë, ƒë∆∞·ª£c gi·∫£m t·ª´ $784$ chi·ªÅu xu·ªëng $2$ chi·ªÅu (d√πng PCA).  
                        - **M√†u s·∫Øc**: M·ªói c·ª•m c√≥ m·ªôt m√†u ri√™ng. ƒêi·ªÉm nhi·ªÖu (kh√¥ng thu·ªôc c·ª•m n√†o) c√≥ m√†u x√°m, h√¨nh ch·ªØ 'x'.  
                        - **R√™ chu·ªôt**: R√™ chu·ªôt v√†o ƒëi·ªÉm ƒë·ªÉ xem gi√° tr·ªã PCA1, PCA2, v√† c·ª•m.  
                        - **√ù nghƒ©a**: DBSCAN t·ª± t√¨m ${n_clusters_est}$ c·ª•m v√† ${n_noise}$ ƒëi·ªÉm nhi·ªÖu (${noise_percentage:.2f}\\%$ t·ªïng s·ªë). L√Ω t∆∞·ªüng l√† c√°c c·ª•m ch·ª©a c√°c ƒëi·ªÉm d·ªØ li·ªáu t∆∞∆°ng t·ª± nhau, nhi·ªÖu l√† c√°c ƒëi·ªÉm b·∫•t th∆∞·ªùng.  
                        """, unsafe_allow_html=True)

                    st.subheader("Th√¥ng tin chi ti·∫øt")
                    with st.expander("Xem chi ti·∫øt k·∫øt qu·∫£", expanded=True):
                        st.markdown("**Th√¥ng tin l·∫ßn ch·∫°y:**")
                        st.write(f"- T√™n l·∫ßn ch·∫°y: {run_name}")
                        st.write(f"- ID l·∫ßn ch·∫°y: {run_id}")

                        st.markdown("**C√†i ƒë·∫∑t:**")
                        st.write(f"- Ph∆∞∆°ng ph√°p: {cluster_method}")
                        if cluster_method == "K-means":
                            st.write(f"- S·ªë nh√≥m: $ {n_clusters} $", unsafe_allow_html=True)
                        else:
                            st.write(f"- Kho·∫£ng c√°ch t·ªëi ƒëa ($\\epsilon$): $ {eps} $", unsafe_allow_html=True)
                            st.write(f"- S·ªë ƒëi·ªÉm t·ªëi thi·ªÉu ($\\text{{minPts}}$): $ {min_samples} $", unsafe_allow_html=True)
                        st.write(f"- Th·ªùi gian ch·∫°y: $ {training_time:.2f} $ gi√¢y", unsafe_allow_html=True)
                        st.write(f"- S·ªë ·∫£nh ƒë√£ ph√¢n c·ª•m: $ {X.shape[0]} $", unsafe_allow_html=True)

                        st.markdown("**K·∫øt qu·∫£ chi ti·∫øt:**")
                        if cluster_method == "K-means":
                            st.write(f"- ƒê·ªô ch·∫∑t c·ªßa c·ª•m (inertia): $ {inertia:.2f} $ (s·ªë c√†ng nh·ªè, c√°c ƒëi·ªÉm c√†ng g·∫ßn trung t√¢m c·ª•m).", unsafe_allow_html=True)
                        else:
                            noise_percentage = (n_noise / num_samples * 100) if num_samples > 0 else 0
                            st.write(f"- S·ªë c·ª•m t√¨m ƒë∆∞·ª£c: $ {n_clusters_est} $", unsafe_allow_html=True)
                            st.write(f"- S·ªë ƒëi·ªÉm nhi·ªÖu: $ {n_noise} $ ($ {noise_percentage:.2f}\\% $ t·ªïng s·ªë ·∫£nh).", unsafe_allow_html=True)

    with tab_log_info:
        st.header("Theo d√µi k·∫øt qu·∫£")
        st.markdown("""
        Tab n√†y cho ph√©p b·∫°n xem danh s√°ch c√°c l·∫ßn ph√¢n c·ª•m ƒë√£ th·ª±c hi·ªán. Ch·ªçn m·ªôt l·∫ßn ch·∫°y t·ª´ danh s√°ch ƒë·ªÉ xem chi ti·∫øt, ƒë·ªïi t√™n ho·∫∑c x√≥a.
        """, unsafe_allow_html=True)
        
        try:
            client = MlflowClient()
            experiment_id = "4"  # ID c·ªßa experiment MNIST Clustering
            experiment = client.get_experiment(experiment_id)
            if not experiment:
                st.error(f"Kh√¥ng t√¨m th·∫•y experiment v·ªõi ID: {experiment_id}. Vui l√≤ng ki·ªÉm tra l·∫°i MLflow tracking URI.")
            else:
                runs = client.search_runs(experiment_ids=[experiment_id], order_by=["attributes.start_time DESC"])
                
                if not runs:
                    st.info("Ch∆∞a c√≥ l·∫ßn ch·∫°y n√†o ƒë∆∞·ª£c ghi nh·∫≠n.")
                else:
                    run_options = {run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") for run in runs}
                    run_names = list(run_options.values())

                    default_run_name = st.session_state.get('latest_run', {}).get('run_name', run_names[0]) if 'latest_run' in st.session_state else run_names[0]

                    st.subheader("Danh s√°ch run")
                    selected_run_name = st.selectbox(
                        "Ch·ªçn run:",
                        options=run_names,
                        index=run_names.index(default_run_name) if default_run_name in run_names else 0,
                        key="main_select",
                        help="Ch·ªçn m·ªôt l·∫ßn ch·∫°y ƒë·ªÉ xem chi ti·∫øt, ƒë·ªïi t√™n ho·∫∑c x√≥a."
                    )
                    selected_run_id = [k for k, v in run_options.items() if v == selected_run_name][0]
                    selected_run = client.get_run(selected_run_id)

                    st.subheader("ƒê·ªïi t√™n Run")
                    new_run_name = st.text_input(
                        "Nh·∫≠p t√™n m·ªõi:",
                        value=selected_run_name,
                        key="rename_input"
                    )
                    if st.button("C·∫≠p nh·∫≠t t√™n", key="rename_button"):
                        if new_run_name.strip() and new_run_name.strip() != selected_run_name:
                            with st.spinner("ƒêang c·∫≠p nh·∫≠t t√™n..."):
                                client.set_tag(selected_run_id, "mlflow.runName", new_run_name.strip())
                                if 'latest_run' in st.session_state and st.session_state['latest_run']['run_id'] == selected_run_id:
                                    st.session_state['latest_run']['run_name'] = new_run_name.strip()
                                st.success(f"ƒê√£ ƒë·ªïi t√™n th√†nh: {new_run_name.strip()}")
                                time.sleep(0.5)
                                st.rerun()
                        elif not new_run_name.strip():
                            st.warning("Vui l√≤ng nh·∫≠p t√™n h·ª£p l·ªá.")
                        else:
                            st.info("T√™n m·ªõi tr√πng v·ªõi t√™n hi·ªán t·∫°i.")

                    st.subheader("X√≥a Run")
                    if st.button("X√≥a l·∫ßn ch·∫°y", key="delete_button"):
                        with st.spinner("ƒêang x√≥a l·∫ßn ch·∫°y..."):
                            client.delete_run(selected_run_id)
                            if 'latest_run' in st.session_state and st.session_state['latest_run']['run_id'] == selected_run_id:
                                del st.session_state['latest_run']
                            st.success(f"ƒê√£ x√≥a: {selected_run_name}")
                            time.sleep(0.5)
                            st.rerun()

                    st.subheader("Th√¥ng tin chi ti·∫øt c·ªßa Run")
                    st.write(f"**T√™n l·∫ßn ch·∫°y:** {selected_run_name}")
                    st.write(f"**ID l·∫ßn ch·∫°y:** {selected_run_id}")
                    st.write(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** {datetime.fromtimestamp(selected_run.info.start_time / 1000)}")

                    st.markdown("**Tham s·ªë:**", unsafe_allow_html=True)
                    if selected_run.data.params:
                        st.json(selected_run.data.params, expanded=True)
                    else:
                        st.write("Kh√¥ng c√≥ tham s·ªë ƒë∆∞·ª£c ghi nh·∫≠n.")

                    st.markdown("**K·∫øt qu·∫£:**", unsafe_allow_html=True)
                    if selected_run.data.metrics:
                        reduce_method = selected_run.data.params.get("cluster_method", "Kh√¥ng x√°c ƒë·ªãnh")
                        metrics_display = {}

                        training_time = selected_run.data.metrics.get("training_time_seconds", "N/A")
                        metrics_display["Th·ªùi gian th·ª±c hi·ªán (gi√¢y)"] = f"{float(training_time):.2f}" if training_time != "N/A" else "N/A"

                        if reduce_method == "K-means":
                            inertia = selected_run.data.metrics.get("inertia", "N/A")
                            metrics_display["T·ªïng b√¨nh ph∆∞∆°ng kho·∫£ng c√°ch (K-means)"] = f"{float(inertia):.2f}" if inertia != "N/A" else "N/A"
                        elif reduce_method == "DBSCAN":
                            n_clusters = selected_run.data.metrics.get("n_clusters", "N/A")
                            n_noise = selected_run.data.metrics.get("n_noise", "N/A")
                            metrics_display["S·ªë c·ª•m t√¨m ƒë∆∞·ª£c (DBSCAN)"] = n_clusters
                            metrics_display["S·ªë ƒëi·ªÉm nhi·ªÖu (DBSCAN)"] = n_noise

                        st.json(metrics_display, expanded=True)
                    else:
                        st.write("Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë∆∞·ª£c ghi nh·∫≠n.")

                    # Th√™m n√∫t li√™n k·∫øt t·ªõi MLflow UI
                    st.subheader("Truy c·∫≠p MLflow UI")
                    mlflow_url = "https://dagshub.com/huykibo/streamlit_mlflow.mlflow"  # Thay b·∫±ng URL MLflow c·ªßa b·∫°n n·∫øu kh√°c
                    if st.button("M·ªü MLflow UI tr√™n Dagshub"):
                        st.markdown(f'[Click ƒë·ªÉ m·ªü MLflow UI]({mlflow_url})', unsafe_allow_html=True)
        except Exception as e:
            st.error(f"L·ªói k·∫øt n·ªëi MLflow: {e}. Vui l√≤ng ki·ªÉm tra MLFLOW_TRACKING_URI v√† th√¥ng tin x√°c th·ª±c.")

if __name__ == "__main__":
    run_mnist_clustering_app()