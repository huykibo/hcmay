import os
import mlflow
import streamlit as st
import openml
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.neural_network import MLPClassifier
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from datetime import datetime
import time

def    run_mnist_neural_network_app():
    # Thi·∫øt l·∫≠p MLflow
    try:
        os.environ["MLFLOW_TRACKING_USERNAME"] = st.secrets["mlflow"]["MLFLOW_TRACKING_USERNAME"]
        os.environ["MLFLOW_TRACKING_PASSWORD"] = st.secrets["mlflow"]["MLFLOW_TRACKING_PASSWORD"]
        mlflow.set_tracking_uri(st.secrets["mlflow"]["MLFLOW_TRACKING_URI"])
        mlflow.set_experiment("Neural Network ")
    except KeyError as e:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y kh√≥a {e} trong st.secrets. Vui l√≤ng c·∫•u h√¨nh secrets trong Streamlit.")
        st.stop()

    st.title("·ª®ng d·ª•ng Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST b·∫±ng Neural Network")

    # CSS cho tooltip v√† MathJax
    st.markdown("""
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
        <style>
            .tooltip {
                position: relative;
                display: inline-block;
                cursor: pointer;
                color: #1f77b4;
                font-weight: bold;
                margin-left: 5px;
            }
            .tooltip .tooltiptext {
                visibility: hidden;
                width: 400px;
                background-color: #f9f9f9;
                color: #333;
                text-align: left;
                border-radius: 6px;
                padding: 10px;
                position: absolute;
                z-index: 1;
                right: 105%;
                top: 50%;
                transform: translateY(-50%);
                opacity: 0;
                transition: opacity 0.3s;
                border: 1px solid #ccc;
                font-size: 0.9em;
                line-height: 1.4;
            }
            .tooltip:hover .tooltiptext {
                visibility: visible;
                opacity: 1;
            }
        </style>
    """, unsafe_allow_html=True)

    # C√°c tab
    tabs = st.tabs(["Th√¥ng tin", "T·∫£i d·ªØ li·ªáu", "X·ª≠ l√≠ d·ªØ li·ªáu", "Chia d·ªØ li·ªáu", "Hu·∫•n luy·ªán/ƒê√°nh Gi√°", "Demo d·ª± ƒëo√°n", "Th√¥ng tin hu·∫•n luy·ªán"])
    tab_info, tab_load, tab_preprocess, tab_split, tab_train_eval, tab_demo, tab_log_info = tabs

    # Tab 1: Th√¥ng tin
    with tab_info:
        st.header("Gi·ªõi thi·ªáu v·ªÅ ·ª®ng d·ª•ng v√† M·∫°ng Neural Network")
        st.markdown("""
        Ch√†o b·∫°n! ƒê√¢y l√† ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay t·ª´ t·∫≠p d·ªØ li·ªáu **MNIST** b·∫±ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**. H√£y kh√°m ph√° c√°c t√≠nh nƒÉng v√† c√°ch ho·∫°t ƒë·ªông c·ªßa n√≥ nh√©!
        """, unsafe_allow_html=True)

        st.subheader("Ch·ªçn th√¥ng tin ƒë·ªÉ xem")
        info_option = st.selectbox(
            "",
            [
                "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?",
                "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a",
                "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o",
                "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)"
            ],
            label_visibility="collapsed",
            help="Ch·ªçn ƒë·ªÉ xem chi ti·∫øt v·ªÅ ·ª©ng d·ª•ng, d·ªØ li·ªáu, ho·∫∑c m√¥ h√¨nh."
        )

        if info_option == "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?":
            st.subheader("üìò 1. ·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?")
            st.markdown("""
            ƒê√¢y l√† m·ªôt ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu **MNIST**, s·ª≠ d·ª•ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**.

            - **MNIST**:  
              - T·∫≠p d·ªØ li·ªáu g·ªìm **70,000 ·∫£nh** ch·ªØ s·ªë t·ª´ **0 ƒë·∫øn 9**.  
              - M·ªói ·∫£nh c√≥ k√≠ch th∆∞·ªõc **28 √ó 28 pixel**, t∆∞∆°ng ƒë∆∞∆°ng **784 ƒë·∫∑c tr∆∞ng** (gi√° tr·ªã pixel t·ª´ 0 ƒë·∫øn 255).  

            - **M·ª•c ti√™u**:  
              - X√¢y d·ª±ng v√† hu·∫•n luy·ªán m·ªôt **Neural Network** ƒë·ªÉ nh·∫≠n di·ªán ch√≠nh x√°c c√°c ch·ªØ s·ªë vi·∫øt tay.  
              - Cung c·∫•p m·ªôt c√¥ng c·ª• tr·ª±c quan gi√∫p ng∆∞·ªùi d√πng h·ªçc t·∫≠p v√† ƒë√°nh gi√° hi·ªáu qu·∫£ c·ªßa thu·∫≠t to√°n ph√¢n lo·∫°i.

            **Th√¥ng tin c∆° b·∫£n**:  
            - **784 ƒë·∫∑c tr∆∞ng**: M·ªói ·∫£nh ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng vector 784 chi·ªÅu, v·ªõi m·ªói chi·ªÅu l√† gi√° tr·ªã ƒë·ªô s√°ng c·ªßa m·ªôt pixel (t·ª´ 0 ƒë·∫øn 255).  
            - **70,000 m·∫´u**: T·ªïng s·ªë ·∫£nh, bao g·ªìm t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra.  
            - **Nhi·ªám v·ª•**: D·ª± ƒëo√°n nh√£n (t·ª´ 0 ƒë·∫øn 9) c·ªßa m·ªói ·∫£nh d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng pixel.
            """, unsafe_allow_html=True)

        elif info_option == "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a":
            st.subheader("üìò 2. T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a")
            st.markdown("""
            **MNIST** l√† m·ªôt t·∫≠p d·ªØ li·ªáu chu·∫©n trong lƒ©nh v·ª±c h·ªçc m√°y, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Yann LeCun v√† c√°c c·ªông s·ª±.

            - **ƒê·∫∑c ƒëi·ªÉm**:  
              - Bao g·ªìm c√°c ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ h·ªçc sinh trung h·ªçc v√† nh√¢n vi√™n ƒëi·ªÅu tra d√¢n s·ªë M·ªπ.  
              - ƒê∆∞·ª£c chu·∫©n h√≥a th√†nh k√≠ch th∆∞·ªõc **28 √ó 28 pixel**, s·ª≠ d·ª•ng thang ƒë·ªô x√°m (gi√° tr·ªã t·ª´ 0 ƒë·∫øn 255).  

            - **√ù nghƒ©a**:  
              - L√† b√†i to√°n c∆° b·∫£n ƒë·ªÉ ki·ªÉm tra hi·ªáu qu·∫£ c·ªßa c√°c thu·∫≠t to√°n ph√¢n lo·∫°i trong h·ªçc m√°y.  
              - D·ªØ li·ªáu ƒë∆°n gi·∫£n nh∆∞ng ƒë·ªß ph·ª©c t·∫°p ƒë·ªÉ ƒë√°nh gi√° kh·∫£ nƒÉng ph√¢n bi·ªát gi·ªØa c√°c l·ªõp t∆∞∆°ng t·ª± (v√≠ d·ª•: "4" v√† "9").  
              - Ph√π h·ª£p cho c·∫£ ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu v√† c√°c nh√† nghi√™n c·ª©u mu·ªën th·ª≠ nghi·ªám m√¥ h√¨nh ph·ª©c t·∫°p.
            """, unsafe_allow_html=True)

            st.subheader("üì∑ Minh h·ªça d·ªØ li·ªáu MNIST")
            st.markdown("""
            D∆∞·ªõi ƒë√¢y l√† ·∫£nh minh h·ªça 10 ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9 t·ª´ t·∫≠p d·ªØ li·ªáu MNIST. M·ªói ch·ªØ s·ªë ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n **28 √ó 28 pixel**.
            """, unsafe_allow_html=True)
            with st.spinner("ƒêang t·∫£i ·∫£nh minh h·ªça..."):
                try:
                    mnist_image = Image.open("mnist.png")
                    st.image(mnist_image, caption="·∫¢nh minh h·ªça 10 ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9 trong MNIST", width=800)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y file `mnist.png`. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

        elif info_option == "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o":
            st.subheader("üìä 3. Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o")
            st.markdown("""
            **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o)** l√† m·ªôt m√¥ h√¨nh h·ªçc m√°y m√¥ ph·ªèng c√°ch ho·∫°t ƒë·ªông c·ªßa m·∫°ng n∆°-ron sinh h·ªçc trong n√£o ng∆∞·ªùi.

            - **C·∫•u tr√∫c**:  
              - G·ªìm c√°c **n∆°-ron nh√¢n t·∫°o (nodes)** ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh nhi·ªÅu **l·ªõp (layers)**:  
                - **L·ªõp ƒë·∫ßu v√†o (Input Layer)**: Nh·∫≠n d·ªØ li·ªáu th√¥ (784 pixel t·ª´ ·∫£nh MNIST).  
                - **L·ªõp ·∫©n (Hidden Layers)**: X·ª≠ l√Ω th√¥ng tin b·∫±ng c√°ch k·∫øt h·ª£p tuy·∫øn t√≠nh v√† √°p d·ª•ng h√†m k√≠ch ho·∫°t phi tuy·∫øn.  
                - **L·ªõp ƒë·∫ßu ra (Output Layer)**: ƒê∆∞a ra d·ª± ƒëo√°n (nh√£n t·ª´ 0 ƒë·∫øn 9).  

            - **∆Øu ƒëi·ªÉm v·ªõi MNIST**: Neural Network ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ nh·ªù kh·∫£ nƒÉng h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu h√¨nh ·∫£nh.
            """, unsafe_allow_html=True)

            st.subheader("üõ†Ô∏è C√°c b∆∞·ªõc th·ª±c hi·ªán trong Neural Network")
            st.markdown("""
            D∆∞·ªõi ƒë√¢y l√† c√°c b∆∞·ªõc chi ti·∫øt ho·∫°t ƒë·ªông c·ªßa Neural Network trong b√†i to√°n MNIST:

            1. **Kh·ªüi t·∫°o m√¥ h√¨nh**:  
               - X√°c ƒë·ªãnh c·∫•u tr√∫c m·∫°ng: s·ªë l·ªõp ·∫©n v√† s·ªë n∆°-ron m·ªói l·ªõp.  
               - Kh·ªüi t·∫°o **tr·ªçng s·ªë (W)** v√† **bias (b)** ng·∫´u nhi√™n ho·∫∑c b·∫±ng 0.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step1_init.png"), caption="B∆∞·ªõc 1: Kh·ªüi t·∫°o m√¥ h√¨nh", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 1.")

            st.markdown("""
            2. **Lan truy·ªÅn thu·∫≠n (Feedforward)**:  
               - T√≠nh gi√° tr·ªã d·ª± ƒëo√°n **≈∂** t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o **X**:  
                 - **L·ªõp ƒë·∫ßu v√†o**: \( A^{(0)} = X \) (ma tr·∫≠n \( N \times 784 \), \( N \) l√† s·ªë m·∫´u).  
                 - **Cho m·ªói l·ªõp \( l \)**:  
                   - T·ªïng tuy·∫øn t√≠nh:  
                     $$ Z^{(l)} = A^{(l-1)} \cdot W^{(l)} + b^{(l)} $$  
                   - √Åp d·ª•ng h√†m k√≠ch ho·∫°t:  
                     $$ A^{(l)} = \sigma(Z^{(l)}) $$  
                 - **L·ªõp ƒë·∫ßu ra**: \( \hat{Y} = A^{(L)} \) (ma tr·∫≠n \( N \times 10 \)).  
               - V√≠ d·ª• h√†m k√≠ch ho·∫°t **sigmoid**:  
                 $$ \sigma(z) = \frac{1}{1 + e^{-z}} $$
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step2_feedforward.png"), caption="B∆∞·ªõc 2: Lan truy·ªÅn thu·∫≠n", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 2.")

            st.markdown("""
            3. **T√≠nh h√†m m·∫•t m√°t (Loss Function)**:  
               - ƒêo ƒë·ªô sai l·ªách gi·ªØa d·ª± ƒëo√°n \( \hat{Y} \) v√† nh√£n th·ª±c \( Y \). V·ªõi MNIST, d√πng **Cross-Entropy**:  
                 $$ L = -\frac{1}{N} \sum_{i=1}^{N} \sum_{j=0}^{9} y_{ij} \cdot \log(\hat{y}_{ij}) $$  
               - Trong ƒë√≥:  
                 - \( y_{ij} \): Nh√£n th·ª±c (d·∫°ng one-hot encoded).  
                 - \( \hat{y}_{ij} \): X√°c su·∫•t d·ª± ƒëo√°n cho l·ªõp \( j \).
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step3_loss.png"), caption="B∆∞·ªõc 3: T√≠nh h√†m m·∫•t m√°t", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 3.")

            st.markdown("""
            4. **Lan truy·ªÅn ng∆∞·ª£c (Backpropagation)**:  
               - T√≠nh ƒë·∫°o h√†m c·ªßa \( L \) theo \( W^{(l)} \) v√† \( b^{(l)} \) ƒë·ªÉ c·∫≠p nh·∫≠t tham s·ªë:  
                 - T·∫°i **L·ªõp ƒë·∫ßu ra**:  
                   $$ \delta^{(L)} = \hat{Y} - Y $$  
                 - T·∫°i **L·ªõp ·∫©n**:  
                   $$ \delta^{(l)} = (\delta^{(l+1)} \cdot (W^{(l+1)})^T) \odot \sigma'(Z^{(l)}) $$  
                 - \( \sigma'(z) \): ƒê·∫°o h√†m h√†m k√≠ch ho·∫°t (v·ªõi sigmoid: \( \sigma'(z) = \sigma(z) \cdot (1 - \sigma(z)) \)).  
                 - ƒê·∫°o h√†m theo tr·ªçng s·ªë v√† bias:  
                   $$ \frac{\partial L}{\partial W^{(l)}} = (A^{(l-1)})^T \cdot \delta^{(l)} $$  
                   $$ \frac{\partial L}{\partial b^{(l)}} = \sum_{i=1}^{N} \delta^{(l)}_i $$
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step4_backprop.png"), caption="B∆∞·ªõc 4: Lan truy·ªÅn ng∆∞·ª£c", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 4.")

            st.markdown("""
            5. **C·∫≠p nh·∫≠t tham s·ªë (Gradient Descent)**:  
               - ƒêi·ªÅu ch·ªânh \( W \) v√† \( b \) ƒë·ªÉ gi·∫£m m·∫•t m√°t:  
                 $$ W^{(l)} = W^{(l)} - \eta \cdot \frac{\partial L}{\partial W^{(l)}} $$  
                 $$ b^{(l)} = b^{(l)} - \eta \cdot \frac{\partial L}{\partial b^{(l)}} $$  
               - Trong ƒë√≥: \( \eta \) l√† **t·ªëc ƒë·ªô h·ªçc (learning rate)**.
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step5_gradient.png"), caption="B∆∞·ªõc 5: C·∫≠p nh·∫≠t tham s·ªë", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 5.")

            st.markdown("""
            6. **L·∫∑p l·∫°i**:  
               - Quay l·∫°i b∆∞·ªõc 2 qua nhi·ªÅu **epoch** cho ƒë·∫øn khi \( L \) h·ªôi t·ª•.
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step6_repeat_improved.png"), caption="B∆∞·ªõc 6: L·∫∑p l·∫°i", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 6.")

            st.subheader("‚öôÔ∏è C√°c tham s·ªë c∆° b·∫£n v√† c√¥ng d·ª•ng")
            st.markdown("""
            D∆∞·ªõi ƒë√¢y l√† c√°c tham s·ªë ch√≠nh b·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh trong ·ª©ng d·ª•ng:

            - **hidden_layer_sizes**:  
              - **√ù nghƒ©a**: S·ªë n∆°-ron trong c√°c l·ªõp ·∫©n (v√≠ d·ª•: 128).  
              - **C√¥ng d·ª•ng**: Quy·∫øt ƒë·ªãnh s·ª©c m·∫°nh t√≠nh to√°n c·ªßa m√¥ h√¨nh; nhi·ªÅu n∆°-ron h∆°n gi√∫p h·ªçc ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p nh∆∞ng t·ªën t√†i nguy√™n h∆°n.  
            - **learning_rate_init**:  
              - **√ù nghƒ©a**: T·ªëc ƒë·ªô h·ªçc ban ƒë·∫ßu (v√≠ d·ª•: 0.001).  
              - **C√¥ng d·ª•ng**: ƒêi·ªÅu ch·ªânh t·ªëc ƒë·ªô c·∫≠p nh·∫≠t tr·ªçng s·ªë; gi√° tr·ªã nh·ªè gi√∫p h·ªçc ·ªïn ƒë·ªãnh nh∆∞ng ch·∫≠m.  
            - **max_iter**:  
              - **√ù nghƒ©a**: S·ªë l·∫ßn hu·∫•n luy·ªán t·ªëi ƒëa (v√≠ d·ª•: 200).  
              - **C√¥ng d·ª•ng**: Gi·ªõi h·∫°n s·ªë l·∫ßn l·∫∑p ƒë·ªÉ ƒë·∫°t ƒë·ªô ch√≠nh x√°c mong mu·ªën.
            """, unsafe_allow_html=True)

            st.subheader("üü™ ∆Øu ƒëi·ªÉm v√† nh∆∞·ª£c ƒëi·ªÉm")
            st.markdown("""
            - **‚úÖ ∆Øu ƒëi·ªÉm**:  
              - H·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu h√¨nh ·∫£nh nh∆∞ MNIST.  
              - D·ªÖ s·ª≠ d·ª•ng v·ªõi c√°c tham s·ªë c∆° b·∫£n ƒë∆∞·ª£c t·ªëi ∆∞u s·∫µn.  

            - **‚ùå Nh∆∞·ª£c ƒëi·ªÉm**:  
              - T·ªën th·ªùi gian hu·∫•n luy·ªán n·∫øu s·ªë m·∫´u l·ªõn ho·∫∑c s·ªë n∆°-ron nhi·ªÅu.  
              - C·∫ßn d·ªØ li·ªáu ƒë∆∞·ª£c chu·∫©n h√≥a ƒë·ªÉ ƒë·∫°t hi·ªáu qu·∫£ t·ªëi ∆∞u.
            """, unsafe_allow_html=True)

        elif info_option == "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)":
            st.subheader("üìò 4. C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)")
            st.markdown("""
            ƒê·ªô ch√≠nh x√°c (**Accuracy**) ƒëo t·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng c·ªßa m√¥ h√¨nh:  
            $$ \text{Accuracy} = \frac{\text{S·ªë m·∫´u d·ª± ƒëo√°n ƒë√∫ng}}{\text{T·ªïng s·ªë m·∫´u}} $$

            - **V√≠ d·ª•**: N·∫øu m√¥ h√¨nh d·ª± ƒëo√°n ƒë√∫ng 92/100 ·∫£nh, th√¨:  
              $$ \text{Accuracy} = \frac{92}{100} = 92\% $$  

            - **√ù nghƒ©a**: V·ªõi Neural Network, Accuracy th·ªÉ hi·ªán kh·∫£ nƒÉng m√¥ h√¨nh ph√¢n lo·∫°i ƒë√∫ng c√°c ch·ªØ s·ªë d·ª±a tr√™n c√°c ƒë·∫∑c tr∆∞ng pixel m√† n√≥ ƒë√£ h·ªçc ƒë∆∞·ª£c t·ª´ d·ªØ li·ªáu MNIST.
            """, unsafe_allow_html=True)

    # Tab 2: T·∫£i d·ªØ li·ªáu
    with tab_load:
        st.header("T·∫£i D·ªØ li·ªáu")
        if st.button("T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML"):
            with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ OpenML..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                try:
                    mnist = openml.datasets.get_dataset(554)
                    progress_bar.progress(20)
                    status_text.text("ƒê√£ t·∫£i 20% - ƒêang l·∫•y d·ªØ li·ªáu...")

                    X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute)
                    progress_bar.progress(50)
                    status_text.text("ƒê√£ t·∫£i 50% - ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")

                    st.session_state['full_data'] = (X, y)
                    progress_bar.progress(90)
                    status_text.text(f"ƒê√£ t·∫£i 90% - Ho√†n t·∫•t {X.shape[0]} m·∫´u...")

                    with mlflow.start_run(run_name="Data_Load"):
                        mlflow.log_param("total_samples", X.shape[0])

                    progress_bar.progress(100)
                    status_text.text("ƒê√£ t·∫£i 100% - Ho√†n t·∫•t!")
                    time.sleep(1)
                    status_text.empty()
                    progress_bar.empty()
                    st.success("T·∫£i d·ªØ li·ªáu th√†nh c√¥ng!")
                    st.write("K√≠ch th∆∞·ªõc d·ªØ li·ªáu g·ªëc:", X.shape)
                except Exception as e:
                    st.error(f"Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu: {e}")

        if 'full_data' in st.session_state:
            X_full, y_full = st.session_state['full_data']
            num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u:", 
                                    min_value=10, max_value=len(X_full), value=min(1000, len(X_full)), step=1)
            if st.button("Ch·ªët s·ªë l∆∞·ª£ng m·∫´u"):
                with st.spinner(f"ƒêang l·∫•y {num_samples} m·∫´u..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    df = pd.concat([X_full, y_full.rename("label")], axis=1)
                    progress_bar.progress(30)
                    status_text.text("ƒê√£ x·ª≠ l√Ω 30% - ƒêang n·ªëi d·ªØ li·ªáu...")

                    sampled_df = df.sample(n=num_samples, random_state=42)
                    progress_bar.progress(70)
                    status_text.text("ƒê√£ x·ª≠ l√Ω 70% - ƒêang l·∫•y m·∫´u...")

                    X_sampled = sampled_df.drop(columns=["label"])
                    y_sampled = sampled_df["label"]
                    st.session_state['data'] = (X_sampled, y_sampled)
                    progress_bar.progress(90)
                    status_text.text("ƒê√£ x·ª≠ l√Ω 90% - ƒêang l∆∞u d·ªØ li·ªáu...")

                    with mlflow.start_run(run_name="Data_Sample"):
                        mlflow.log_param("num_samples", num_samples)

                    progress_bar.progress(100)
                    status_text.text("ƒê√£ x·ª≠ l√Ω 100% - Ho√†n t·∫•t!")
                    time.sleep(1)
                    status_text.empty()
                    progress_bar.empty()
                    st.success(f"ƒê√£ ch·ªët {num_samples} m·∫´u!")

    # Tab 3: X·ª≠ l√Ω d·ªØ li·ªáu
    with tab_preprocess:
        st.header("X·ª≠ l√Ω D·ªØ li·ªáu")
        if 'data' not in st.session_state:
            st.info("Vui l√≤ng t·∫£i v√† ch·ªët s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc.")
        else:
            X, y = st.session_state['data']
            if "data_original" not in st.session_state:
                st.session_state["data_original"] = (X.copy(), y.copy())

            st.subheader("D·ªØ li·ªáu G·ªëc")
            fig, axes = plt.subplots(2, 5, figsize=(10, 4))
            for i, ax in enumerate(axes.flat):
                ax.imshow(X.iloc[i].values.reshape(28, 28), cmap='gray')
                ax.set_title(f"Label: {y.iloc[i]}")
                ax.axis("off")
            st.pyplot(fig)

            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("Normalization", key="normalize_btn"):
                    X_norm = X / 255.0
                    st.session_state["data_processed"] = (X_norm, y)
                    st.success("ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu!")
                    st.rerun()
            with col2:
                st.markdown("""
                    <div class="tooltip">
                        ?
                        <span class="tooltiptext">
                            ƒê∆∞a d·ªØ li·ªáu v·ªÅ kho·∫£ng [0, 1] b·∫±ng c√°ch chia cho 255.<br>
                            C√¥ng d·ª•ng: ƒê·∫£m b·∫£o thang ƒëo ƒë·ªìng nh·∫•t, c·∫ßn thi·∫øt cho Neural Network.
                        </span>
                    </div>
                """, unsafe_allow_html=True)

            if "data_processed" in st.session_state:
                X_processed, y_processed = st.session_state["data_processed"]
                st.subheader("D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω")
                fig, axes = plt.subplots(2, 5, figsize=(10, 4))
                for i, ax in enumerate(axes.flat):
                    ax.imshow(X_processed.iloc[i].values.reshape(28, 28), cmap='gray')
                    ax.set_title(f"Label: {y_processed.iloc[i]}")
                    ax.axis("off")
                st.pyplot(fig)

    # Tab 4: Chia d·ªØ li·ªáu
    with tab_split:
        st.header("Chia T·∫≠p D·ªØ Li·ªáu")
        if 'data' not in st.session_state:
            st.info("Vui l√≤ng t·∫£i v√† ch·ªët s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc.")
        else:
            data_source = st.session_state.get("data_processed", st.session_state['data'])
            X, y = data_source
            total_samples = len(X)
            st.write(f"T·ªïng s·ªë m·∫´u: {total_samples}")

            test_pct = st.slider("T·ª∑ l·ªá t·∫≠p Test (%)", 0, 100, 20)
            valid_pct = st.slider("T·ª∑ l·ªá t·∫≠p Validation (%) t·ª´ ph·∫ßn c√≤n l·∫°i", 0, 100, 20)
            
            if test_pct + valid_pct > 100:
                st.warning("T·ªïng t·ª∑ l·ªá Test v√† Validation v∆∞·ª£t qu√° 100%!")
            
            test_size = int(total_samples * test_pct / 100)
            if test_size > 0:
                X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size / total_samples, random_state=42)
            else:
                X_temp, y_temp = X, y
                X_test, y_test = pd.DataFrame(), pd.Series()

            valid_size = int(len(X_temp) * valid_pct / 100)
            if valid_size > 0 and len(X_temp) > valid_size:
                X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=valid_size / len(X_temp), random_state=42)
            else:
                X_train, y_train = X_temp, y_temp
                X_valid, y_valid = pd.DataFrame(), pd.Series()

            st.write(f"Train: {len(X_train)} m·∫´u, Validation: {len(X_valid)} m·∫´u, Test: {len(X_test)} m·∫´u")
            if st.button("X√°c nh·∫≠n chia d·ªØ li·ªáu"):
                st.session_state['split_data'] = {
                    "X_train": X_train, "y_train": y_train,
                    "X_valid": X_valid, "y_valid": y_valid,
                    "X_test": X_test, "y_test": y_test
                }
                st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia!")

    # Tab 5: Hu·∫•n luy·ªán/ƒê√°nh Gi√°
    with tab_train_eval:
        st.header("Hu·∫•n luy·ªán v√† ƒê√°nh Gi√°")
        if 'split_data' not in st.session_state:
            st.info("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            st.subheader("Hu·∫•n luy·ªán Neural Network")
            X_train = st.session_state['split_data']["X_train"]
            num_samples = len(X_train)
            st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: {num_samples}")

            st.subheader("B·∫£ng g·ª£i √Ω tham s·ªë t·ªëi ∆∞u")
            st.markdown("""
            | S·ªë l∆∞·ª£ng m·∫´u | Hidden Layer Sizes | Learning Rate Init | Max Iter |
            |--------------|--------------------|--------------------|----------|
            | <1000        | (64,)             | 0.01              | 100      |
            | 1000-5000    | (128,)            | 0.001             | 200      |
            | 5000-50000   | (256, 128)        | 0.001             | 300      |
            | >50000       | (512, 256)        | 0.0001            | 500      |
            """)
            st.markdown("""
            - **hidden_layer_sizes**: Tuple ƒë·ªãnh nghƒ©a s·ªë n∆°-ron trong c√°c l·ªõp ·∫©n.  
            - **learning_rate_init**: T·ªëc ƒë·ªô h·ªçc ban ƒë·∫ßu.  
            - **max_iter**: S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa.
            """)

            params = {}
            if num_samples < 1000:
                params["hidden_layer_sizes"] = (64,)
                params["learning_rate_init"] = 0.01
                params["max_iter"] = 100
            elif 1000 <= num_samples <= 5000:
                params["hidden_layer_sizes"] = (128,)
                params["learning_rate_init"] = 0.001
                params["max_iter"] = 200
            elif 5000 < num_samples <= 50000:
                params["hidden_layer_sizes"] = (256, 128)
                params["learning_rate_init"] = 0.001
                params["max_iter"] = 300
            else:
                params["hidden_layer_sizes"] = (512, 256)
                params["learning_rate_init"] = 0.0001
                params["max_iter"] = 500

            st.markdown("#### Tham s·ªë m√¥ h√¨nh (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh)")
            hidden_layers_input = st.text_input("Hidden Layer Sizes (d·∫°ng tuple, v√≠ d·ª•: 128, 64)", value=str(params["hidden_layer_sizes"]).strip("()"))
            params["hidden_layer_sizes"] = tuple(int(x.strip()) for x in hidden_layers_input.split(",") if x.strip())
            params["learning_rate_init"] = st.number_input("Learning Rate Init", min_value=0.0001, max_value=0.1, value=params["learning_rate_init"])
            params["max_iter"] = st.number_input("Max Iter", min_value=10, max_value=1000, value=params["max_iter"])

            if st.button("Th·ª±c hi·ªán Hu·∫•n luy·ªán"):
                with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    start_time = time.time()

                    X_train = st.session_state['split_data']["X_train"]
                    y_train = st.session_state['split_data']["y_train"]
                    X_valid = st.session_state['split_data']["X_valid"]
                    y_valid = st.session_state['split_data']["y_valid"]
                    X_test = st.session_state['split_data']["X_test"]
                    y_test = st.session_state['split_data']["y_test"]

                    run_name = f"NeuralNetwork_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    with mlflow.start_run(run_name=run_name) as run:
                        pipeline = Pipeline([
                            ('imputer', SimpleImputer(strategy='mean')),
                            ('classifier', MLPClassifier(
                                hidden_layer_sizes=params["hidden_layer_sizes"],
                                learning_rate_init=params["learning_rate_init"],
                                max_iter=params["max_iter"],
                                activation='relu',
                                solver='adam',
                                random_state=42,
                                verbose=False
                            ))
                        ])
                        pipeline.fit(X_train, y_train)
                        model = pipeline

                        for i in range(0, 51, 5):
                            progress_bar.progress(i)
                            status_text.text(f"ƒêang hu·∫•n luy·ªán {i}%...")

                        mlflow.log_params(params)
                        y_valid_pred = model.predict(X_valid)
                        accuracy_val = accuracy_score(y_valid, y_valid_pred)
                        mlflow.log_metric("accuracy_val", accuracy_val)
                        cm_valid = confusion_matrix(y_valid, y_valid_pred)

                        y_test_pred = model.predict(X_test)
                        accuracy_test = accuracy_score(y_test, y_test_pred)
                        mlflow.log_metric("accuracy_test", accuracy_test)
                        cm_test = confusion_matrix(y_test, y_test_pred)

                        training_time = time.time() - start_time
                        mlflow.log_metric("training_time_seconds", training_time)
                        mlflow.sklearn.log_model(model, "model")

                        for i in range(50, 101, 5):
                            progress_bar.progress(i)
                            status_text.text(f"Ho√†n t·∫•t {i}%...")

                        run_id = run.info.run_id
                        st.session_state['model'] = model
                        st.session_state['training_results'] = {
                            'training_time': training_time,
                            'accuracy_val': accuracy_val,
                            'accuracy_test': accuracy_test,
                            'cm_valid': cm_valid,
                            'cm_test': cm_test,
                            'model_choice': 'Neural Network',
                            'params': params,
                            'num_samples': num_samples,
                            'run_name': run_name,
                            'run_id': run_id
                        }

                        status_text.empty()
                        progress_bar.empty()

            if 'training_results' in st.session_state:
                st.success(f"Hu·∫•n luy·ªán ho√†n t·∫•t. Th·ªùi gian: {st.session_state['training_results']['training_time']:.2f} gi√¢y.")
                st.write(f"Accuracy Validation: {st.session_state['training_results']['accuracy_val']:.4f}")
                st.write(f"Accuracy Test: {st.session_state['training_results']['accuracy_test']:.4f}")

                fig, ax = plt.subplots()
                sns.heatmap(st.session_state['training_results']['cm_valid'], annot=True, fmt="d", cmap="Blues", ax=ax)
                ax.set_title("Confusion Matrix - Validation")
                st.pyplot(fig)

                fig, ax = plt.subplots()
                sns.heatmap(st.session_state['training_results']['cm_test'], annot=True, fmt="d", cmap="Blues", ax=ax)
                ax.set_title("Confusion Matrix - Test")
                st.pyplot(fig)

    # Tab 6: Demo d·ª± ƒëo√°n
    with tab_demo:
        st.header("Demo D·ª± ƒëo√°n")
        if 'split_data' not in st.session_state or 'model' not in st.session_state:
            st.info("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
        else:
            mode = st.radio("Ch·ªçn ph∆∞∆°ng th·ª©c d·ª± ƒëo√°n:", ["D·ªØ li·ªáu t·ª´ Test", "Upload ·∫£nh m·ªõi", "V·∫Ω s·ªë"])
            
            progress_bar = st.progress(0)
            status_text = st.empty()

            def preprocess_input(data):
                return data / 255.0

            is_normalized = "data_processed" in st.session_state

            if mode == "D·ªØ li·ªáu t·ª´ Test":
                X_test = st.session_state['split_data']["X_test"]
                y_test = st.session_state['split_data']["y_test"]
                idx = st.slider("Ch·ªçn m·∫´u t·ª´ Test", 0, len(X_test)-1, 0)
                if st.button("D·ª± ƒëo√°n"):
                    with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                        for i in range(0, 51, 5):
                            progress_bar.progress(i)
                            status_text.text(f"ƒêang x·ª≠ l√Ω {i}%...")
                            time.sleep(0.1)
                        
                        sample = X_test.iloc[idx].values.reshape(1, -1)
                        if not is_normalized:
                            sample = preprocess_input(sample)
                        
                        prediction = st.session_state['model'].predict(sample)[0]
                        proba = st.session_state['model'].predict_proba(sample)[0]
                        confidence = max(proba) * 100
                        y_true = y_test.iloc[idx]
                        
                        for i in range(50, 101, 5):
                            progress_bar.progress(i)
                            status_text.text(f"ƒêang d·ª± ƒëo√°n {i}%...")
                            time.sleep(0.1)
                        
                        st.success(f"D·ª± ƒëo√°n: **{prediction}** | Confidence: **{confidence:.2f}%** | Gi√° tr·ªã th·ª±c: **{y_true}**")
                        fig, ax = plt.subplots()
                        ax.imshow(X_test.iloc[idx].values.reshape(28, 28), cmap='gray')
                        ax.axis("off")
                        st.pyplot(fig)
                        
                        time.sleep(1)
                        progress_bar.empty()
                        status_text.empty()

            elif mode == "Upload ·∫£nh m·ªõi":
                uploaded_images = st.file_uploader("Upload ·∫£nh (28x28, grayscale)", type=["png", "jpg"], accept_multiple_files=True)
                if uploaded_images:
                    for i, uploaded_image in enumerate(uploaded_images):
                        with st.spinner(f"ƒêang x·ª≠ l√Ω ·∫£nh {i+1}/{len(uploaded_images)}..."):
                            for j in range(0, 51, 5):
                                progress_bar.progress(j)
                                status_text.text(f"ƒêang t·∫£i ·∫£nh {i+1} - {j}%...")
                                time.sleep(0.1)
                            
                            img = Image.open(uploaded_image).convert('L').resize((28, 28))
                            img_array = np.array(img).flatten().reshape(1, -1)
                            if not is_normalized:
                                img_array = preprocess_input(img_array)
                            
                            prediction = st.session_state['model'].predict(img_array)[0]
                            proba = st.session_state['model'].predict_proba(img_array)[0]
                            confidence = max(proba) * 100
                            
                            for j in range(50, 101, 5):
                                progress_bar.progress(j)
                                status_text.text(f"ƒêang d·ª± ƒëo√°n ·∫£nh {i+1} - {j}%...")
                                time.sleep(0.1)
                            
                            st.success(f"D·ª± ƒëo√°n: **{prediction}** | ƒê·ªô tin c·∫≠y: **{confidence:.2f}%**")
                            st.image(img, caption=f"·∫¢nh {i+1} ƒë∆∞·ª£c upload", use_container_width=True)
                            
                            time.sleep(1)
                            progress_bar.empty()
                            status_text.empty()

            elif mode == "V·∫Ω s·ªë":
                st.write("V·∫Ω m·ªôt ch·ªØ s·ªë t·ª´ 0-9 tr√™n canvas b√™n d∆∞·ªõi (28x28 pixel):")
                canvas_result = st_canvas(
                    fill_color="black",
                    stroke_width=20,
                    stroke_color="white",
                    background_color="black",
                    width=280,
                    height=280,
                    drawing_mode="freedraw",
                    key="canvas"
                )
                if st.button("D·ª± ƒëo√°n s·ªë ƒë√£ v·∫Ω"):
                    if canvas_result.image_data is not None:
                        with st.spinner("ƒêang x·ª≠ l√Ω v·∫Ω..."):
                            for i in range(0, 51, 5):
                                progress_bar.progress(i)
                                status_text.text(f"ƒêang x·ª≠ l√Ω {i}%...")
                                time.sleep(0.1)
                            
                            img = Image.fromarray((canvas_result.image_data * 255).astype(np.uint8)).convert('L').resize((28, 28))
                            img_array = np.array(img).flatten().reshape(1, -1)
                            if not is_normalized:
                                img_array = preprocess_input(img_array)
                            
                            prediction = st.session_state['model'].predict(img_array)[0]
                            proba = st.session_state['model'].predict_proba(img_array)[0]
                            confidence = max(proba) * 100
                            
                            for i in range(50, 101, 5):
                                progress_bar.progress(i)
                                status_text.text(f"ƒêang d·ª± ƒëo√°n {i}%...")
                                time.sleep(0.1)
                            
                            st.success(f"D·ª± ƒëo√°n: **{prediction}** | ƒê·ªô tin c·∫≠y: **{confidence:.2f}%**")
                            
                            time.sleep(1)
                            progress_bar.empty()
                            status_text.empty()
                    else:
                        st.warning("Vui l√≤ng v·∫Ω m·ªôt ch·ªØ s·ªë tr∆∞·ªõc khi d·ª± ƒëo√°n!")

    # Tab 7: Th√¥ng tin hu·∫•n luy·ªán
    with tab_log_info:
        st.header("Theo d√µi k·∫øt qu·∫£")
        st.markdown("""
        Tab n√†y cho ph√©p b·∫°n xem danh s√°ch c√°c l·∫ßn hu·∫•n luy·ªán ƒë√£ th·ª±c hi·ªán. Ch·ªçn m·ªôt l·∫ßn ch·∫°y ƒë·ªÉ xem chi ti·∫øt, ƒë·ªïi t√™n ho·∫∑c x√≥a.
        """, unsafe_allow_html=True)
        
        try:
            client = MlflowClient()
            experiment = client.get_experiment_by_name("Neural Network ")
            if not experiment:
                st.error("Kh√¥ng t√¨m th·∫•y experiment 'Neural Network '. Vui l√≤ng ki·ªÉm tra l·∫°i MLflow tracking URI.")
            else:
                experiment_id = experiment.experiment_id
                runs = client.search_runs(experiment_ids=[experiment_id], order_by=["attributes.start_time DESC"])
                
                if not runs:
                    st.info("Ch∆∞a c√≥ l·∫ßn ch·∫°y n√†o ƒë∆∞·ª£c ghi nh·∫≠n.")
                else:
                    run_options = {run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") for run in runs}
                    run_names = list(run_options.values())
                    selected_run_name = st.selectbox("Ch·ªçn run:", run_names)
                    selected_run_id = [k for k, v in run_options.items() if v == selected_run_name][0]
                    selected_run = client.get_run(selected_run_id)

                    st.subheader("ƒê·ªïi t√™n Run")
                    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", value=selected_run_name)
                    if st.button("C·∫≠p nh·∫≠t t√™n"):
                        client.set_tag(selected_run_id, "mlflow.runName", new_run_name)
                        st.success(f"ƒê√£ ƒë·ªïi t√™n th√†nh: {new_run_name}")
                        st.rerun()

                    st.subheader("X√≥a Run")
                    if st.button("X√≥a l·∫ßn ch·∫°y"):
                        client.delete_run(selected_run_id)
                        st.success(f"ƒê√£ x√≥a: {selected_run_name}")
                        st.rerun()

                    st.subheader("Th√¥ng tin chi ti·∫øt c·ªßa Run")
                    st.write(f"**T√™n l·∫ßn ch·∫°y:** {selected_run_name}")
                    st.write(f"**ID l·∫ßn ch·∫°y:** {selected_run_id}")
                    st.write(f"**Tham s·ªë:** {selected_run.data.params}")
                    st.write(f"**K·∫øt qu·∫£:** {selected_run.data.metrics}")
        except Exception as e:
            st.error(f"L·ªói k·∫øt n·ªëi MLflow: {e}")

if __name__ == "__main__":
       run_mnist_neural_network_app()