import os
import mlflow
import streamlit as st
import openml
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.neural_network import MLPClassifier  # Neural Network
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from datetime import datetime
import time

def run_mnist_neural_network_app():
    st.title("·ª®ng d·ª•ng Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Neural Network")

    # CSS cho MathJax v√† giao di·ªán
    st.markdown("""
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
        <style>
            .inline-container {
                display: inline-flex;
                align-items: center;
                gap: 5px;
            }
        </style>
    """, unsafe_allow_html=True)

    # C√°c tab
    tabs = st.tabs(["Th√¥ng tin", "T·∫£i d·ªØ li·ªáu", "X·ª≠ l√Ω d·ªØ li·ªáu", "Chia d·ªØ li·ªáu", "Hu·∫•n luy·ªán/ƒê√°nh gi√°", "Demo d·ª± ƒëo√°n", "Th√¥ng tin hu·∫•n luy·ªán"])
    tab_info, tab_load, tab_preprocess, tab_split, tab_train_eval, tab_demo, tab_log_info = tabs

    # Tab 1: Th√¥ng tin
    with tab_info:
        st.header("Gi·ªõi thi·ªáu v·ªÅ ·ª®ng d·ª•ng v√† M·∫°ng Neural Network")
        st.markdown("""
        Ch√†o b·∫°n! ƒê√¢y l√† ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay t·ª´ t·∫≠p d·ªØ li·ªáu **MNIST** b·∫±ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**. H√£y kh√°m ph√° c√°c t√≠nh nƒÉng v√† c√°ch ho·∫°t ƒë·ªông c·ªßa n√≥ nh√©!
        """, unsafe_allow_html=True)

        st.subheader("Ch·ªçn th√¥ng tin ƒë·ªÉ xem")
        info_option = st.selectbox(
            "",
            [
                "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?",
                "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a",
                "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o",
                "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)"
            ],
            label_visibility="collapsed",
            help="Ch·ªçn ƒë·ªÉ xem chi ti·∫øt v·ªÅ ·ª©ng d·ª•ng, d·ªØ li·ªáu, ho·∫∑c m√¥ h√¨nh."
        )

        if info_option == "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?":
            st.subheader("üìò 1. ·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?")
            st.markdown("""
            ƒê√¢y l√† m·ªôt ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu **MNIST**, s·ª≠ d·ª•ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**.  
            - **MNIST**: T·∫≠p d·ªØ li·ªáu g·ªìm $70,000$ ·∫£nh ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$, m·ªói ·∫£nh k√≠ch th∆∞·ªõc $28 \\times 28$ pixel (t·ªïng c·ªông $784$ ƒë·∫∑c tr∆∞ng).  
            - **M·ª•c ti√™u**:  
              - X√¢y d·ª±ng v√† hu·∫•n luy·ªán m·ªôt m·∫°ng n∆°-ron ƒë·ªÉ nh·∫≠n di·ªán ch√≠nh x√°c c√°c ch·ªØ s·ªë.  
              - Cung c·∫•p c√¥ng c·ª• tr·ª±c quan ƒë·ªÉ h·ªçc t·∫≠p v√† ƒë√°nh gi√° hi·ªáu qu·∫£ c·ªßa thu·∫≠t to√°n.  

            **Th√¥ng tin c∆° b·∫£n**:  
            - **$784$ ƒë·∫∑c tr∆∞ng**: M·ªói ·∫£nh ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng vector $784$ chi·ªÅu (gi√° tr·ªã pixel t·ª´ $0$ ƒë·∫øn $255$).  
            - **$70,000$ m·∫´u**: T·ªïng s·ªë ·∫£nh, ƒë∆∞·ª£c chia th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra.  
            - **Nhi·ªám v·ª•**: D·ª± ƒëo√°n nh√£n ($0$-$9$) d·ª±a tr√™n ƒë·∫∑c tr∆∞ng pixel.  
            """, unsafe_allow_html=True)

        elif info_option == "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a":
            st.subheader("üìò 2. T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a")
            st.markdown("""
            **MNIST** l√† t·∫≠p d·ªØ li·ªáu chu·∫©n trong h·ªçc m√°y, ƒë∆∞·ª£c t·∫°o b·ªüi Yann LeCun v√† c√°c c·ªông s·ª±.  
            - **ƒê·∫∑c ƒëi·ªÉm**:  
              - G·ªìm c√°c ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ h·ªçc sinh trung h·ªçc v√† nh√¢n vi√™n ƒëi·ªÅu tra d√¢n s·ªë M·ªπ.  
              - Chu·∫©n h√≥a th√†nh k√≠ch th∆∞·ªõc $28 \\times 28$ pixel, thang ƒë·ªô x√°m (gi√° tr·ªã t·ª´ $0$ ƒë·∫øn $255$).  

            **√ù nghƒ©a**:  
            - L√† b√†i to√°n c∆° b·∫£n ƒë·ªÉ ki·ªÉm tra kh·∫£ nƒÉng ph√¢n lo·∫°i c·ªßa c√°c m√¥ h√¨nh h·ªçc m√°y.  
            - ƒê∆°n gi·∫£n nh∆∞ng ƒë·ªß ph·ª©c t·∫°p ƒë·ªÉ ƒë√°nh gi√° kh·∫£ nƒÉng ph√¢n bi·ªát c√°c l·ªõp t∆∞∆°ng t·ª± (v√≠ d·ª•: "$4$" v√† "$9$").  
            - Ph√π h·ª£p cho c·∫£ ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu v√† nghi√™n c·ª©u m√¥ h√¨nh ph·ª©c t·∫°p.  
            """, unsafe_allow_html=True)

            st.subheader("üì∑ Minh h·ªça d·ªØ li·ªáu MNIST")
            st.markdown("""
            D∆∞·ªõi ƒë√¢y l√† ·∫£nh minh h·ªça $10$ ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$ t·ª´ t·∫≠p d·ªØ li·ªáu MNIST ƒë·ªÉ b·∫°n h√¨nh dung. M·ªói ch·ªØ s·ªë ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n $28 \\times 28$ pixel.
            """, unsafe_allow_html=True)
            with st.spinner("ƒêang t·∫£i ·∫£nh minh h·ªça..."):
                try:
                    mnist_image = Image.open("mnist.png")
                    st.image(mnist_image, caption="·∫¢nh minh h·ªça $10$ ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$ trong MNIST", width=800)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y file `mnist.png`. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

        elif info_option == "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o":
            st.subheader("üìä 3. Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o")
            st.markdown("""
            **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o)** l√† m·ªôt m√¥ h√¨nh h·ªçc m√°y m√¥ ph·ªèng c√°ch ho·∫°t ƒë·ªông c·ªßa m·∫°ng n∆°-ron sinh h·ªçc trong n√£o ng∆∞·ªùi.  
            - **C·∫•u tr√∫c**: G·ªìm c√°c **n∆°-ron nh√¢n t·∫°o** (nodes) ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh c√°c **l·ªõp (layers)**:  
              - **L·ªõp ƒë·∫ßu v√†o (Input Layer)**: Nh·∫≠n d·ªØ li·ªáu ($784$ pixel t·ª´ ·∫£nh MNIST).  
              - **L·ªõp ·∫©n (Hidden Layers)**: X·ª≠ l√Ω th√¥ng tin b·∫±ng c√°ch k·∫øt h·ª£p tuy·∫øn t√≠nh v√† √°p d·ª•ng h√†m k√≠ch ho·∫°t phi tuy·∫øn.  
              - **L·ªõp ƒë·∫ßu ra (Output Layer)**: ƒê∆∞a ra d·ª± ƒëo√°n (nh√£n t·ª´ $0$-$9$).  

            Neural Network ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ v·ªõi b√†i to√°n MNIST nh·ªù kh·∫£ nƒÉng h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu h√¨nh ·∫£nh.
            """, unsafe_allow_html=True)

            st.subheader("üõ†Ô∏è C√°c b∆∞·ªõc th·ª±c hi·ªán trong Neural Network")
            st.markdown("""
            1. **Kh·ªüi t·∫°o m√¥ h√¨nh**:  
               - X√°c ƒë·ªãnh c·∫•u tr√∫c m·∫°ng (s·ªë l·ªõp ·∫©n, s·ªë n∆°-ron m·ªói l·ªõp).  
               - Kh·ªüi t·∫°o **tr·ªçng s·ªë** $W$ v√† **bias** $b$ ng·∫´u nhi√™n ho·∫∑c b·∫±ng $0$.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step1_init.png"), caption="Minh h·ªça B∆∞·ªõc 1: Kh·ªüi t·∫°o m√¥ h√¨nh", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 1. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            2. **Lan truy·ªÅn thu·∫≠n (Feedforward)**:  
               - T√≠nh gi√° tr·ªã d·ª± ƒëo√°n $\\hat{Y}$ t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o $X$:  
                 - **L·ªõp ƒë·∫ßu v√†o**: $A^{(0)} = X$ (ma tr·∫≠n $N \\times 784$, $N$ l√† s·ªë m·∫´u).  
                 - **Cho m·ªói l·ªõp $l$**:  
                   - T·ªïng tuy·∫øn t√≠nh:  
                     $$ Z^{(l)} = A^{(l-1)} \\cdot W^{(l)} + b^{(l)} $$  
                   - √Åp d·ª•ng h√†m k√≠ch ho·∫°t:  
                     $$ A^{(l)} = \\sigma(Z^{(l)}) $$  
                 - **L·ªõp ƒë·∫ßu ra**: $\\hat{Y} = A^{(L)}$ (ma tr·∫≠n $N \\times 10$).  
               - V√≠ d·ª• h√†m k√≠ch ho·∫°t **sigmoid**:  
                 $$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step2_feedforward.png"), caption="Minh h·ªça B∆∞·ªõc 2: Lan truy·ªÅn thu·∫≠n", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 2. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            3. **T√≠nh h√†m m·∫•t m√°t (Loss Function)**:  
               - ƒêo ƒë·ªô sai l·ªách gi·ªØa $\\hat{Y}$ v√† $Y$ (gi√° tr·ªã th·ª±c). V·ªõi MNIST, d√πng **Cross-Entropy**:  
                 $$ L = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=0}^{9} y_{ij} \\cdot \\log(\\hat{y}_{ij}) $$  
               - Trong ƒë√≥:  
                 - $y_{ij}$: Nh√£n th·ª±c (d·∫°ng one-hot encoded).  
                 - $\\hat{y}_{ij}$: X√°c su·∫•t d·ª± ƒëo√°n cho l·ªõp $j$.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step3_loss.png"), caption="Minh h·ªça B∆∞·ªõc 3: T√≠nh h√†m m·∫•t m√°t", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 3. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            4. **Lan truy·ªÅn ng∆∞·ª£c (Backpropagation)**:  
               - T√≠nh ƒë·∫°o h√†m c·ªßa $L$ theo $W^{(l)}$ v√† $b^{(l)}$ ƒë·ªÉ c·∫≠p nh·∫≠t tham s·ªë:  
                 - T·∫°i **L·ªõp ƒë·∫ßu ra**:  
                   $$ \\delta^{(L)} = \\hat{Y} - Y $$  
                 - T·∫°i **L·ªõp ·∫©n**:  
                   $$ \\delta^{(l)} = (\\delta^{(l+1)} \\cdot (W^{(l+1)})^T) \\odot \\sigma'(Z^{(l)}) $$  
                   - $\\sigma'(z)$: ƒê·∫°o h√†m h√†m k√≠ch ho·∫°t (v·ªõi sigmoid: $\\sigma'(z) = \\sigma(z) \\cdot (1 - \\sigma(z))$).  
                 - ƒê·∫°o h√†m theo tr·ªçng s·ªë v√† bias:  
                   $$ \\frac{\\partial L}{\\partial W^{(l)}} = (A^{(l-1)})^T \\cdot \\delta^{(l)} $$  
                   $$ \\frac{\\partial L}{\\partial b^{(l)}} = \\sum_{i=1}^{N} \\delta^{(l)}_i $$
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step4_backprop.png"), caption="Minh h·ªça B∆∞·ªõc 4: Lan truy·ªÅn ng∆∞·ª£c", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 4. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            5. **C·∫≠p nh·∫≠t tham s·ªë (Gradient Descent)**:  
               - ƒêi·ªÅu ch·ªânh $W$ v√† $b$ ƒë·ªÉ gi·∫£m m·∫•t m√°t:  
                 $$ W^{(l)} = W^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial W^{(l)}} $$  
                 $$ b^{(l)} = b^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial b^{(l)}} $$  
               - Trong ƒë√≥: $\\eta$ l√† **t·ªëc ƒë·ªô h·ªçc (learning rate)**.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step5_gradient.png"), caption="Minh h·ªça B∆∞·ªõc 5: C·∫≠p nh·∫≠t tham s·ªë", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 5. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            6. **L·∫∑p l·∫°i**:  
               - Quay l·∫°i b∆∞·ªõc $2$ qua nhi·ªÅu **epoch** cho ƒë·∫øn khi $L$ h·ªôi t·ª•.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step6_repeat_improved.png"), caption="Minh h·ªça B∆∞·ªõc 6: L·∫∑p l·∫°i", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 6. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.subheader("‚öôÔ∏è C√°c tham s·ªë c∆° b·∫£n v√† c√¥ng d·ª•ng")
            st.markdown("""
            D∆∞·ªõi ƒë√¢y l√† c√°c tham s·ªë b·∫°n s·∫Ω s·ª≠ d·ª•ng ƒë·ªÉ ƒëi·ªÅu ch·ªânh m√¥ h√¨nh trong ·ª©ng d·ª•ng n√†y:  
            - **hidden_layer_sizes**:  
              - **√ù nghƒ©a**: S·ªë n∆°-ron trong l·ªõp ·∫©n (v√≠ d·ª•: $128$).  
              - **C√¥ng d·ª•ng**: Quy·∫øt ƒë·ªãnh s·ª©c m·∫°nh c·ªßa m√¥ h√¨nh; nhi·ªÅu n∆°-ron h∆°n th√¨ h·ªçc ƒë∆∞·ª£c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p h∆°n nh∆∞ng t·ªën th·ªùi gian h∆°n.  
            - **learning_rate_init**:  
              - **√ù nghƒ©a**: T·ªëc ƒë·ªô h·ªçc ban ƒë·∫ßu (v√≠ d·ª•: $0.001$).  
              - **C√¥ng d·ª•ng**: ƒêi·ªÅu ch·ªânh t·ªëc ƒë·ªô c·∫≠p nh·∫≠t tr·ªçng s·ªë; nh·ªè h∆°n th√¨ h·ªçc ch·∫≠m nh∆∞ng ·ªïn ƒë·ªãnh h∆°n.  
            - **max_iter**:  
              - **√ù nghƒ©a**: S·ªë l·∫ßn hu·∫•n luy·ªán t·ªëi ƒëa (v√≠ d·ª•: $200$).  
              - **C√¥ng d·ª•ng**: Gi·ªõi h·∫°n s·ªë l·∫ßn m√¥ h√¨nh h·ªçc qua d·ªØ li·ªáu ƒë·ªÉ ƒë·∫°t ƒë·ªô ch√≠nh x√°c mong mu·ªën.  
            """, unsafe_allow_html=True)

            st.subheader("üü™ ∆Øu ƒëi·ªÉm v√† nh∆∞·ª£c ƒëi·ªÉm")
            st.markdown("""
            ##### ‚úÖ **∆Øu ƒëi·ªÉm**:  
            - H·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu h√¨nh ·∫£nh nh∆∞ MNIST.  
            - D·ªÖ s·ª≠ d·ª•ng v·ªõi c√°c tham s·ªë c∆° b·∫£n ƒë∆∞·ª£c t·ªëi ∆∞u s·∫µn.  

            ##### ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**:  
            - T·ªën th·ªùi gian hu·∫•n luy·ªán n·∫øu s·ªë m·∫´u l·ªõn ho·∫∑c s·ªë n∆°-ron nhi·ªÅu.  
            - C·∫ßn d·ªØ li·ªáu ƒë∆∞·ª£c chu·∫©n h√≥a ƒë·ªÉ ƒë·∫°t hi·ªáu qu·∫£ t·ªët nh·∫•t.  
            """, unsafe_allow_html=True)

        elif info_option == "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)":
            st.subheader("üìò 4. C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)")
            st.markdown("""
            ƒê·ªô ch√≠nh x√°c (**Accuracy**) ƒëo t·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng:  
            $$ \\text{Accuracy} = \\frac{\\text{S·ªë m·∫´u d·ª± ƒëo√°n ƒë√∫ng}}{\\text{T·ªïng s·ªë m·∫´u}} $$  
            - **V√≠ d·ª•**: D·ª± ƒëo√°n ƒë√∫ng $92/100$ ·∫£nh ‚Üí $\\text{Accuracy} = 92\\%$.  
            - **√ù nghƒ©a**: V·ªõi Neural Network, Accuracy ƒëo kh·∫£ nƒÉng m√¥ h√¨nh ph√¢n lo·∫°i ƒë√∫ng c√°c ch·ªØ s·ªë d·ª±a tr√™n ƒë·∫∑c tr∆∞ng pixel h·ªçc ƒë∆∞·ª£c.  
            """, unsafe_allow_html=True)

    # Tab 2: T·∫£i d·ªØ li·ªáu
    with tab_load:
        st.header("T·∫£i D·ªØ li·ªáu MNIST")
        st.markdown("""
        Ph·∫ßn n√†y cho ph√©p t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML v√† ch·ªçn s·ªë l∆∞·ª£ng m·∫´u ƒë·ªÉ x·ª≠ l√Ω. T·ªïng c·ªông c√≥ $70,000$ m·∫´u, b·∫°n c√≥ th·ªÉ ch·ªçn m·ªôt ph·∫ßn nh·ªè h∆°n ƒë·ªÉ gi·∫£m th·ªùi gian t√≠nh to√°n.
        """, unsafe_allow_html=True)

        if st.button("T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML"):
            with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ OpenML..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                try:
                    mnist = openml.datasets.get_dataset(554)
                    progress_bar.progress(20)
                    status_text.text("ƒê√£ t·∫£i 20% - ƒêang l·∫•y d·ªØ li·ªáu...")

                    X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute)
                    progress_bar.progress(50)
                    status_text.text("ƒê√£ t·∫£i 50% - ƒêang x·ª≠ l√Ω d·ªØ li·ªáu...")

                    st.session_state['full_data'] = (X, y)
                    progress_bar.progress(90)
                    status_text.text(f"ƒê√£ t·∫£i 90% - Ho√†n t·∫•t {X.shape[0]} m·∫´u...")

                    with mlflow.start_run(run_name="Data_Load"):
                        mlflow.log_param("total_samples", X.shape[0])

                    progress_bar.progress(100)
                    status_text.text("ƒê√£ t·∫£i 100% - Ho√†n t·∫•t!")
                    time.sleep(1)
                    status_text.empty()
                    progress_bar.empty()
                    st.success("T·∫£i d·ªØ li·ªáu th√†nh c√¥ng!")
                    st.write("K√≠ch th∆∞·ªõc d·ªØ li·ªáu g·ªëc:", X.shape)
                except Exception as e:
                    st.error(f"Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu: {e}")

        if 'full_data' in st.session_state:
            X_full, y_full = st.session_state['full_data']
            num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u:", 
                                    min_value=10, max_value=len(X_full), value=min(1000, len(X_full)), step=1)
            if st.button("X√°c nh·∫≠n s·ªë l∆∞·ª£ng m·∫´u"):
                with st.spinner(f"ƒêang x·ª≠ l√Ω {num_samples} m·∫´u..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    df = pd.concat([X_full, y_full.rename("label")], axis=1)
                    progress_bar.progress(30)
                    status_text.text("ƒêang x·ª≠ l√Ω 30% - ƒêang k·∫øt h·ª£p d·ªØ li·ªáu...")

                    sampled_df = df.sample(n=num_samples, random_state=42)
                    progress_bar.progress(70)
                    status_text.text("ƒêang x·ª≠ l√Ω 70% - ƒêang l·∫•y m·∫´u ng·∫´u nhi√™n...")

                    X_sampled = sampled_df.drop(columns=["label"])
                    y_sampled = sampled_df["label"]
                    st.session_state['data'] = (X_sampled, y_sampled)
                    progress_bar.progress(90)
                    status_text.text("ƒêang x·ª≠ l√Ω 90% - ƒêang l∆∞u tr·ªØ d·ªØ li·ªáu...")

                    with mlflow.start_run(run_name="Data_Sample"):
                        mlflow.log_param("num_samples", num_samples)

                    progress_bar.progress(100)
                    status_text.text("ƒê√£ x·ª≠ l√Ω 100% - Ho√†n t·∫•t!")
                    time.sleep(1)
                    status_text.empty()
                    progress_bar.empty()
                    st.success(f"ƒê√£ ch·ªçn {num_samples} m·∫´u ƒë·ªÉ x·ª≠ l√Ω!")

    # Tab 3: X·ª≠ l√Ω d·ªØ li·ªáu
    with tab_preprocess:
        st.header("X·ª≠ l√Ω D·ªØ li·ªáu")
        st.markdown("""
        Ph·∫ßn n√†y cho ph√©p b·∫°n chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa Neural Network.
        """, unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui l√≤ng t·∫£i d·ªØ li·ªáu t·ª´ tab 'T·∫£i d·ªØ li·ªáu' tr∆∞·ªõc khi x·ª≠ l√Ω.")
        else:
            X, y = st.session_state['data']
            if "data_original" not in st.session_state:
                st.session_state["data_original"] = (X.copy(), y.copy())

            st.subheader("üì∑ D·ªØ li·ªáu G·ªëc")
            st.markdown("""
            D∆∞·ªõi ƒë√¢y l√† $10$ m·∫´u ƒë·∫ßu ti√™n t·ª´ d·ªØ li·ªáu g·ªëc ƒë·ªÉ b·∫°n h√¨nh dung:
            """, unsafe_allow_html=True)
            fig, axes = plt.subplots(2, 5, figsize=(10, 4))
            for i, ax in enumerate(axes.flat):
                ax.imshow(X.iloc[i].values.reshape(28, 28), cmap='gray')
                ax.set_title(f"Nh√£n: {y.iloc[i]}")
                ax.axis("off")
            st.pyplot(fig)

            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("Chu·∫©n h√≥a (Normalization)", key="normalize_btn"):
                    X_norm = X / 255.0
                    st.session_state["data_processed"] = (X_norm, y)
                    st.success("ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu!")
                    st.rerun()
            with col2:
                st.markdown("""
                **Chu·∫©n h√≥a**:  
                ƒê∆∞a gi√° tr·ªã pixel v·ªÅ kho·∫£ng $[0, 1]$ b·∫±ng c√°ch chia cho $255$.  
                - **C√¥ng d·ª•ng**: ƒê·∫£m b·∫£o thang ƒëo ƒë·ªìng nh·∫•t, gi√∫p Neural Network h·ªçc t·ªët h∆°n.
                """, unsafe_allow_html=True)

            if "data_processed" in st.session_state:
                X_processed, y_processed = st.session_state["data_processed"]
                st.subheader("üì∑ D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω")
                st.markdown("""
                D∆∞·ªõi ƒë√¢y l√† $10$ m·∫´u ƒë·∫ßu ti√™n sau khi chu·∫©n h√≥a:
                """, unsafe_allow_html=True)
                fig, axes = plt.subplots(2, 5, figsize=(10, 4))
                for i, ax in enumerate(axes.flat):
                    ax.imshow(X_processed.iloc[i].values.reshape(28, 28), cmap='gray')
                    ax.set_title(f"Nh√£n: {y_processed.iloc[i]}")
                    ax.axis("off")
                st.pyplot(fig)

    # Tab 4: Chia d·ªØ li·ªáu
    with tab_split:
        st.header("Chia T·∫≠p D·ªØ li·ªáu")
        st.markdown("""
        Ph·∫ßn n√†y gi√∫p b·∫°n chia d·ªØ li·ªáu th√†nh c√°c t·∫≠p hu·∫•n luy·ªán (Train), ki·ªÉm ƒë·ªãnh (Validation), v√† ki·ªÉm tra (Test).
        """, unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui l√≤ng t·∫£i v√† ch·ªët s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc.")
        else:
            data_source = st.session_state.get("data_processed", st.session_state['data'])
            X, y = data_source
            total_samples = len(X)
            st.write(f"T·ªïng s·ªë m·∫´u: ${total_samples}$")

            test_pct = st.slider("T·ª∑ l·ªá t·∫≠p Test (%)", 0, 100, 20)
            valid_pct = st.slider("T·ª∑ l·ªá t·∫≠p Validation (%) t·ª´ ph·∫ßn c√≤n l·∫°i", 0, 100, 20)
            
            if test_pct + valid_pct > 100:
                st.warning("T·ªïng t·ª∑ l·ªá Test v√† Validation v∆∞·ª£t qu√° $100\\%$!")
            
            test_size = int(total_samples * test_pct / 100)
            if test_size > 0:
                X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size / total_samples, random_state=42)
            else:
                X_temp, y_temp = X, y
                X_test, y_test = pd.DataFrame(), pd.Series()

            valid_size = int(len(X_temp) * valid_pct / 100)
            if valid_size > 0 and len(X_temp) > valid_size:
                X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=valid_size / len(X_temp), random_state=42)
            else:
                X_train, y_train = X_temp, y_temp
                X_valid, y_valid = pd.DataFrame(), pd.Series()

            st.write(f"Train: ${len(X_train)}$ m·∫´u, Validation: ${len(X_valid)}$ m·∫´u, Test: ${len(X_test)}$ m·∫´u")
            if st.button("X√°c nh·∫≠n chia d·ªØ li·ªáu"):
                st.session_state['split_data'] = {
                    "X_train": X_train, "y_train": y_train,
                    "X_valid": X_valid, "y_valid": y_valid,
                    "X_test": X_test, "y_test": y_test
                }
                st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia!")

    # Tab 5: Hu·∫•n luy·ªán/ƒê√°nh gi√°
    with tab_train_eval:
        st.header("Hu·∫•n luy·ªán v√† ƒê√°nh gi√°")
        st.markdown("""
        Ph·∫ßn n√†y gi√∫p b·∫°n hu·∫•n luy·ªán m√¥ h√¨nh Neural Network c∆° b·∫£n v√† ki·ªÉm tra ƒë·ªô ch√≠nh x√°c.  
        Ch·ªâ c·∫ßn ch·ªçn v√†i tham s·ªë ƒë∆°n gi·∫£n, c√≤n l·∫°i ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u s·∫µn!
        """, unsafe_allow_html=True)

        if 'split_data' not in st.session_state:
            st.info("Vui l√≤ng chia d·ªØ li·ªáu t·ª´ tab 'Chia d·ªØ li·ªáu' tr∆∞·ªõc.")
        else:
            X_train = st.session_state['split_data']["X_train"]
            num_samples = len(X_train)
            st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: ${num_samples}$")

            st.subheader("‚öôÔ∏è Thi·∫øt l·∫≠p m√¥ h√¨nh ƒë∆°n gi·∫£n")
            st.markdown("""
            B·∫°n ch·ªâ c·∫ßn ch·ªçn 3 tham s·ªë c∆° b·∫£n. C√°c c√†i ƒë·∫∑t kh√°c ƒë√£ ƒë∆∞·ª£c t·ª± ƒë·ªông t·ªëi ∆∞u cho b√†i to√°n MNIST!
            """, unsafe_allow_html=True)

            # G·ª£i √Ω tham s·ªë d·ª±a tr√™n s·ªë m·∫´u
            if num_samples < 1000:
                default_hidden_size = 64
                default_max_iter = 100
                default_lr = 0.01
            elif 1000 <= num_samples <= 5000:
                default_hidden_size = 128
                default_max_iter = 200
                default_lr = 0.001
            else:
                default_hidden_size = 256
                default_max_iter = 300
                default_lr = 0.001

            # Ng∆∞·ªùi d√πng nh·∫≠p tham s·ªë
            hidden_size = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n", min_value=10, max_value=500, value=default_hidden_size, step=10,
                                          help="S·ªë n∆°-ron c√†ng l·ªõn, m√¥ h√¨nh c√†ng m·∫°nh nh∆∞ng t·ªën th·ªùi gian h∆°n.")
            max_iter = st.number_input("S·ªë l·∫ßn hu·∫•n luy·ªán t·ªëi ƒëa", min_value=50, max_value=500, value=default_max_iter, step=10,
                                       help="S·ªë l·∫ßn m√¥ h√¨nh h·ªçc qua d·ªØ li·ªáu. Nhi·ªÅu h∆°n th√¨ ch√≠nh x√°c h∆°n nh∆∞ng l√¢u h∆°n.")
            lr = st.selectbox("T·ªëc ƒë·ªô h·ªçc", [0.01, 0.001, 0.0001], index=[0.01, 0.001, 0.0001].index(default_lr),
                              help="T·ªëc ƒë·ªô h·ªçc c√†ng nh·ªè th√¨ m√¥ h√¨nh h·ªçc ch·∫≠m nh∆∞ng ·ªïn ƒë·ªãnh h∆°n.")

            # N√∫t hu·∫•n luy·ªán
            if st.button("B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán"):
                with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    start_time = time.time()

                    X_train = st.session_state['split_data']["X_train"]
                    y_train = st.session_state['split_data']["y_train"]
                    X_valid = st.session_state['split_data']["X_valid"]
                    y_valid = st.session_state['split_data']["y_valid"]
                    X_test = st.session_state['split_data']["X_test"]
                    y_test = st.session_state['split_data']["y_test"]

                    # ƒê·ªãnh nghƒ©a m√¥ h√¨nh v·ªõi tham s·ªë m·∫∑c ƒë·ªãnh
                    pipeline = Pipeline([
                        ('imputer', SimpleImputer(strategy='mean')),
                        ('classifier', MLPClassifier(
                            hidden_layer_sizes=(hidden_size,),  # Ch·ªâ 1 l·ªõp ·∫©n
                            activation='relu',                  # M·∫∑c ƒë·ªãnh
                            solver='adam',                      # M·∫∑c ƒë·ªãnh
                            learning_rate_init=lr,
                            max_iter=max_iter
                        ))
                    ])

                    # Hu·∫•n luy·ªán
                    pipeline.fit(X_train, y_train)
                    model = pipeline

                    # Ghi log v·ªõi MLflow
                    run_name = f"SimpleNN_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    with mlflow.start_run(run_name=run_name) as run:
                        mlflow.log_param("hidden_size", hidden_size)
                        mlflow.log_param("max_iter", max_iter)
                        mlflow.log_param("learning_rate", lr)

                        # D·ª± ƒëo√°n v√† ƒë√°nh gi√°
                        y_valid_pred = model.predict(X_valid)
                        accuracy_val = accuracy_score(y_valid, y_valid_pred)
                        mlflow.log_metric("accuracy_val", accuracy_val)
                        cm_valid = confusion_matrix(y_valid, y_valid_pred)

                        y_test_pred = model.predict(X_test)
                        accuracy_test = accuracy_score(y_test, y_test_pred)
                        mlflow.log_metric("accuracy_test", accuracy_test)
                        cm_test = confusion_matrix(y_test, y_test_pred)

                        training_time = time.time() - start_time
                        mlflow.log_metric("training_time_seconds", training_time)
                        mlflow.sklearn.log_model(model, "model")

                        run_id = run.info.run_id
                        st.session_state['model'] = model
                        st.session_state['training_results'] = {
                            'training_time': training_time,
                            'accuracy_val': accuracy_val,
                            'accuracy_test': accuracy_test,
                            'cm_valid': cm_valid,
                            'cm_test': cm_test,
                            'run_name': run_name,
                            'run_id': run_id
                        }

                    progress_bar.progress(100)
                    status_text.text("Ho√†n t·∫•t!")
                    time.sleep(1)
                    status_text.empty()
                    progress_bar.empty()

            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            if 'training_results' in st.session_state:
                st.success(f"Hu·∫•n luy·ªán ho√†n t·∫•t! Th·ªùi gian: ${st.session_state['training_results']['training_time']:.2f}$ gi√¢y.")
                st.write(f"ƒê·ªô ch√≠nh x√°c Validation: ${st.session_state['training_results']['accuracy_val']:.4f}$")
                st.write(f"ƒê·ªô ch√≠nh x√°c Test: ${st.session_state['training_results']['accuracy_test']:.4f}$")

                st.subheader("üìä Ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix)")
                fig, ax = plt.subplots()
                sns.heatmap(st.session_state['training_results']['cm_valid'], annot=True, fmt="d", cmap="Blues", ax=ax)
                ax.set_title("Ma tr·∫≠n nh·∫ßm l·∫´n - Validation")
                st.pyplot(fig)

                fig, ax = plt.subplots()
                sns.heatmap(st.session_state['training_results']['cm_test'], annot=True, fmt="d", cmap="Blues", ax=ax)
                ax.set_title("Ma tr·∫≠n nh·∫ßm l·∫´n - Test")
                st.pyplot(fig)

    # Tab 6: Demo d·ª± ƒëo√°n
    with tab_demo:
        st.header("Demo D·ª± ƒëo√°n")
        st.markdown("""
        Ph·∫ßn n√†y cho ph√©p b·∫°n th·ª≠ nghi·ªám d·ª± ƒëo√°n v·ªõi d·ªØ li·ªáu Test, ·∫£nh upload, ho·∫∑c s·ªë b·∫°n v·∫Ω.
        """, unsafe_allow_html=True)

        if 'split_data' not in st.session_state or 'model' not in st.session_state:
            st.info("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
        else:
            mode = st.radio("Ch·ªçn ph∆∞∆°ng th·ª©c d·ª± ƒëo√°n:", ["D·ªØ li·ªáu t·ª´ Test", "Upload ·∫£nh m·ªõi", "V·∫Ω s·ªë"])
            
            def preprocess_input(data):
                return data / 255.0

            is_normalized = "data_processed" in st.session_state

            if mode == "D·ªØ li·ªáu t·ª´ Test":
                X_test = st.session_state['split_data']["X_test"]
                y_test = st.session_state['split_data']["y_test"]
                idx = st.slider("Ch·ªçn m·∫´u t·ª´ Test", 0, len(X_test)-1, 0)
                if st.button("D·ª± ƒëo√°n"):
                    with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                        sample = X_test.iloc[idx].values.reshape(1, -1)
                        if not is_normalized:
                            sample = preprocess_input(sample)
                        
                        prediction = st.session_state['model'].predict(sample)[0]
                        proba = st.session_state['model'].predict_proba(sample)[0]
                        confidence = max(proba) * 100
                        y_true = y_test.iloc[idx]
                        
                        st.success(f"D·ª± ƒëo√°n: **${prediction}$** | ƒê·ªô tin c·∫≠y: **${confidence:.2f}\\%$** | Gi√° tr·ªã th·ª±c: **${y_true}$**")
                        fig, ax = plt.subplots()
                        ax.imshow(X_test.iloc[idx].values.reshape(28, 28), cmap='gray')
                        ax.axis("off")
                        st.pyplot(fig)

            elif mode == "Upload ·∫£nh m·ªõi":
                uploaded_images = st.file_uploader("Upload ·∫£nh ($28\\times28$, grayscale)", type=["png", "jpg"], accept_multiple_files=True)
                if uploaded_images:
                    for i, uploaded_image in enumerate(uploaded_images):
                        with st.spinner(f"ƒêang x·ª≠ l√Ω ·∫£nh {i+1}/{len(uploaded_images)}..."):
                            img = Image.open(uploaded_image).convert('L').resize((28, 28))
                            img_array = np.array(img).flatten().reshape(1, -1)
                            if not is_normalized:
                                img_array = preprocess_input(img_array)
                            
                            prediction = st.session_state['model'].predict(img_array)[0]
                            proba = st.session_state['model'].predict_proba(img_array)[0]
                            confidence = max(proba) * 100
                            
                            st.success(f"D·ª± ƒëo√°n: **${prediction}$** | ƒê·ªô tin c·∫≠y: **${confidence:.2f}\\%$**")
                            st.image(img, caption=f"·∫¢nh {i+1} ƒë∆∞·ª£c upload", use_container_width=True)

            elif mode == "V·∫Ω s·ªë":
                st.write("V·∫Ω m·ªôt ch·ªØ s·ªë t·ª´ $0$-$9$ tr√™n canvas b√™n d∆∞·ªõi ($28\\times28$ pixel):")
                canvas_result = st_canvas(
                    fill_color="black",
                    stroke_width=20,
                    stroke_color="white",
                    background_color="black",
                    width=280,
                    height=280,
                    drawing_mode="freedraw",
                    key="canvas"
                )
                if st.button("D·ª± ƒëo√°n s·ªë ƒë√£ v·∫Ω"):
                    if canvas_result.image_data is not None:
                        with st.spinner("ƒêang x·ª≠ l√Ω v·∫Ω..."):
                            img = Image.fromarray((canvas_result.image_data * 255).astype(np.uint8)).convert('L').resize((28, 28))
                            img_array = np.array(img).flatten().reshape(1, -1)
                            if not is_normalized:
                                img_array = preprocess_input(img_array)
                            
                            prediction = st.session_state['model'].predict(img_array)[0]
                            proba = st.session_state['model'].predict_proba(img_array)[0]
                            confidence = max(proba) * 100
                            
                            st.success(f"D·ª± ƒëo√°n: **${prediction}$** | ƒê·ªô tin c·∫≠y: **${confidence:.2f}\\%$**")
                    else:
                        st.warning("Vui l√≤ng v·∫Ω m·ªôt ch·ªØ s·ªë tr∆∞·ªõc khi d·ª± ƒëo√°n!")

    # Tab 7: Th√¥ng tin hu·∫•n luy·ªán
    with tab_log_info:
        st.header("Theo d√µi k·∫øt qu·∫£")
        st.markdown("""
        Tab n√†y cho ph√©p b·∫°n xem danh s√°ch c√°c l·∫ßn hu·∫•n luy·ªán ƒë√£ th·ª±c hi·ªán v√† chi ti·∫øt t·ª´ng l·∫ßn ch·∫°y.
        """, unsafe_allow_html=True)

        try:
            client = MlflowClient()
            experiment = client.get_experiment_by_name("Neural Network ")
            if not experiment:
                st.error("Kh√¥ng t√¨m th·∫•y experiment 'Neural Network '.")
            else:
                runs = client.search_runs(experiment_ids=[experiment.experiment_id], order_by=["attributes.start_time DESC"])
                if not runs:
                    st.info("Ch∆∞a c√≥ l·∫ßn ch·∫°y n√†o ƒë∆∞·ª£c ghi nh·∫≠n.")
                else:
                    run_options = {run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") for run in runs}
                    selected_run_name = st.selectbox("Ch·ªçn run:", list(run_options.values()))
                    selected_run_id = [k for k, v in run_options.items() if v == selected_run_name][0]
                    selected_run = client.get_run(selected_run_id)

                    st.subheader("üìò Th√¥ng tin chi ti·∫øt")
                    st.write(f"**T√™n l·∫ßn ch·∫°y:** {selected_run_name}")
                    st.write(f"**ID l·∫ßn ch·∫°y:** {selected_run_id}")
                    st.write(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** {datetime.fromtimestamp(selected_run.info.start_time / 1000)}")
                    st.markdown("**Tham s·ªë:**", unsafe_allow_html=True)
                    st.json(selected_run.data.params, expanded=True)
                    st.markdown("**K·∫øt qu·∫£:**", unsafe_allow_html=True)
                    st.json(selected_run.data.metrics, expanded=True)

        except Exception as e:
            st.error(f"L·ªói k·∫øt n·ªëi MLflow: {e}")

if __name__ == "__main__":
    run_mnist_neural_network_app()