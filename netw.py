import streamlit as st
import os
import numpy as np
import pandas as pd
import random
import struct
from scipy.interpolate import UnivariateSpline
import plotly.graph_objects as go
from sklearn.decomposition import PCA
import mlflow
import time 
from PIL import Image
from sklearn.metrics import silhouette_score, silhouette_samples, davies_bouldin_score
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import pairwise_distances
from sklearn.manifold import TSNE
from sklearn.neural_network import MLPClassifier
import networkx as nx
import plotly.express as px
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
from streamlit_drawable_canvas import st_canvas
from sklearn.datasets import make_classification
from mlflow.tracking import MlflowClient
from netw import run_mnist_neural_network_app

def run_NeuralNetwork_app():
    @st.cache_data
    def get_sampled_pixels(images, sample_size=100_000):
        return np.random.choice(images.flatten(), sample_size, replace=False)

    @st.cache_data
    def get_random_indices(num_images, total_images):
        return np.random.randint(0, total_images, size=num_images)

    # ƒê·ªãnh nghƒ©a h√†m ƒë·ªÉ ƒë·ªçc file .idx t·ª´ c·ª•c b·ªô
    def load_mnist_images(filename):
        with open(filename, 'rb') as f:
            magic, num, rows, cols = struct.unpack('>IIII', f.read(16))
            images = np.fromfile(f, dtype=np.uint8).reshape(num, rows, cols)
        return images

    def load_mnist_labels(filename):
        with open(filename, 'rb') as f:
            magic, num = struct.unpack('>II', f.read(8))
            labels = np.fromfile(f, dtype=np.uint8)
        return labels

    # ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu (c·∫≠p nh·∫≠t ƒë·ªÉ tr·ªè ƒë·∫øn th∆∞ m·ª•c dulieuminst)
    dataset_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "dulieuminst")
    train_images_path = os.path.join(dataset_path, "train-images.idx3-ubyte")
    train_labels_path = os.path.join(dataset_path, "train-labels.idx1-ubyte")
    test_images_path = os.path.join(dataset_path, "t10k-images.idx3-ubyte")
    test_labels_path = os.path.join(dataset_path, "t10k-labels.idx1-ubyte")

    # T·∫£i d·ªØ li·ªáu MNIST t·ª´ c·ª•c b·ªô
    try:
        train_images = load_mnist_images(train_images_path)
        train_labels = load_mnist_labels(train_labels_path)
        test_images = load_mnist_images(test_images_path)
        test_labels = load_mnist_labels(test_labels_path)

        st.session_state.train_images = train_images
        st.session_state.train_labels = train_labels
        st.session_state.test_images = test_images
        st.session_state.test_labels = test_labels
    except FileNotFoundError as e:
        st.error(f"‚ö†Ô∏è L·ªói: Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu MNIST. Ki·ªÉm tra ƒë∆∞·ªùng d·∫´n: {e}")
        return
    except Exception as e:
        st.error(f"‚ö†Ô∏è L·ªói khi t·∫£i d·ªØ li·ªáu MNIST: {e}")
        return

    # Chu·∫©n b·ªã d·ªØ li·ªáu cho gi·∫£m chi·ªÅu (reshape images th√†nh vector)
    X_train = train_images.reshape(train_images.shape[0], -1)
    X_test = test_images.reshape(test_images.shape[0], -1)
    y_train = train_labels
    y_test = test_labels

    st.session_state.X_train = X_train
    st.session_state.X_test = X_test
    st.session_state.y_train = y_train
    st.session_state.y_test = y_test

    # Giao di·ªán Streamlit
    st.title("üì∏ MNIST Neural Network")
    tabs = st.tabs([
        "Th√¥ng tin",
        "Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu",
        "Ph√¢n chia t·ªâ l·ªá",
        "Hu·∫•n luy·ªán m√¥ h√¨nh",
        "D·ª± ƒëo√°n",
        "Th√¥ng tin & Mlflow",
    ])
    tab_note, tab_data, tab_samples, tab_preprocess, tab_demo, tab_mlflow = tabs

    # Tab "Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu"
    with tab_data:
        st.header("Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu")
        total_train_samples = len(train_images)
        total_test_samples = len(test_images)

        # G·ª£i √Ω c√°c m·ª©c ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu
        st.markdown("### G·ª£i √Ω ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu")
        st.markdown("""
        - **1000 m·∫´u**: Hu·∫•n luy·ªán nhanh (v√†i gi√¢y), nh∆∞ng ƒë·ªô ch√≠nh x√°c th·∫•p.
        - **10000 m·∫´u**: Th·ªùi gian hu·∫•n luy·ªán trung b√¨nh (v√†i ph√∫t), ƒë·ªô ch√≠nh x√°c kh√°.
        - **50000 m·∫´u**: Th·ªùi gian hu·∫•n luy·ªán l√¢u (10-20 ph√∫t), nh∆∞ng ƒë·ªô ch√≠nh x√°c cao.
        - **To√†n b·ªô (70000 m·∫´u)**: Th·ªùi gian hu·∫•n luy·ªán r·∫•t l√¢u, ƒë·ªô ch√≠nh x√°c t·ªëi ∆∞u.
        """)

        # Ng∆∞·ªùi d√πng ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu hu·∫•n luy·ªán
        num_train_samples = st.selectbox(
            "Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu hu·∫•n luy·ªán",
            options=[1000, 10000, 50000, total_train_samples],
            format_func=lambda x: f"{x} m·∫´u",
            index=3  # M·∫∑c ƒë·ªãnh l√† to√†n b·ªô d·ªØ li·ªáu
        )

        # Ng∆∞·ªùi d√πng ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu ki·ªÉm tra
        num_test_samples = st.selectbox(
            "Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu ki·ªÉm tra",
            options=[100, 1000, 5000, total_test_samples],
            format_func=lambda x: f"{x} m·∫´u",
            index=3  # M·∫∑c ƒë·ªãnh l√† to√†n b·ªô d·ªØ li·ªáu
        )

        # C·∫≠p nh·∫≠t d·ªØ li·ªáu theo s·ªë l∆∞·ª£ng ƒë∆∞·ª£c ch·ªçn
        st.session_state.train_images = train_images[:num_train_samples]
        st.session_state.train_labels = train_labels[:num_train_samples]
        st.session_state.test_images = test_images[:num_test_samples]
        st.session_state.test_labels = test_labels[:num_test_samples]

        st.session_state.X_train = X_train[:num_train_samples]
        st.session_state.X_test = X_test[:num_test_samples]
        st.session_state.y_train = y_train[:num_train_samples]
        st.session_state.y_test = y_test[:num_test_samples]

        st.write(f"ƒê√£ ch·ªçn {num_train_samples} m·∫´u hu·∫•n luy·ªán v√† {num_test_samples} m·∫´u ki·ªÉm tra.")

    # Tab "Th√¥ng tin"
    with tab_note:
        with st.expander("**Th√¥ng tin m√¥ h√¨nh**", expanded=True):
            st.markdown("## üîπ Neural Network (M·∫°ng N∆°-ron Nh√¢n t·∫°o)")
            st.markdown("---")
            st.markdown("### Kh√°i ni·ªám Neural Network")
            st.markdown(
                """
                - **Neural Network (M·∫°ng N∆°-ron Nh√¢n t·∫°o)** l√† m·ªôt m√¥ h√¨nh h·ªçc m√°y ƒë∆∞·ª£c l·∫•y c·∫£m h·ª©ng t·ª´ c·∫•u tr√∫c c·ªßa m·∫°ng n∆°-ron sinh h·ªçc trong n√£o ng∆∞·ªùi.  
                - N√≥ bao g·ªìm c√°c **n∆°-ron** (nodes) ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh **l·ªõp** (layers): l·ªõp ƒë·∫ßu v√†o (input layer), c√°c l·ªõp ·∫©n (hidden layers), v√† l·ªõp ƒë·∫ßu ra (output layer).  
                - Neural Network ƒë·∫∑c bi·ªát m·∫°nh trong vi·ªác x·ª≠ l√Ω c√°c b√†i to√°n phi tuy·∫øn t√≠nh v√† h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu.
                """
            )
            st.image("image1.png", caption="C·∫•u tr√∫c Neural Network (Ngu·ªìn: https://byvn.net/m3Sf)", use_container_width=True)

            st.markdown("---")
            st.markdown("### C·∫•u tr√∫c Neural Network")
            st.markdown(
                """
                M·∫°ng N∆°-ron Nh√¢n t·∫°o (Neural Network) c√≥ c·∫•u tr√∫c c∆° b·∫£n bao g·ªìm c√°c th√†nh ph·∫ßn ch√≠nh sau:

                1. **L·ªõp ƒë·∫ßu v√†o (Input Layer)**:  
                - ƒê√¢y l√† n∆°i nh·∫≠n d·ªØ li·ªáu th√¥ t·ª´ b√†i to√°n (v√≠ d·ª•: gi√° tr·ªã pixel c·ªßa ·∫£nh, s·ªë li·ªáu th·ªëng k√™, vƒÉn b·∫£n, v.v.).  
                - S·ªë l∆∞·ª£ng n∆°-ron trong l·ªõp n√†y t∆∞∆°ng ·ª©ng v·ªõi s·ªë ƒë·∫∑c tr∆∞ng (features) c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o.

                2. **C√°c l·ªõp ·∫©n (Hidden Layers)**:  
                - L√† c√°c l·ªõp trung gian gi·ªØa l·ªõp ƒë·∫ßu v√†o v√† l·ªõp ƒë·∫ßu ra, n∆°i di·ªÖn ra qu√° tr√¨nh x·ª≠ l√Ω v√† h·ªçc h·ªèi.  
                - M·ªói l·ªõp ·∫©n bao g·ªìm nhi·ªÅu n∆°-ron, v√† s·ªë l∆∞·ª£ng l·ªõp ·∫©n c≈©ng nh∆∞ n∆°-ron trong m·ªói l·ªõp c√≥ th·ªÉ thay ƒë·ªïi t√πy thu·ªôc v√†o ƒë·ªô ph·ª©c t·∫°p c·ªßa b√†i to√°n.  
                - C√°c n∆°-ron trong l·ªõp ·∫©n √°p d·ª•ng **h√†m k√≠ch ho·∫°t (activation function)** nh∆∞ ReLU, Sigmoid ho·∫∑c Tanh ƒë·ªÉ x·ª≠ l√Ω t√≠nh phi tuy·∫øn t√≠nh.
                - **L∆∞u √Ω r·∫±ng:** m·ªôt Neural Network ch·ªâ c√≥ 1 l·ªõp ƒë·∫ßu v√†o v√† 1 l·ªõp ƒë·∫ßu ra nh∆∞ng c√≥ th·ªÉ c√≥ nhi·ªÅu c√°c l·ªõp ·∫©n 
                3. **L·ªõp ƒë·∫ßu ra (Output Layer)**:  
                - L·ªõp n√†y t·∫°o ra k·∫øt qu·∫£ cu·ªëi c√πng c·ªßa m·∫°ng (d·ª± ƒëo√°n ho·∫∑c ph√¢n lo·∫°i).  
                - S·ªë l∆∞·ª£ng n∆°-ron trong l·ªõp ƒë·∫ßu ra ph·ª• thu·ªôc v√†o lo·∫°i b√†i to√°n:  
                    - **Ph√¢n lo·∫°i nh·ªã ph√¢n**: 1 n∆°-ron (v√≠ d·ª•: d√πng h√†m Sigmoid).  
                    - **Ph√¢n lo·∫°i ƒëa l·ªõp**: S·ªë n∆°-ron b·∫±ng s·ªë l·ªõp (v√≠ d·ª•: d√πng h√†m Softmax).  
                    - **H·ªìi quy**: 1 ho·∫∑c nhi·ªÅu n∆°-ron t√πy theo s·ªë l∆∞·ª£ng gi√° tr·ªã c·∫ßn d·ª± ƒëo√°n.
                """
            )
            st.image("image2.png", caption="C·∫•u tr√∫c Neural Network c√≥ 2 ho·∫∑c nhi·ªÅu l·ªõp ·∫©n (Ngu·ªìn: https://byvn.net/m3Sf)", use_container_width=True)

            st.markdown("---")
            st.markdown("### C√°c b∆∞·ªõc hu·∫•n luy·ªán Neural Network")
            st.write("1. **Kh·ªüi t·∫°o m√¥ h√¨nh**: X√°c ƒë·ªãnh s·ªë l·ªõp ·∫©n, s·ªë n∆°-ron trong m·ªói l·ªõp, v√† h√†m k√≠ch ho·∫°t.")
            st.write("2. **Chu·∫©n h√≥a d·ªØ li·ªáu**: ƒê∆∞a d·ªØ li·ªáu v·ªÅ d·∫°ng chu·∫©n ƒë·ªÉ tƒÉng hi·ªáu qu·∫£ hu·∫•n luy·ªán.")
            st.write("3. **Lan truy·ªÅn xu√¥i (Forward Propagation)**: T√≠nh to√°n ƒë·∫ßu ra t·ª´ ƒë·∫ßu v√†o qua c√°c l·ªõp.")
            st.write("4. **Lan truy·ªÅn ng∆∞·ª£c (Backpropagation)**: C·∫≠p nh·∫≠t tr·ªçng s·ªë d·ª±a tr√™n h√†m m·∫•t m√°t.")
            st.write("5. **D·ª± ƒëo√°n**: S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n tr√™n d·ªØ li·ªáu m·ªõi.")
            st.markdown("---")
            st.markdown("### C√°c h√†m k√≠ch ho·∫°t trong Neural Network")
            # H√†m Sigmoid
            st.markdown("**1. H√†m Sigmoid:**")
            st.latex(r"f(x) = \frac{1}{1 + e^{-x}}")
            st.markdown(
                """
                - **Trong ƒë√≥:**
                    - $$e^x$$ v√† $$e^{-x}$$: l√† h√†m m≈© v·ªõi c∆° s·ªë $$e$$ v√† s·ªë m≈© $$x$$ ho·∫∑c $$-x$$
                    - $$( x )$$: Gi√° tr·ªã ƒë·∫ßu v√†o c·ªßa n∆°-ron (t·ªïng c√≥ tr·ªçng s·ªë c·ªông v·ªõi bias).  
                    - $$(( f(x) )$$: ƒê·∫ßu ra c·ªßa h√†m Sigmoid, n·∫±m trong kho·∫£ng $$(((0, 1))$$.  
                """
            )
            st.image("image3.png", caption="Bi·ªÉu ƒë·ªì h√†m Sigmoid (Ngu·ªìn: https://byvn.net/qW4e)", use_container_width=True)

            # H√†m Tanh
            st.markdown("**2. H√†m Hyperbolic Tangent (Tanh):**")
            st.latex(r"f(x) = \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}")
            st.markdown(
                """
                - **Trong ƒë√≥:**
                    - $$( x )$$: Gi√° tr·ªã ƒë·∫ßu v√†o c·ªßa n∆°-ron.  
                    - $$(( f(x) )$$: ƒê·∫ßu ra c·ªßa h√†m Tanh, n·∫±m trong kho·∫£ng $$(((-1 , 1))$$.  
                """
            )
            st.image("image4.png", caption="Bi·ªÉu ƒë·ªì h√†m Hyperbolic Tangent (Tanh) (Ngu·ªìn: https://byvn.net/qW4e)", use_container_width=True)

            # H√†m ReLU
            st.markdown("**3. H√†m ReLU (Rectified Linear Unit):**")
            st.latex(r"f(x) = \max(0, x)")
            st.markdown(
                """
                - **Trong ƒë√≥:**
                    - $$( x )$$: Gi√° tr·ªã ƒë·∫ßu v√†o c·ªßa n∆°-ron.  
                    - $$(( f(x) )$$: ƒê·∫ßu ra c·ªßa h√†m ReLU, b·∫±ng 0 n·∫øu $$( x < 0 )$$, b·∫±ng $$( x )$$ n·∫øu $$( x \geq 0 )$$.  
                """
            )
            st.image("image5.png", caption="Bi·ªÉu ƒë·ªì h√†m ReLU (Rectified Linear Unit) (Ngu·ªìn: https://byvn.net/qW4e)", use_container_width=True)

            # H√†m Softmax
            st.markdown("**4. H√†m Softmax:**")
            st.latex(r"f(x_i) = \frac{e^{z_i}}{\sum_{j=1}^{N} e^{z_j}}")
            st.markdown(
                """
                - **Trong ƒë√≥:**
                    - $$( x_i )$$: Gi√° tr·ªã ƒë·∫ßu v√†o c·ªßa n∆°-ron th·ª© $$( i )$$.  
                    - $$( N )$$: S·ªë l∆∞·ª£ng n∆°-ron trong l·ªõp ƒë·∫ßu ra (t∆∞∆°ng ·ª©ng v·ªõi s·ªë l·ªõp trong b√†i to√°n ph√¢n lo·∫°i).  
                    - $$( f(x_i) )$$: ƒê·∫ßu ra c·ªßa h√†m Softmax, n·∫±m trong kho·∫£ng $$((0, 1))$$ v√† t·ªïng c√°c ƒë·∫ßu ra b·∫±ng 1.  
                """
            )
            st.image("image6.png", caption="Bi·ªÉu ƒë·ªì h√†m Softmax (Ngu·ªìn: https://byvn.net/yvvj)", use_container_width=True)

            st.markdown("---")
            st.markdown("### C√¥ng th·ª©c to√°n h·ªçc")
            st.markdown("**1. Lan truy·ªÅn xu√¥i (Forward Propagation):**")
            st.latex(r"h_l = f(W_l h_{l-1} + b_l)")
            st.markdown(
                """
                - **Trong ƒë√≥:**
                - $$( h_l )$$: ƒê·∫ßu ra c·ªßa l·ªõp $$( l )$$.  
                - $$( W_l )$$: Ma tr·∫≠n tr·ªçng s·ªë c·ªßa l·ªõp $$( l )$$.  
                - $$( h_{l-1} )$$: ƒê·∫ßu ra c·ªßa l·ªõp tr∆∞·ªõc ƒë√≥ (ho·∫∑c d·ªØ li·ªáu ƒë·∫ßu v√†o n·∫øu l√† l·ªõp ƒë·∫ßu ti√™n).  
                - $$( b_l )$$: Vector bias c·ªßa l·ªõp $$( l )$$.  
                - $$( f )$$: H√†m k√≠ch ho·∫°t (v√≠ d·ª•: ReLU, Sigmoid, Tanh).
                """
            )
            st.markdown("**2. H√†m m·∫•t m√°t (Loss Function) - Cross-Entropy cho ph√¢n lo·∫°i:**")
            st.latex(r"L = -\frac{1}{N} \sum_{i=1}^{N} [y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i)]")
            st.markdown(
                """
                - **Trong ƒë√≥:**
                - $$( y_i )$$: Nh√£n th·ª±c t·∫ø c·ªßa m·∫´u $$( i )$$ (0 ho·∫∑c 1).  
                - $$( \hat{y}_i )$$: D·ª± ƒëo√°n c·ªßa m√¥ h√¨nh cho m·∫´u $$( i )$$ (x√°c su·∫•t t·ª´ 0 ƒë·∫øn 1).  
                - $$( N )$$: S·ªë m·∫´u.
                """
            )
            st.markdown("**3. Lan truy·ªÅn ng∆∞·ª£c (Backpropagation) - C·∫≠p nh·∫≠t tr·ªçng s·ªë:**")
            st.latex(r"W_l = W_l - \eta \frac{\partial L}{\partial W_l}")
            st.markdown(
                r"""
                - **Trong ƒë√≥:**
                - $$\eta$$: T·ªëc ƒë·ªô h·ªçc (learning rate).  
                - $$\frac{\partial L}{\partial W_l}$$: ƒê·∫°o h√†m c·ªßa h√†m m·∫•t m√°t theo tr·ªçng s·ªë $$W_l$$.
                """
            )
            st.markdown("---")
            st.markdown("### ∆Øu ƒëi·ªÉm & Nh∆∞·ª£c ƒëi·ªÉm c·ªßa Neural Network")
            st.table({
                "**∆Øu ƒëi·ªÉm**": [
                    "H·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng phi tuy·∫øn t√≠nh ph·ª©c t·∫°p.",
                    "Linh ho·∫°t v·ªõi nhi·ªÅu lo·∫°i d·ªØ li·ªáu v√† b√†i to√°n.",
                    "Hi·ªáu qu·∫£ cao v·ªõi d·ªØ li·ªáu l·ªõn khi ƒë∆∞·ª£c t·ªëi ∆∞u t·ªët."
                ],
                "**Nh∆∞·ª£c ƒëi·ªÉm**": [
                    "Y√™u c·∫ßu l∆∞·ª£ng d·ªØ li·ªáu l·ªõn ƒë·ªÉ hu·∫•n luy·ªán.",
                    "T·ªën t√†i nguy√™n t√≠nh to√°n.",
                    "Kh√≥ di·ªÖn gi·∫£i k·∫øt qu·∫£."
                ]
            })

    # Tab "Ph√¢n chia t·ªâ l·ªá"
    with tab_samples:
        with st.expander("**Ph√¢n chia d·ªØ li·ªáu**", expanded=True):
            if "train_images" in st.session_state:
                train_images = st.session_state.train_images
                train_labels = st.session_state.train_labels
                test_images = st.session_state.test_images
                test_labels = st.session_state.test_labels

                X = np.concatenate((train_images, test_images), axis=0)
                y = np.concatenate((train_labels, test_labels), axis=0)
                X = X.reshape(X.shape[0], -1)

                test_size = st.slider("üîπ Ch·ªçn % t·ª∑ l·ªá t·∫≠p test", min_value=10, max_value=50, value=20, step=5, key="test_size") / 100
                val_size = st.slider("üîπ Ch·ªçn % t·ª∑ l·ªá t·∫≠p validation (trong ph·∫ßn train)", min_value=10, max_value=50, value=20, step=5, key="val_size") / 100

                X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
                val_size_adjusted = val_size / (1 - test_size)
                X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size_adjusted, random_state=42)

                st.session_state.X_train = X_train
                st.session_state.X_val = X_val
                st.session_state.X_test = X_test
                st.session_state.y_train = y_train
                st.session_state.y_val = y_val
                st.session_state.y_test = y_test

                total_samples = X.shape[0]
                test_percent = (X_test.shape[0] / total_samples) * 100
                val_percent = (X_val.shape[0] / total_samples) * 100
                train_percent = (X_train.shape[0] / total_samples) * 100

                st.write(f"üìä **T·ª∑ l·ªá ph√¢n chia**: Test={test_percent:.0f}%, Validation={val_percent:.0f}%, Train={train_percent:.0f}%")
                st.write("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω v√† chia t√°ch.")
                st.write(f"üîπ K√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán: `{X_train.shape}`")
                st.write(f"üîπ K√≠ch th∆∞·ªõc t·∫≠p validation: `{X_val.shape}`")
                st.write(f"üîπ K√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra: `{X_test.shape}`")
            else:
                st.error("üö® D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c n·∫°p. H√£y ƒë·∫£m b·∫£o `train_images`, `train_labels` v√† `test_images` ƒë√£ ƒë∆∞·ª£c t·∫£i tr∆∞·ªõc khi ch·∫°y.")

    # Tab "Hu·∫•n luy·ªán m√¥ h√¨nh"
    with tab_preprocess:
        with st.expander("**Hu·∫•n luy·ªán m√¥ h√¨nh Neural Network**", expanded=True):
            if "X_train" not in st.session_state:
                st.error("üö® Vui l√≤ng ph√¢n chia d·ªØ li·ªáu ·ªü tab 'Ph√¢n chia d·ªØ li·ªáu' tr∆∞·ªõc khi hu·∫•n luy·ªán m√¥ h√¨nh.")
            else:
                # L·∫•y d·ªØ li·ªáu t·ª´ session_state
                X_train = st.session_state.X_train
                X_val = st.session_state.X_val
                X_test = st.session_state.X_test
                y_train = st.session_state.y_train
                y_val = st.session_state.y_val
                y_test = st.session_state.y_test

                # Chu·∫©n h√≥a d·ªØ li·ªáu
                X_train = X_train / 255.0
                X_val = X_val / 255.0
                X_test = X_test / 255.0

                # X√°c ƒë·ªãnh s·ªë l·ªõp v√† input shape
                num_classes = len(np.unique(y_train))
                input_shape = X_train.shape[1]

                # C·∫•u h√¨nh hu·∫•n luy·ªán
                st.markdown("### C·∫•u h√¨nh hu·∫•n luy·ªán")

                # G·ª£i √Ω tham s·ªë t·ªëi ∆∞u d·ª±a tr√™n s·ªë l∆∞·ª£ng d·ªØ li·ªáu
                num_train_samples = len(X_train)
                if num_train_samples <= 1000:
                    suggested_hidden_layers = 1
                    suggested_neurons = [128]
                    suggested_batch_size = 32
                    suggested_learning_rate = 0.001
                elif num_train_samples <= 10000:
                    suggested_hidden_layers = 2
                    suggested_neurons = [256, 128]
                    suggested_batch_size = 64
                    suggested_learning_rate = 0.0005
                elif num_train_samples <= 50000:
                    suggested_hidden_layers = 3
                    suggested_neurons = [512, 256, 128]
                    suggested_batch_size = 128
                    suggested_learning_rate = 0.0001
                else:
                    suggested_hidden_layers = 4
                    suggested_neurons = [512, 256, 128, 64]
                    suggested_batch_size = 256
                    suggested_learning_rate = 0.00005

                st.markdown(f"**G·ª£i √Ω tham s·ªë t·ªëi ∆∞u cho {num_train_samples} m·∫´u:**")
                st.write(f"- S·ªë l·ªõp ·∫©n: {suggested_hidden_layers}")
                st.write(f"- S·ªë n∆°-ron: {suggested_neurons}")
                st.write(f"- Batch size: {suggested_batch_size}")
                st.write(f"- Learning rate: {suggested_learning_rate}")

                num_hidden_layers = st.slider(
                    "üîπ S·ªë l∆∞·ª£ng l·ªõp ·∫©n",
                    min_value=1,
                    max_value=5,
                    value=suggested_hidden_layers,
                    step=1,
                    key="num_hidden_layers"
                )
                st.write(f"**S·ªë l·ªõp ·∫©n ƒë∆∞·ª£c ch·ªçn:** {num_hidden_layers}")

                hidden_layer_neurons = []
                for i in range(num_hidden_layers):
                    default_neurons = suggested_neurons[i] if i < len(suggested_neurons) else 128
                    neurons = st.number_input(
                        f"üîπ S·ªë n∆°-ron cho l·ªõp ·∫©n {i+1}",
                        min_value=32,
                        max_value=1024,
                        value=default_neurons,
                        step=32,
                        key=f"neurons_layer_{i}"
                    )
                    hidden_layer_neurons.append(neurons)
                st.write(f"**S·ªë n∆°-ron cho c√°c l·ªõp ·∫©n:** {hidden_layer_neurons}")

                activation_function = st.selectbox(
                    "üîπ H√†m k√≠ch ho·∫°t cho c√°c l·ªõp ·∫©n",
                    options=['relu', 'sigmoid', 'tanh'],
                    index=0,
                    key="activation_function"
                )

                epochs = st.slider("üîπ S·ªë epoch", min_value=5, max_value=50, value=10, step=5, key="epochs")
                batch_size = st.selectbox("üîπ Batch size", options=[32, 64, 128, 256], index=[32, 64, 128, 256].index(suggested_batch_size), key="batch_size")
                optimizer_choice = st.selectbox(
                    "üîπ B·ªô t·ªëi ∆∞u",
                    options=['adam', 'sgd', 'rmsprop', 'adagrad'],
                    index=0,
                    key="optimizer"
                )
                learning_rate = st.slider(
                    "üîπ Learning Rate (T·ªëc ƒë·ªô h·ªçc)",
                    min_value=0.0001,
                    max_value=0.1,
                    value=suggested_learning_rate,
                    step=0.0001,
                    format="%.4f",
                    key="learning_rate"
                )
                st.write(f"**Learning Rate ƒë∆∞·ª£c ch·ªçn:** {learning_rate}")

                # Kh·ªüi t·∫°o tr·∫°ng th√°i n·∫øu ch∆∞a c√≥
                if 'training_completed' not in st.session_state:
                    st.session_state['training_completed'] = False

                # Ch·ªâ hu·∫•n luy·ªán khi nh·∫•n n√∫t
                if st.button("üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán", key="train_button"):
                    with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
                        # X√¢y d·ª±ng m√¥ h√¨nh (b·ªè Dropout)
                        model = models.Sequential()
                        model.add(layers.Input(shape=(input_shape,)))
                        for neurons in hidden_layer_neurons:
                            model.add(layers.Dense(neurons, activation=activation_function))
                        model.add(layers.Dense(num_classes, activation='softmax'))

                        # C·∫•u h√¨nh optimizer
                        if optimizer_choice == "adam":
                            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
                        elif optimizer_choice == "sgd":
                            optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)
                        elif optimizer_choice == "rmsprop":
                            optimizer = tf.keras.optimizers.RMSprop(learning_rate=learning_rate)
                        elif optimizer_choice == "adagrad":
                            optimizer = tf.keras.optimizers.Adagrad(learning_rate=learning_rate)

                        model.compile(optimizer=optimizer,
                                    loss='sparse_categorical_crossentropy',
                                    metrics=['accuracy'])

                        with mlflow.start_run():
                            progress_bar = st.progress(0)
                            status_text = st.empty()
                            start_time = time.time()

                            class TimeHistory(tf.keras.callbacks.Callback):
                                def on_train_begin(self, logs={}):
                                    self.times = []
                                    status_text.markdown(" **Hu·∫•n luy·ªán**: 0%")
                                def on_epoch_begin(self, epoch, logs={}):
                                    self.epoch_start = time.time()
                                def on_epoch_end(self, epoch, logs={}):
                                    self.times.append(time.time() - self.epoch_start)
                                    progress = (epoch + 1) / epochs * 100
                                    progress_bar.progress(int(progress))
                                    status_text.markdown(f" **ƒêang hu·∫•n luy·ªán**: {int(progress)}%")
                                def on_train_end(self, logs={}):
                                    status_text.markdown(" **Hu·∫•n luy·ªán**: 100% (Ho√†n th√†nh)")

                            time_callback = TimeHistory()
                            history = model.fit(X_train, y_train,
                                            epochs=epochs,
                                            batch_size=batch_size,
                                            validation_data=(X_val, y_val),
                                            verbose=1,
                                            callbacks=[time_callback])

                            total_time = time.time() - start_time
                            progress_bar.progress(100)

                            test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)
                            train_loss, train_accuracy = model.evaluate(X_train, y_train, verbose=0)
                            val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)
                            total_params = model.count_params()

                            # L∆∞u t·∫•t c·∫£ v√†o session_state
                            st.session_state['trained_model'] = model
                            st.session_state['history'] = history
                            st.session_state['test_accuracy'] = test_accuracy
                            st.session_state['val_accuracy'] = val_accuracy
                            st.session_state['train_accuracy'] = train_accuracy
                            st.session_state['test_loss'] = test_loss
                            st.session_state['val_loss'] = val_loss
                            st.session_state['train_loss'] = train_loss
                            st.session_state['total_time'] = total_time
                            st.session_state['time_callback'] = time_callback
                            st.session_state['training_completed'] = True
                            st.session_state['total_params'] = total_params

                            # Ghi log v·ªõi MLflow
                            mlflow.log_param("epochs", epochs)
                            mlflow.log_param("batch_size", batch_size)
                            mlflow.log_param("optimizer", optimizer_choice)
                            mlflow.log_param("learning_rate", learning_rate)
                            mlflow.log_param("activation_function", activation_function)
                            mlflow.log_param("num_hidden_layers", num_hidden_layers)
                            mlflow.log_param("hidden_layer_neurons", hidden_layer_neurons)
                            mlflow.log_param("num_classes", num_classes)
                            mlflow.log_param("input_shape", input_shape)
                            mlflow.log_param("total_params", total_params)

                            mlflow.log_metric("train_accuracy", train_accuracy)
                            mlflow.log_metric("val_accuracy", val_accuracy)
                            mlflow.log_metric("test_accuracy", test_accuracy)
                            mlflow.log_metric("train_loss", train_loss)
                            mlflow.log_metric("val_loss", val_loss)
                            mlflow.log_metric("test_loss", test_loss)
                            mlflow.log_metric("total_training_time", total_time)
                            mlflow.log_metric("avg_epoch_time", np.mean(time_callback.times))

                # Hi·ªÉn th·ªã k·∫øt qu·∫£ n·∫øu hu·∫•n luy·ªán ƒë√£ ho√†n t·∫•t
                if st.session_state['training_completed']:
                    model = st.session_state['trained_model']
                    history = st.session_state['history']
                    test_accuracy = st.session_state['test_accuracy']
                    val_accuracy = st.session_state['val_accuracy']
                    train_accuracy = st.session_state['train_accuracy']
                    test_loss = st.session_state['test_loss']
                    val_loss = st.session_state['val_loss']
                    train_loss = st.session_state['train_loss']
                    total_time = st.session_state['total_time']
                    time_callback = st.session_state['time_callback']
                    total_params = st.session_state['total_params']

                    st.success("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
                    st.write("#### ‚úÖ **Th√¥ng tin m√¥ h√¨nh v√† k·∫øt qu·∫£ hu·∫•n luy·ªán**")

                    # Ki·∫øn tr√∫c m√¥ h√¨nh
                    st.write("**1. Ki·∫øn tr√∫c m√¥ h√¨nh:**")
                    st.write(f" - S·ªë l·ªõp ·∫©n: {num_hidden_layers}")
                    st.write(f" - S·ªë n∆°-ron: {hidden_layer_neurons}")
                    st.write(f" - H√†m k√≠ch ho·∫°t: {activation_function}")

                    # S·ªë l∆∞·ª£ng tham s·ªë
                    st.write("**2. S·ªë l∆∞·ª£ng tham s·ªë:**")
                    st.write(f"- T·ªïng s·ªë tham s·ªë: {total_params:,}")

                    # Th√¥ng tin hu·∫•n luy·ªán
                    st.write("**3. Th√¥ng tin hu·∫•n luy·ªán:**")
                    st.write(f"- S·ªë epoch: {epochs}")
                    st.write(f"- Batch size: {batch_size}")
                    st.write(f"- Learning rate: {learning_rate}")
                    st.write(f"- B·ªô t·ªëi ∆∞u: {optimizer_choice}")

                    # Loss v√† Accuracy
                    st.write("**4. K·∫øt qu·∫£ Loss & Accuracy:**")
                    st.write(f"- **Validation Accuracy**: {val_accuracy:.4f}")
                    st.write(f"- **Test Accuracy**: {test_accuracy:.4f}")

                    # Th·ªùi gian hu·∫•n luy·ªán
                    st.write("**5. Th·ªùi gian hu·∫•n luy·ªán:**")
                    st.write(f"- T·ªïng th·ªùi gian: {total_time:.2f} gi√¢y")
                    st.write(f"- Th·ªùi gian trung b√¨nh m·ªói epoch: {np.mean(time_callback.times):.2f} gi√¢y")

                    # Bi·ªÉu ƒë·ªì
                    st.write("**6. Bi·ªÉu ƒë·ªì K·∫øt qu·∫£ Hu·∫•n luy·ªán:**")
                    # Bi·ªÉu ƒë·ªì Loss
                    fig, ax = plt.subplots(figsize=(8, 4))
                    ax.plot(history.history['loss'], label='Training Loss', marker='o', linestyle='-')
                    ax.plot(history.history['val_loss'], label='Validation Loss', marker='s', linestyle='--')
                    ax.set_xlabel("Epochs")
                    ax.set_ylabel("Loss")
                    ax.set_title("Training & Validation Loss")
                    ax.legend()
                    ax.grid(True)
                    st.pyplot(fig)
                    st.markdown("""
                    **Gi·∫£i th√≠ch bi·ªÉu ƒë·ªì Loss:**
                    - **Train Loss (M·∫•t m√°t hu·∫•n luy·ªán):** ƒê·∫°i di·ªán cho sai s·ªë gi·ªØa d·ª± ƒëo√°n v√† nh√£n th·ª±c t·∫ø tr√™n t·∫≠p hu·∫•n luy·ªán. Gi√° tr·ªã gi·∫£m d·∫ßn qua c√°c epoch cho th·∫•y m√¥ h√¨nh ƒëang h·ªçc t·ªët h∆°n.
                    - **Val Loss (M·∫•t m√°t validation):** ƒêo l∆∞·ªùng sai s·ªë tr√™n t·∫≠p validation, gi√∫p ƒë√°nh gi√° kh·∫£ nƒÉng t·ªïng qu√°t h√≥a. N·∫øu Val Loss ·ªïn ƒë·ªãnh ho·∫∑c gi·∫£m ch·∫≠m, m√¥ h√¨nh kh√¥ng b·ªã overfitting.
                    - Hai ƒë∆∞·ªùng n√†y n√™n c√≥ xu h∆∞·ªõng t∆∞∆°ng t·ª±; n·∫øu Val Loss tƒÉng trong khi Train Loss gi·∫£m, ƒë√≥ l√† d·∫•u hi·ªáu c·ªßa overfitting.
                    """)
                    st.markdown("---")

                    # Bi·ªÉu ƒë·ªì Accuracy
                    fig, ax = plt.subplots(figsize=(8, 4))
                    ax.plot(history.history['accuracy'], label='Training Accuracy', marker='o', linestyle='-')
                    ax.plot(history.history['val_accuracy'], label='Validation Accuracy', marker='s', linestyle='--')
                    ax.set_xlabel("Epochs")
                    ax.set_ylabel("Accuracy")
                    ax.set_title("Training & Validation Accuracy")
                    ax.legend()
                    ax.grid(True)
                    st.pyplot(fig)
                    st.markdown("""
                    **Gi·∫£i th√≠ch bi·ªÉu ƒë·ªì Accuracy:**
                    - **Train Accuracy (ƒê·ªô ch√≠nh x√°c hu·∫•n luy·ªán):** T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng tr√™n t·∫≠p hu·∫•n luy·ªán, th∆∞·ªùng tƒÉng qua c√°c epoch khi m√¥ h√¨nh h·ªçc.
                    - **Val Accuracy (ƒê·ªô ch√≠nh x√°c validation):** T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng tr√™n t·∫≠p validation, ph·∫£n √°nh kh·∫£ nƒÉng t·ªïng qu√°t h√≥a. Gi√° tr·ªã cao v√† ·ªïn ƒë·ªãnh cho th·∫•y m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët tr√™n d·ªØ li·ªáu m·ªõi.
                    - S·ª± kh√°c bi·ªát gi·ªØa Train Accuracy v√† Val Accuracy kh√¥ng qu√° l·ªõn l√† d·∫•u hi·ªáu c·ªßa m·ªôt m√¥ h√¨nh c√¢n b·∫±ng.
                    """)
                else:
                    st.info("Ch∆∞a c√≥ k·∫øt qu·∫£ hu·∫•n luy·ªán. Nh·∫•n 'B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán' ƒë·ªÉ b·∫Øt ƒë·∫ßu.")

    # Tab "D·ª± ƒëo√°n"
    with tab_demo:
        st.header("D·ª± ƒëo√°n s·ªë vi·∫øt tay")
        st.write("Ch·ªçn c√°ch nh·∫≠p li·ªáu: t·∫£i l√™n h√¨nh ·∫£nh ho·∫∑c v·∫Ω tr·ª±c ti·∫øp.")

        if 'trained_model' not in st.session_state:
            st.warning("‚ö†Ô∏è Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc trong tab 'Hu·∫•n luy·ªán'!")
        else:
            model = st.session_state['trained_model']

            input_method = st.selectbox("Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p li·ªáu", ["V·∫Ω tr·ª±c ti·∫øp", "T·∫£i ·∫£nh l√™n"])

            if input_method == "V·∫Ω tr·ª±c ti·∫øp":
                canvas_result = st_canvas(
                    fill_color="rgba(255, 165, 0, 0.3)",
                    stroke_width=20,
                    stroke_color="#FFFFFF",
                    background_color="#000000",
                    height=280,
                    width=280,
                    drawing_mode="freedraw",
                    key="canvas"
                )

                # Ch·ªâ d·ª± ƒëo√°n khi ng∆∞·ªùi d√πng nh·∫•n n√∫t
                if canvas_result.image_data is not None:
                    image = Image.fromarray(canvas_result.image_data.astype('uint8'), 'RGBA')
                    image = image.convert('L')
                    image = image.resize((28, 28))
                    st.image(image, caption="H√¨nh ·∫£nh b·∫°n v·∫Ω (resize 28x28)", width=100)

                    if st.button("D·ª± ƒëo√°n", key="predict_button"):
                        image_array = np.array(image, dtype=np.float32) / 255.0
                        image_array = image_array.reshape(1, 784)

                        image_tensor = tf.convert_to_tensor(image_array, dtype=tf.float32)
                        prediction = model.predict(image_tensor, verbose=0)
                        predicted_class = np.argmax(prediction[0])
                        confidence = prediction[0][predicted_class]

                        st.write(f"**D·ª± ƒëo√°n:** {predicted_class}")
                        st.write(f"**X√°c su·∫•t:** {confidence:.4f}")

                    if st.button("X√≥a v√† v·∫Ω l·∫°i", key="clear_button"):
                        st.session_state.pop("canvas")
                        st.rerun()

            elif input_method == "T·∫£i ·∫£nh l√™n":
                uploaded_file = st.file_uploader("T·∫£i l√™n h√¨nh ·∫£nh", type=["png", "jpg", "jpeg"])
                if uploaded_file is not None:
                    image = Image.open(uploaded_file).convert('L')
                    image = image.resize((28, 28))
                    st.image(image, caption="H√¨nh ·∫£nh ƒë·∫ßu v√†o", width=100)

                    if st.button("D·ª± ƒëo√°n", key="predict_upload_button"):
                        image_array = np.array(image, dtype=np.float32) / 255.0
                        image_array = image_array.reshape(1, 784)

                        image_tensor = tf.convert_to_tensor(image_array, dtype=tf.float32)
                        prediction = model.predict(image_tensor, verbose=0)
                        predicted_class = np.argmax(prediction[0])
                        confidence = prediction[0][predicted_class]

                        st.write(f"**D·ª± ƒëo√°n:** {predicted_class} (X√°c su·∫•t: {confidence:.4f})")

    # Tab "Th√¥ng tin & Mlflow"
    with tab_mlflow:
        st.header("Th√¥ng tin Hu·∫•n luy·ªán & MLflow UI")
        try:
            client = MlflowClient()
            experiment_name = "NeuralNetworkExperiment"

            # Ki·ªÉm tra n·∫øu experiment ƒë√£ t·ªìn t·∫°i
            experiment = client.get_experiment_by_name(experiment_name)
            if experiment is None:
                experiment_id = client.create_experiment(experiment_name)
                st.success(f"Experiment m·ªõi ƒë∆∞·ª£c t·∫°o v·ªõi ID: {experiment_id}")
            else:
                experiment_id = experiment.experiment_id
                st.info(f"ƒêang s·ª≠ d·ª•ng experiment ID: {experiment_id}")

            mlflow.set_experiment(experiment_name)

            # Truy v·∫•n c√°c run trong experiment
            runs = client.search_runs(experiment_ids=[experiment_id])

            # 1) Ch·ªçn v√† ƒë·ªïi t√™n Run Name
            st.subheader("ƒê·ªïi t√™n Run")
            if runs:
                run_options = {run.info.run_id: f"{run.data.tags.get('mlflow.runName', 'Unnamed')} - {run.info.run_id}"
                            for run in runs}
                selected_run_id_for_rename = st.selectbox("Ch·ªçn Run ƒë·ªÉ ƒë·ªïi t√™n:", 
                                                        options=list(run_options.keys()), 
                                                        format_func=lambda x: run_options[x])
                new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi cho Run:", 
                                            value=run_options[selected_run_id_for_rename].split(" - ")[0])
                if st.button("C·∫≠p nh·∫≠t t√™n Run"):
                    if new_run_name.strip():
                        client.set_tag(selected_run_id_for_rename, "mlflow.runName", new_run_name.strip())
                        st.success(f"ƒê√£ c·∫≠p nh·∫≠t t√™n Run th√†nh: {new_run_name.strip()}")
                    else:
                        st.warning("Vui l√≤ng nh·∫≠p t√™n m·ªõi cho Run.")
            else:
                st.info("Ch∆∞a c√≥ Run n√†o ƒë∆∞·ª£c log.")

            # 2) X√≥a Run
            st.subheader("Danh s√°ch Run")
            if runs:
                selected_run_id_to_delete = st.selectbox("", 
                                                        options=list(run_options.keys()), 
                                                        format_func=lambda x: run_options[x])
                if st.button("X√≥a Run", key="delete_run"):
                    client.delete_run(selected_run_id_to_delete)
                    st.success(f"ƒê√£ x√≥a Run {run_options[selected_run_id_to_delete]} th√†nh c√¥ng!")
                    st.rerun()
            else:
                st.info("Ch∆∞a c√≥ Run n√†o ƒë·ªÉ x√≥a.")

            # 3) Danh s√°ch c√°c th√≠ nghi·ªám
            st.subheader("Danh s√°ch c√°c Run ƒë√£ log")
            if runs:
                selected_run_id = st.selectbox("Ch·ªçn Run ƒë·ªÉ xem chi ti·∫øt:", 
                                            options=list(run_options.keys()), 
                                            format_func=lambda x: run_options[x])

                # 4) Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt c·ªßa Run ƒë∆∞·ª£c ch·ªçn
                selected_run = client.get_run(selected_run_id)
                st.write(f"**Run ID:** {selected_run_id}")
                st.write(f"**Run Name:** {selected_run.data.tags.get('mlflow.runName', 'Unnamed')}")

                # Hi·ªÉn th·ªã c√°c tham s·ªë ƒë√£ log
                st.markdown("### Tham s·ªë ƒë√£ log")
                st.json({
                    "epochs": selected_run.data.params.get("epochs", "N/A"),
                    "batch_size": selected_run.data.params.get("batch_size", "N/A"),
                    "optimizer": selected_run.data.params.get("optimizer", "N/A"),
                    "learning_rate": selected_run.data.params.get("learning_rate", "N/A"),
                    "activation_function": selected_run.data.params.get("activation_function", "N/A"),
                    "num_hidden_layers": selected_run.data.params.get("num_hidden_layers", "N/A"),
                    "hidden_layer_neurons": selected_run.data.params.get("hidden_layer_neurons", "N/A"),
                    "num_classes": selected_run.data.params.get("num_classes", "N/A"),
                    "input_shape": selected_run.data.params.get("input_shape", "N/A"),
                    "total_params": selected_run.data.params.get("total_params", "N/A")
                })

                # Hi·ªÉn th·ªã c√°c ch·ªâ s·ªë ƒë√£ log
                st.markdown("### Ch·ªâ s·ªë ƒë√£ log")
                metrics = {
                    "Train Accuracy": selected_run.data.metrics.get("train_accuracy", "N/A"),
                    "Validation Accuracy": selected_run.data.metrics.get("val_accuracy", "N/A"),
                    "Test Accuracy": selected_run.data.metrics.get("test_accuracy", "N/A"),
                    "Train Loss": selected_run.data.metrics.get("train_loss", "N/A"),
                    "Validation Loss": selected_run.data.metrics.get("val_loss", "N/A"),
                    "Test Loss": selected_run.data.metrics.get("test_loss", "N/A"),
                    "Total Training Time (s)": selected_run.data.metrics.get("total_training_time", "N/A"),
                    "Average Epoch Time (s)": selected_run.data.metrics.get("avg_epoch_time", "N/A")
                }
                st.json(metrics)

                # 5) N√∫t b·∫•m m·ªü MLflow UI
                st.subheader("Truy c·∫≠p MLflow UI")
                mlflow_url = "https://dagshub.com/Dung2204/HMVPython.mlflow"
                if st.button("M·ªü MLflow UI"):
                    st.markdown(f'**[Click ƒë·ªÉ m·ªü MLflow UI]({mlflow_url})**')
            else:
                st.info("Ch∆∞a c√≥ Run n√†o ƒë∆∞·ª£c log. Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")

        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi MLflow: {e}")

if __name__ == "__main__":
    run_NeuralNetwork_app()