import os
import mlflow
import streamlit as st
import openml
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.neural_network import MLPClassifier  # Neural Network
from sklearn.impute import SimpleImputer
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from datetime import datetime
import time

def run_mnist_neural_network_app():
    st.title("á»¨ng dá»¥ng PhÃ¢n loáº¡i Chá»¯ sá»‘ MNIST vá»›i Neural Network")

    # CSS cho MathJax vÃ  giao diá»‡n
    st.markdown("""
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
        <style>
            .inline-container {
                display: inline-flex;
                align-items: center;
                gap: 5px;
            }
        </style>
    """, unsafe_allow_html=True)

    # CÃ¡c tab
    tabs = st.tabs(["ThÃ´ng tin", "Táº£i dá»¯ liá»‡u", "Xá»­ lÃ½ dá»¯ liá»‡u", "Chia dá»¯ liá»‡u", "Huáº¥n luyá»‡n/ÄÃ¡nh giÃ¡", "Demo dá»± Ä‘oÃ¡n", "ThÃ´ng tin huáº¥n luyá»‡n"])
    tab_info, tab_load, tab_preprocess, tab_split, tab_train_eval, tab_demo, tab_log_info = tabs

    # Tab 1: ThÃ´ng tin
    with tab_info:
        st.header("Giá»›i thiá»‡u vá» á»¨ng dá»¥ng vÃ  Máº¡ng Neural Network")
        st.markdown("""
        ChÃ o báº¡n! ÄÃ¢y lÃ  á»©ng dá»¥ng phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay tá»« táº­p dá»¯ liá»‡u **MNIST** báº±ng **Máº¡ng nÆ¡-ron nhÃ¢n táº¡o (Neural Network)**. HÃ£y khÃ¡m phÃ¡ cÃ¡c tÃ­nh nÄƒng vÃ  cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a nÃ³ nhÃ©!
        """, unsafe_allow_html=True)

        st.subheader("Chá»n thÃ´ng tin Ä‘á»ƒ xem")
        info_option = st.selectbox(
            "",
            [
                "á»¨ng dá»¥ng nÃ y lÃ  gÃ¬ vÃ  má»¥c tiÃªu cá»§a nÃ³?",
                "Táº­p dá»¯ liá»‡u MNIST: Äáº·c Ä‘iá»ƒm vÃ  Ã½ nghÄ©a",
                "Neural Network â€“ Máº¡ng nÆ¡-ron nhÃ¢n táº¡o",
                "CÃ´ng thá»©c Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c (Accuracy)"
            ],
            label_visibility="collapsed",
            help="Chá»n Ä‘á»ƒ xem chi tiáº¿t vá» á»©ng dá»¥ng, dá»¯ liá»‡u, hoáº·c mÃ´ hÃ¬nh."
        )

        if info_option == "á»¨ng dá»¥ng nÃ y lÃ  gÃ¬ vÃ  má»¥c tiÃªu cá»§a nÃ³?":
            st.subheader("ğŸ“˜ 1. á»¨ng dá»¥ng nÃ y lÃ  gÃ¬ vÃ  má»¥c tiÃªu cá»§a nÃ³?")
            st.markdown("""
            ÄÃ¢y lÃ  má»™t á»©ng dá»¥ng phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay dá»±a trÃªn táº­p dá»¯ liá»‡u **MNIST**, sá»­ dá»¥ng **Máº¡ng nÆ¡-ron nhÃ¢n táº¡o (Neural Network)**.  
            - **MNIST**: Táº­p dá»¯ liá»‡u gá»“m $70,000$ áº£nh chá»¯ sá»‘ tá»« $0$ Ä‘áº¿n $9$, má»—i áº£nh kÃ­ch thÆ°á»›c $28 \\times 28$ pixel (tá»•ng cá»™ng $784$ Ä‘áº·c trÆ°ng).  
            - **Má»¥c tiÃªu**:  
              - XÃ¢y dá»±ng vÃ  huáº¥n luyá»‡n má»™t máº¡ng nÆ¡-ron Ä‘á»ƒ nháº­n diá»‡n chÃ­nh xÃ¡c cÃ¡c chá»¯ sá»‘.  
              - Cung cáº¥p cÃ´ng cá»¥ trá»±c quan Ä‘á»ƒ há»c táº­p vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a thuáº­t toÃ¡n.  

            **ThÃ´ng tin cÆ¡ báº£n**:  
            - **$784$ Ä‘áº·c trÆ°ng**: Má»—i áº£nh Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng vector $784$ chiá»u (giÃ¡ trá»‹ pixel tá»« $0$ Ä‘áº¿n $255$).  
            - **$70,000$ máº«u**: Tá»•ng sá»‘ áº£nh, Ä‘Æ°á»£c chia thÃ nh táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra.  
            - **Nhiá»‡m vá»¥**: Dá»± Ä‘oÃ¡n nhÃ£n ($0$-$9$) dá»±a trÃªn Ä‘áº·c trÆ°ng pixel.  
            """, unsafe_allow_html=True)

        elif info_option == "Táº­p dá»¯ liá»‡u MNIST: Äáº·c Ä‘iá»ƒm vÃ  Ã½ nghÄ©a":
            st.subheader("ğŸ“˜ 2. Táº­p dá»¯ liá»‡u MNIST: Äáº·c Ä‘iá»ƒm vÃ  Ã½ nghÄ©a")
            st.markdown("""
            **MNIST** lÃ  táº­p dá»¯ liá»‡u chuáº©n trong há»c mÃ¡y, Ä‘Æ°á»£c táº¡o bá»Ÿi Yann LeCun vÃ  cÃ¡c cá»™ng sá»±.  
            - **Äáº·c Ä‘iá»ƒm**:  
              - Gá»“m cÃ¡c áº£nh chá»¯ sá»‘ viáº¿t tay tá»« há»c sinh trung há»c vÃ  nhÃ¢n viÃªn Ä‘iá»u tra dÃ¢n sá»‘ Má»¹.  
              - Chuáº©n hÃ³a thÃ nh kÃ­ch thÆ°á»›c $28 \\times 28$ pixel, thang Ä‘á»™ xÃ¡m (giÃ¡ trá»‹ tá»« $0$ Ä‘áº¿n $255$).  

            **Ã nghÄ©a**:  
            - LÃ  bÃ i toÃ¡n cÆ¡ báº£n Ä‘á»ƒ kiá»ƒm tra kháº£ nÄƒng phÃ¢n loáº¡i cá»§a cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y.  
            - ÄÆ¡n giáº£n nhÆ°ng Ä‘á»§ phá»©c táº¡p Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ kháº£ nÄƒng phÃ¢n biá»‡t cÃ¡c lá»›p tÆ°Æ¡ng tá»± (vÃ­ dá»¥: "$4$" vÃ  "$9$").  
            - PhÃ¹ há»£p cho cáº£ ngÆ°á»i má»›i báº¯t Ä‘áº§u vÃ  nghiÃªn cá»©u mÃ´ hÃ¬nh phá»©c táº¡p.  
            """, unsafe_allow_html=True)

            st.subheader("ğŸ“· Minh há»a dá»¯ liá»‡u MNIST")
            st.markdown("""
            DÆ°á»›i Ä‘Ã¢y lÃ  áº£nh minh há»a $10$ chá»¯ sá»‘ tá»« $0$ Ä‘áº¿n $9$ tá»« táº­p dá»¯ liá»‡u MNIST Ä‘á»ƒ báº¡n hÃ¬nh dung. Má»—i chá»¯ sá»‘ Ä‘Æ°á»£c biá»ƒu diá»…n dÆ°á»›i dáº¡ng ma tráº­n $28 \\times 28$ pixel.
            """, unsafe_allow_html=True)
            with st.spinner("Äang táº£i áº£nh minh há»a..."):
                try:
                    mnist_image = Image.open("mnist.png")
                    st.image(mnist_image, caption="áº¢nh minh há»a $10$ chá»¯ sá»‘ tá»« $0$ Ä‘áº¿n $9$ trong MNIST", width=800)
                except FileNotFoundError:
                    st.error("KhÃ´ng tÃ¬m tháº¥y file `mnist.png`. Vui lÃ²ng kiá»ƒm tra Ä‘Æ°á»ng dáº«n.")
                except Exception as e:
                    st.error(f"Lá»—i khi táº£i áº£nh: {e}")

        elif info_option == "Neural Network â€“ Máº¡ng nÆ¡-ron nhÃ¢n táº¡o":
            st.subheader("ğŸ“Š 3. Neural Network â€“ Máº¡ng nÆ¡-ron nhÃ¢n táº¡o")
            st.markdown("""
            **Neural Network (Máº¡ng nÆ¡-ron nhÃ¢n táº¡o)** lÃ  má»™t mÃ´ hÃ¬nh há»c mÃ¡y mÃ´ phá»ng cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a máº¡ng nÆ¡-ron sinh há»c trong nÃ£o ngÆ°á»i.  
            - **Cáº¥u trÃºc**: Gá»“m cÃ¡c **nÆ¡-ron nhÃ¢n táº¡o** (nodes) Ä‘Æ°á»£c tá»• chá»©c thÃ nh cÃ¡c **lá»›p (layers)**:  
              - **Lá»›p Ä‘áº§u vÃ o (Input Layer)**: Nháº­n dá»¯ liá»‡u ($784$ pixel tá»« áº£nh MNIST).  
              - **Lá»›p áº©n (Hidden Layers)**: Xá»­ lÃ½ thÃ´ng tin báº±ng cÃ¡ch káº¿t há»£p tuyáº¿n tÃ­nh vÃ  Ã¡p dá»¥ng hÃ m kÃ­ch hoáº¡t phi tuyáº¿n.  
              - **Lá»›p Ä‘áº§u ra (Output Layer)**: ÄÆ°a ra dá»± Ä‘oÃ¡n (nhÃ£n tá»« $0$-$9$).  

            Neural Network Ä‘áº·c biá»‡t hiá»‡u quáº£ vá»›i bÃ i toÃ¡n MNIST nhá» kháº£ nÄƒng há»c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p tá»« dá»¯ liá»‡u hÃ¬nh áº£nh.
            """, unsafe_allow_html=True)

            st.subheader("ğŸ› ï¸ CÃ¡c bÆ°á»›c thá»±c hiá»‡n trong Neural Network")
            st.markdown("""
            1. **Khá»Ÿi táº¡o mÃ´ hÃ¬nh**:  
               - XÃ¡c Ä‘á»‹nh cáº¥u trÃºc máº¡ng (sá»‘ lá»›p áº©n, sá»‘ nÆ¡-ron má»—i lá»›p).  
               - Khá»Ÿi táº¡o **trá»ng sá»‘** $W$ vÃ  **bias** $b$ ngáº«u nhiÃªn hoáº·c báº±ng $0$.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step1_init.png"), caption="Minh há»a BÆ°á»›c 1: Khá»Ÿi táº¡o mÃ´ hÃ¬nh", width=600)
            except FileNotFoundError:
                st.error("KhÃ´ng tÃ¬m tháº¥y áº£nh minh há»a cho BÆ°á»›c 1. Vui lÃ²ng cháº¡y mÃ£ táº¡o áº£nh trÆ°á»›c.")

            st.markdown("""
            2. **Lan truyá»n thuáº­n (Feedforward)**:  
               - TÃ­nh giÃ¡ trá»‹ dá»± Ä‘oÃ¡n $\\hat{Y}$ tá»« dá»¯ liá»‡u Ä‘áº§u vÃ o $X$:  
                 - **Lá»›p Ä‘áº§u vÃ o**: $A^{(0)} = X$ (ma tráº­n $N \\times 784$, $N$ lÃ  sá»‘ máº«u).  
                 - **Cho má»—i lá»›p $l$**:  
                   - Tá»•ng tuyáº¿n tÃ­nh:  
                     $$ Z^{(l)} = A^{(l-1)} \\cdot W^{(l)} + b^{(l)} $$  
                   - Ãp dá»¥ng hÃ m kÃ­ch hoáº¡t:  
                     $$ A^{(l)} = \\sigma(Z^{(l)}) $$  
                 - **Lá»›p Ä‘áº§u ra**: $\\hat{Y} = A^{(L)}$ (ma tráº­n $N \\times 10$).  
               - VÃ­ dá»¥ hÃ m kÃ­ch hoáº¡t **sigmoid**:  
                 $$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step2_feedforward.png"), caption="Minh há»a BÆ°á»›c 2: Lan truyá»n thuáº­n", width=600)
            except FileNotFoundError:
                st.error("KhÃ´ng tÃ¬m tháº¥y áº£nh minh há»a cho BÆ°á»›c 2. Vui lÃ²ng cháº¡y mÃ£ táº¡o áº£nh trÆ°á»›c.")

            st.markdown("""
            3. **TÃ­nh hÃ m máº¥t mÃ¡t (Loss Function)**:  
               - Äo Ä‘á»™ sai lá»‡ch giá»¯a $\\hat{Y}$ vÃ  $Y$ (giÃ¡ trá»‹ thá»±c). Vá»›i MNIST, dÃ¹ng **Cross-Entropy**:  
                 $$ L = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=0}^{9} y_{ij} \\cdot \\log(\\hat{y}_{ij}) $$  
               - Trong Ä‘Ã³:  
                 - $y_{ij}$: NhÃ£n thá»±c (dáº¡ng one-hot encoded).  
                 - $\\hat{y}_{ij}$: XÃ¡c suáº¥t dá»± Ä‘oÃ¡n cho lá»›p $j$.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step3_loss.png"), caption="Minh há»a BÆ°á»›c 3: TÃ­nh hÃ m máº¥t mÃ¡t", width=600)
            except FileNotFoundError:
                st.error("KhÃ´ng tÃ¬m tháº¥y áº£nh minh há»a cho BÆ°á»›c 3. Vui lÃ²ng cháº¡y mÃ£ táº¡o áº£nh trÆ°á»›c.")

            st.markdown("""
            4. **Lan truyá»n ngÆ°á»£c (Backpropagation)**:  
               - TÃ­nh Ä‘áº¡o hÃ m cá»§a $L$ theo $W^{(l)}$ vÃ  $b^{(l)}$ Ä‘á»ƒ cáº­p nháº­t tham sá»‘:  
                 - Táº¡i **Lá»›p Ä‘áº§u ra**:  
                   $$ \\delta^{(L)} = \\hat{Y} - Y $$  
                 - Táº¡i **Lá»›p áº©n**:  
                   $$ \\delta^{(l)} = (\\delta^{(l+1)} \\cdot (W^{(l+1)})^T) \\odot \\sigma'(Z^{(l)}) $$  
                   - $\\sigma'(z)$: Äáº¡o hÃ m hÃ m kÃ­ch hoáº¡t (vá»›i sigmoid: $\\sigma'(z) = \\sigma(z) \\cdot (1 - \\sigma(z))$).  
                 - Äáº¡o hÃ m theo trá»ng sá»‘ vÃ  bias:  
                   $$ \\frac{\\partial L}{\\partial W^{(l)}} = (A^{(l-1)})^T \\cdot \\delta^{(l)} $$  
                   $$ \\frac{\\partial L}{\\partial b^{(l)}} = \\sum_{i=1}^{N} \\delta^{(l)}_i $$
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step4_backprop.png"), caption="Minh há»a BÆ°á»›c 4: Lan truyá»n ngÆ°á»£c", width=600)
            except FileNotFoundError:
                st.error("KhÃ´ng tÃ¬m tháº¥y áº£nh minh há»a cho BÆ°á»›c 4. Vui lÃ²ng cháº¡y mÃ£ táº¡o áº£nh trÆ°á»›c.")

            st.markdown("""
            5. **Cáº­p nháº­t tham sá»‘ (Gradient Descent)**:  
               - Äiá»u chá»‰nh $W$ vÃ  $b$ Ä‘á»ƒ giáº£m máº¥t mÃ¡t:  
                 $$ W^{(l)} = W^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial W^{(l)}} $$  
                 $$ b^{(l)} = b^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial b^{(l)}} $$  
               - Trong Ä‘Ã³: $\\eta$ lÃ  **tá»‘c Ä‘á»™ há»c (learning rate)**.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step5_gradient.png"), caption="Minh há»a BÆ°á»›c 5: Cáº­p nháº­t tham sá»‘", width=600)
            except FileNotFoundError:
                st.error("KhÃ´ng tÃ¬m tháº¥y áº£nh minh há»a cho BÆ°á»›c 5. Vui lÃ²ng cháº¡y mÃ£ táº¡o áº£nh trÆ°á»›c.")

            st.markdown("""
            6. **Láº·p láº¡i**:  
               - Quay láº¡i bÆ°á»›c $2$ qua nhiá»u **epoch** cho Ä‘áº¿n khi $L$ há»™i tá»¥.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step6_repeat_improved.png"), caption="Minh há»a BÆ°á»›c 6: Láº·p láº¡i", width=600)
            except FileNotFoundError:
                st.error("KhÃ´ng tÃ¬m tháº¥y áº£nh minh há»a cho BÆ°á»›c 6. Vui lÃ²ng cháº¡y mÃ£ táº¡o áº£nh trÆ°á»›c.")

            st.subheader("âš™ï¸ CÃ¡c tham sá»‘ cÆ¡ báº£n vÃ  cÃ´ng dá»¥ng")
            st.markdown("""
            DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c tham sá»‘ báº¡n sáº½ sá»­ dá»¥ng Ä‘á»ƒ Ä‘iá»u chá»‰nh mÃ´ hÃ¬nh trong á»©ng dá»¥ng nÃ y:  
            - **hidden_layer_sizes**:  
              - **Ã nghÄ©a**: Sá»‘ nÆ¡-ron trong lá»›p áº©n (vÃ­ dá»¥: $128$).  
              - **CÃ´ng dá»¥ng**: Quyáº¿t Ä‘á»‹nh sá»©c máº¡nh cá»§a mÃ´ hÃ¬nh; nhiá»u nÆ¡-ron hÆ¡n thÃ¬ há»c Ä‘Æ°á»£c Ä‘áº·c trÆ°ng phá»©c táº¡p hÆ¡n nhÆ°ng tá»‘n thá»i gian hÆ¡n.  
            - **learning_rate_init**:  
              - **Ã nghÄ©a**: Tá»‘c Ä‘á»™ há»c ban Ä‘áº§u (vÃ­ dá»¥: $0.001$).  
              - **CÃ´ng dá»¥ng**: Äiá»u chá»‰nh tá»‘c Ä‘á»™ cáº­p nháº­t trá»ng sá»‘; nhá» hÆ¡n thÃ¬ há»c cháº­m nhÆ°ng á»•n Ä‘á»‹nh hÆ¡n.  
            - **max_iter**:  
              - **Ã nghÄ©a**: Sá»‘ láº§n huáº¥n luyá»‡n tá»‘i Ä‘a (vÃ­ dá»¥: $200$).  
              - **CÃ´ng dá»¥ng**: Giá»›i háº¡n sá»‘ láº§n mÃ´ hÃ¬nh há»c qua dá»¯ liá»‡u Ä‘á»ƒ Ä‘áº¡t Ä‘á»™ chÃ­nh xÃ¡c mong muá»‘n.  
            """, unsafe_allow_html=True)

            st.subheader("ğŸŸª Æ¯u Ä‘iá»ƒm vÃ  nhÆ°á»£c Ä‘iá»ƒm")
            st.markdown("""
            ##### âœ… **Æ¯u Ä‘iá»ƒm**:  
            - Há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p tá»« dá»¯ liá»‡u hÃ¬nh áº£nh nhÆ° MNIST.  
            - Dá»… sá»­ dá»¥ng vá»›i cÃ¡c tham sá»‘ cÆ¡ báº£n Ä‘Æ°á»£c tá»‘i Æ°u sáºµn.  

            ##### âŒ **NhÆ°á»£c Ä‘iá»ƒm**:  
            - Tá»‘n thá»i gian huáº¥n luyá»‡n náº¿u sá»‘ máº«u lá»›n hoáº·c sá»‘ nÆ¡-ron nhiá»u.  
            - Cáº§n dá»¯ liá»‡u Ä‘Æ°á»£c chuáº©n hÃ³a Ä‘á»ƒ Ä‘áº¡t hiá»‡u quáº£ tá»‘t nháº¥t.  
            """, unsafe_allow_html=True)

        elif info_option == "CÃ´ng thá»©c Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c (Accuracy)":
            st.subheader("ğŸ“˜ 4. CÃ´ng thá»©c Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c (Accuracy)")
            st.markdown("""
            Äá»™ chÃ­nh xÃ¡c (**Accuracy**) Ä‘o tá»· lá»‡ dá»± Ä‘oÃ¡n Ä‘Ãºng:  
            $$ \\text{Accuracy} = \\frac{\\text{Sá»‘ máº«u dá»± Ä‘oÃ¡n Ä‘Ãºng}}{\\text{Tá»•ng sá»‘ máº«u}} $$  
            - **VÃ­ dá»¥**: Dá»± Ä‘oÃ¡n Ä‘Ãºng $92/100$ áº£nh â†’ $\\text{Accuracy} = 92\\%$.  
            - **Ã nghÄ©a**: Vá»›i Neural Network, Accuracy Ä‘o kháº£ nÄƒng mÃ´ hÃ¬nh phÃ¢n loáº¡i Ä‘Ãºng cÃ¡c chá»¯ sá»‘ dá»±a trÃªn Ä‘áº·c trÆ°ng pixel há»c Ä‘Æ°á»£c.  
            """, unsafe_allow_html=True)

    # Tab 2: Táº£i dá»¯ liá»‡u
    with tab_load:
        st.header("Táº£i Dá»¯ liá»‡u MNIST")
        st.markdown("""
        Pháº§n nÃ y cho phÃ©p táº£i dá»¯ liá»‡u MNIST tá»« OpenML vÃ  chá»n sá»‘ lÆ°á»£ng máº«u Ä‘á»ƒ xá»­ lÃ½. Tá»•ng cá»™ng cÃ³ $70,000$ máº«u, báº¡n cÃ³ thá»ƒ chá»n má»™t pháº§n nhá» hÆ¡n Ä‘á»ƒ giáº£m thá»i gian tÃ­nh toÃ¡n.
        """, unsafe_allow_html=True)

        if st.button("Táº£i dá»¯ liá»‡u MNIST tá»« OpenML"):
            with st.spinner("Äang táº£i dá»¯ liá»‡u tá»« OpenML..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                try:
                    mnist = openml.datasets.get_dataset(554)
                    progress_bar.progress(20)
                    status_text.text("ÄÃ£ táº£i 20% - Äang láº¥y dá»¯ liá»‡u...")

                    X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute)
                    progress_bar.progress(50)
                    status_text.text("ÄÃ£ táº£i 50% - Äang xá»­ lÃ½ dá»¯ liá»‡u...")

                    st.session_state['full_data'] = (X, y)
                    progress_bar.progress(90)
                    status_text.text(f"ÄÃ£ táº£i 90% - HoÃ n táº¥t {X.shape[0]} máº«u...")

                    with mlflow.start_run(run_name="Data_Load"):
                        mlflow.log_param("total_samples", X.shape[0])

                    progress_bar.progress(100)
                    status_text.text("ÄÃ£ táº£i 100% - HoÃ n táº¥t!")
                    time.sleep(1)
                    status_text.empty()
                    progress_bar.empty()
                    st.success("Táº£i dá»¯ liá»‡u thÃ nh cÃ´ng!")
                    st.write("KÃ­ch thÆ°á»›c dá»¯ liá»‡u gá»‘c:", X.shape)
                except Exception as e:
                    st.error(f"KhÃ´ng thá»ƒ táº£i dá»¯ liá»‡u: {e}")

        if 'full_data' in st.session_state:
            X_full, y_full = st.session_state['full_data']
            num_samples = st.slider("Chá»n sá»‘ lÆ°á»£ng máº«u:", 
                                    min_value=10, max_value=len(X_full), value=min(1000, len(X_full)), step=1)
            if st.button("XÃ¡c nháº­n sá»‘ lÆ°á»£ng máº«u"):
                with st.spinner(f"Äang xá»­ lÃ½ {num_samples} máº«u..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()

                    df = pd.concat([X_full, y_full.rename("label")], axis=1)
                    progress_bar.progress(30)
                    status_text.text("Äang xá»­ lÃ½ 30% - Äang káº¿t há»£p dá»¯ liá»‡u...")

                    sampled_df = df.sample(n=num_samples, random_state=42)
                    progress_bar.progress(70)
                    status_text.text("Äang xá»­ lÃ½ 70% - Äang láº¥y máº«u ngáº«u nhiÃªn...")

                    X_sampled = sampled_df.drop(columns=["label"])
                    y_sampled = sampled_df["label"]
                    st.session_state['data'] = (X_sampled, y_sampled)
                    progress_bar.progress(90)
                    status_text.text("Äang xá»­ lÃ½ 90% - Äang lÆ°u trá»¯ dá»¯ liá»‡u...")

                    with mlflow.start_run(run_name="Data_Sample"):
                        mlflow.log_param("num_samples", num_samples)

                    progress_bar.progress(100)
                    status_text.text("ÄÃ£ xá»­ lÃ½ 100% - HoÃ n táº¥t!")
                    time.sleep(1)
                    status_text.empty()
                    progress_bar.empty()
                    st.success(f"ÄÃ£ chá»n {num_samples} máº«u Ä‘á»ƒ xá»­ lÃ½!")

    # Tab 3: Xá»­ lÃ½ dá»¯ liá»‡u
    with tab_preprocess:
        st.header("Xá»­ lÃ½ Dá»¯ liá»‡u")
        st.markdown("""
        Pháº§n nÃ y cho phÃ©p báº¡n chuáº©n hÃ³a dá»¯ liá»‡u Ä‘á»ƒ cáº£i thiá»‡n hiá»‡u suáº¥t cá»§a Neural Network.
        """, unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui lÃ²ng táº£i dá»¯ liá»‡u tá»« tab 'Táº£i dá»¯ liá»‡u' trÆ°á»›c khi xá»­ lÃ½.")
        else:
            X, y = st.session_state['data']
            if "data_original" not in st.session_state:
                st.session_state["data_original"] = (X.copy(), y.copy())

            st.subheader("ğŸ“· Dá»¯ liá»‡u Gá»‘c")
            st.markdown("""
            DÆ°á»›i Ä‘Ã¢y lÃ  $10$ máº«u Ä‘áº§u tiÃªn tá»« dá»¯ liá»‡u gá»‘c Ä‘á»ƒ báº¡n hÃ¬nh dung:
            """, unsafe_allow_html=True)
            fig, axes = plt.subplots(2, 5, figsize=(10, 4))
            for i, ax in enumerate(axes.flat):
                ax.imshow(X.iloc[i].values.reshape(28, 28), cmap='gray')
                ax.set_title(f"NhÃ£n: {y.iloc[i]}")
                ax.axis("off")
            st.pyplot(fig)

            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("Chuáº©n hÃ³a (Normalization)", key="normalize_btn"):
                    X_norm = X / 255.0
                    st.session_state["data_processed"] = (X_norm, y)
                    st.success("ÄÃ£ chuáº©n hÃ³a dá»¯ liá»‡u!")
                    st.rerun()
            with col2:
                st.markdown("""
                **Chuáº©n hÃ³a**:  
                ÄÆ°a giÃ¡ trá»‹ pixel vá» khoáº£ng $[0, 1]$ báº±ng cÃ¡ch chia cho $255$.  
                - **CÃ´ng dá»¥ng**: Äáº£m báº£o thang Ä‘o Ä‘á»“ng nháº¥t, giÃºp Neural Network há»c tá»‘t hÆ¡n.
                """, unsafe_allow_html=True)

            if "data_processed" in st.session_state:
                X_processed, y_processed = st.session_state["data_processed"]
                st.subheader("ğŸ“· Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½")
                st.markdown("""
                DÆ°á»›i Ä‘Ã¢y lÃ  $10$ máº«u Ä‘áº§u tiÃªn sau khi chuáº©n hÃ³a:
                """, unsafe_allow_html=True)
                fig, axes = plt.subplots(2, 5, figsize=(10, 4))
                for i, ax in enumerate(axes.flat):
                    ax.imshow(X_processed.iloc[i].values.reshape(28, 28), cmap='gray')
                    ax.set_title(f"NhÃ£n: {y_processed.iloc[i]}")
                    ax.axis("off")
                st.pyplot(fig)

    # Tab 4: Chia dá»¯ liá»‡u
    with tab_split:
        st.header("Chia Táº­p Dá»¯ liá»‡u")
        st.markdown("""
        Pháº§n nÃ y giÃºp báº¡n chia dá»¯ liá»‡u thÃ nh cÃ¡c táº­p huáº¥n luyá»‡n (Train), kiá»ƒm Ä‘á»‹nh (Validation), vÃ  kiá»ƒm tra (Test).
        """, unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui lÃ²ng táº£i vÃ  chá»‘t sá»‘ lÆ°á»£ng máº«u trÆ°á»›c.")
        else:
            data_source = st.session_state.get("data_processed", st.session_state['data'])
            X, y = data_source
            total_samples = len(X)
            st.write(f"Tá»•ng sá»‘ máº«u: ${total_samples}$")

            test_pct = st.slider("Tá»· lá»‡ táº­p Test (%)", 0, 100, 20)
            valid_pct = st.slider("Tá»· lá»‡ táº­p Validation (%) tá»« pháº§n cÃ²n láº¡i", 0, 100, 20)
            
            if test_pct + valid_pct > 100:
                st.warning("Tá»•ng tá»· lá»‡ Test vÃ  Validation vÆ°á»£t quÃ¡ $100\\%$!")
            
            test_size = int(total_samples * test_pct / 100)
            if test_size > 0:
                X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size / total_samples, random_state=42)
            else:
                X_temp, y_temp = X, y
                X_test, y_test = pd.DataFrame(), pd.Series()

            valid_size = int(len(X_temp) * valid_pct / 100)
            if valid_size > 0 and len(X_temp) > valid_size:
                X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=valid_size / len(X_temp), random_state=42)
            else:
                X_train, y_train = X_temp, y_temp
                X_valid, y_valid = pd.DataFrame(), pd.Series()

            st.write(f"Train: ${len(X_train)}$ máº«u, Validation: ${len(X_valid)}$ máº«u, Test: ${len(X_test)}$ máº«u")
            if st.button("XÃ¡c nháº­n chia dá»¯ liá»‡u"):
                st.session_state['split_data'] = {
                    "X_train": X_train, "y_train": y_train,
                    "X_valid": X_valid, "y_valid": y_valid,
                    "X_test": X_test, "y_test": y_test
                }
                st.success("Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia!")

    # Tab 5: Huáº¥n luyá»‡n/ÄÃ¡nh giÃ¡
    with tab_train_eval:
        st.header("Huáº¥n luyá»‡n vÃ  ÄÃ¡nh giÃ¡")
        st.markdown("""
        Pháº§n nÃ y giÃºp báº¡n huáº¥n luyá»‡n mÃ´ hÃ¬nh Neural Network cÆ¡ báº£n vÃ  kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c.  
        Chá»‰ cáº§n chá»n vÃ i tham sá»‘ Ä‘Æ¡n giáº£n, cÃ²n láº¡i Ä‘Ã£ Ä‘Æ°á»£c tá»‘i Æ°u sáºµn!
        """, unsafe_allow_html=True)

        if 'split_data' not in st.session_state:
            st.info("Vui lÃ²ng chia dá»¯ liá»‡u tá»« tab 'Chia dá»¯ liá»‡u' trÆ°á»›c.")
        else:
            X_train = st.session_state['split_data']["X_train"]
            num_samples = len(X_train)
            st.write(f"Sá»‘ lÆ°á»£ng máº«u huáº¥n luyá»‡n: ${num_samples}$")

            st.subheader("âš™ï¸ Thiáº¿t láº­p mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n")
            st.markdown("""
            Báº¡n chá»‰ cáº§n chá»n 3 tham sá»‘ cÆ¡ báº£n. CÃ¡c cÃ i Ä‘áº·t khÃ¡c Ä‘Ã£ Ä‘Æ°á»£c tá»± Ä‘á»™ng tá»‘i Æ°u cho bÃ i toÃ¡n MNIST!
            """, unsafe_allow_html=True)

            # Gá»£i Ã½ tham sá»‘ dá»±a trÃªn sá»‘ máº«u
            if num_samples < 1000:
                default_hidden_size = 64
                default_max_iter = 100
                default_lr = 0.01
            elif 1000 <= num_samples <= 5000:
                default_hidden_size = 128
                default_max_iter = 200
                default_lr = 0.001
            else:
                default_hidden_size = 256
                default_max_iter = 300
                default_lr = 0.001

            # NgÆ°á»i dÃ¹ng nháº­p tham sá»‘
            hidden_size = st.number_input("Sá»‘ nÆ¡-ron lá»›p áº©n", min_value=10, max_value=500, value=default_hidden_size, step=10,
                                          help="Sá»‘ nÆ¡-ron cÃ ng lá»›n, mÃ´ hÃ¬nh cÃ ng máº¡nh nhÆ°ng tá»‘n thá»i gian hÆ¡n.")
            max_iter = st.number_input("Sá»‘ láº§n huáº¥n luyá»‡n tá»‘i Ä‘a", min_value=50, max_value=500, value=default_max_iter, step=10,
                                       help="Sá»‘ láº§n mÃ´ hÃ¬nh há»c qua dá»¯ liá»‡u. Nhiá»u hÆ¡n thÃ¬ chÃ­nh xÃ¡c hÆ¡n nhÆ°ng lÃ¢u hÆ¡n.")
            lr = st.selectbox("Tá»‘c Ä‘á»™ há»c", [0.01, 0.001, 0.0001], index=[0.01, 0.001, 0.0001].index(default_lr),
                              help="Tá»‘c Ä‘á»™ há»c cÃ ng nhá» thÃ¬ mÃ´ hÃ¬nh há»c cháº­m nhÆ°ng á»•n Ä‘á»‹nh hÆ¡n.")

            # NÃºt huáº¥n luyá»‡n
            if st.button("Báº¯t Ä‘áº§u huáº¥n luyá»‡n"):
                with st.spinner("Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    start_time = time.time()

                    X_train = st.session_state['split_data']["X_train"]
                    y_train = st.session_state['split_data']["y_train"]
                    X_valid = st.session_state['split_data']["X_valid"]
                    y_valid = st.session_state['split_data']["y_valid"]
                    X_test = st.session_state['split_data']["X_test"]
                    y_test = st.session_state['split_data']["y_test"]

                    # Äá»‹nh nghÄ©a mÃ´ hÃ¬nh vá»›i tham sá»‘ máº·c Ä‘á»‹nh
                    pipeline = Pipeline([
                        ('imputer', SimpleImputer(strategy='mean')),
                        ('classifier', MLPClassifier(
                            hidden_layer_sizes=(hidden_size,),  # Chá»‰ 1 lá»›p áº©n
                            activation='relu',                  # Máº·c Ä‘á»‹nh
                            solver='adam',                      # Máº·c Ä‘á»‹nh
                            learning_rate_init=lr,
                            max_iter=max_iter
                        ))
                    ])

                    # Huáº¥n luyá»‡n
                    pipeline.fit(X_train, y_train)
                    model = pipeline

                    # Ghi log vá»›i MLflow
                    run_name = f"SimpleNN_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    with mlflow.start_run(run_name=run_name) as run:
                        mlflow.log_param("hidden_size", hidden_size)
                        mlflow.log_param("max_iter", max_iter)
                        mlflow.log_param("learning_rate", lr)

                        # Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
                        y_valid_pred = model.predict(X_valid)
                        accuracy_val = accuracy_score(y_valid, y_valid_pred)
                        mlflow.log_metric("accuracy_val", accuracy_val)
                        cm_valid = confusion_matrix(y_valid, y_valid_pred)

                        y_test_pred = model.predict(X_test)
                        accuracy_test = accuracy_score(y_test, y_test_pred)
                        mlflow.log_metric("accuracy_test", accuracy_test)
                        cm_test = confusion_matrix(y_test, y_test_pred)

                        training_time = time.time() - start_time
                        mlflow.log_metric("training_time_seconds", training_time)
                        mlflow.sklearn.log_model(model, "model")

                        run_id = run.info.run_id
                        st.session_state['model'] = model
                        st.session_state['training_results'] = {
                            'training_time': training_time,
                            'accuracy_val': accuracy_val,
                            'accuracy_test': accuracy_test,
                            'cm_valid': cm_valid,
                            'cm_test': cm_test,
                            'run_name': run_name,
                            'run_id': run_id
                        }

                    progress_bar.progress(100)
                    status_text.text("HoÃ n táº¥t!")
                    time.sleep(1)
                    status_text.empty()
                    progress_bar.empty()

            # Hiá»ƒn thá»‹ káº¿t quáº£
            if 'training_results' in st.session_state:
                st.success(f"Huáº¥n luyá»‡n hoÃ n táº¥t! Thá»i gian: ${st.session_state['training_results']['training_time']:.2f}$ giÃ¢y.")
                st.write(f"Äá»™ chÃ­nh xÃ¡c Validation: ${st.session_state['training_results']['accuracy_val']:.4f}$")
                st.write(f"Äá»™ chÃ­nh xÃ¡c Test: ${st.session_state['training_results']['accuracy_test']:.4f}$")

                st.subheader("ğŸ“Š Ma tráº­n nháº§m láº«n (Confusion Matrix)")
                fig, ax = plt.subplots()
                sns.heatmap(st.session_state['training_results']['cm_valid'], annot=True, fmt="d", cmap="Blues", ax=ax)
                ax.set_title("Ma tráº­n nháº§m láº«n - Validation")
                st.pyplot(fig)

                fig, ax = plt.subplots()
                sns.heatmap(st.session_state['training_results']['cm_test'], annot=True, fmt="d", cmap="Blues", ax=ax)
                ax.set_title("Ma tráº­n nháº§m láº«n - Test")
                st.pyplot(fig)

    # Tab 6: Demo dá»± Ä‘oÃ¡n
    with tab_demo:
        st.header("Demo Dá»± Ä‘oÃ¡n")
        st.markdown("""
        Pháº§n nÃ y cho phÃ©p báº¡n thá»­ nghiá»‡m dá»± Ä‘oÃ¡n vá»›i dá»¯ liá»‡u Test, áº£nh upload, hoáº·c sá»‘ báº¡n váº½.
        """, unsafe_allow_html=True)

        if 'split_data' not in st.session_state or 'model' not in st.session_state:
            st.info("Vui lÃ²ng huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")
        else:
            mode = st.radio("Chá»n phÆ°Æ¡ng thá»©c dá»± Ä‘oÃ¡n:", ["Dá»¯ liá»‡u tá»« Test", "Upload áº£nh má»›i", "Váº½ sá»‘"])
            
            def preprocess_input(data):
                return data / 255.0

            is_normalized = "data_processed" in st.session_state

            if mode == "Dá»¯ liá»‡u tá»« Test":
                X_test = st.session_state['split_data']["X_test"]
                y_test = st.session_state['split_data']["y_test"]
                idx = st.slider("Chá»n máº«u tá»« Test", 0, len(X_test)-1, 0)
                if st.button("Dá»± Ä‘oÃ¡n"):
                    with st.spinner("Äang dá»± Ä‘oÃ¡n..."):
                        sample = X_test.iloc[idx].values.reshape(1, -1)
                        if not is_normalized:
                            sample = preprocess_input(sample)
                        
                        prediction = st.session_state['model'].predict(sample)[0]
                        proba = st.session_state['model'].predict_proba(sample)[0]
                        confidence = max(proba) * 100
                        y_true = y_test.iloc[idx]
                        
                        st.success(f"Dá»± Ä‘oÃ¡n: **${prediction}$** | Äá»™ tin cáº­y: **${confidence:.2f}\\%$** | GiÃ¡ trá»‹ thá»±c: **${y_true}$**")
                        fig, ax = plt.subplots()
                        ax.imshow(X_test.iloc[idx].values.reshape(28, 28), cmap='gray')
                        ax.axis("off")
                        st.pyplot(fig)

            elif mode == "Upload áº£nh má»›i":
                uploaded_images = st.file_uploader("Upload áº£nh ($28\\times28$, grayscale)", type=["png", "jpg"], accept_multiple_files=True)
                if uploaded_images:
                    for i, uploaded_image in enumerate(uploaded_images):
                        with st.spinner(f"Äang xá»­ lÃ½ áº£nh {i+1}/{len(uploaded_images)}..."):
                            img = Image.open(uploaded_image).convert('L').resize((28, 28))
                            img_array = np.array(img).flatten().reshape(1, -1)
                            if not is_normalized:
                                img_array = preprocess_input(img_array)
                            
                            prediction = st.session_state['model'].predict(img_array)[0]
                            proba = st.session_state['model'].predict_proba(img_array)[0]
                            confidence = max(proba) * 100
                            
                            st.success(f"Dá»± Ä‘oÃ¡n: **${prediction}$** | Äá»™ tin cáº­y: **${confidence:.2f}\\%$**")
                            st.image(img, caption=f"áº¢nh {i+1} Ä‘Æ°á»£c upload", use_container_width=True)

            elif mode == "Váº½ sá»‘":
                st.write("Váº½ má»™t chá»¯ sá»‘ tá»« $0$-$9$ trÃªn canvas bÃªn dÆ°á»›i ($28\\times28$ pixel):")
                canvas_result = st_canvas(
                    fill_color="black",
                    stroke_width=20,
                    stroke_color="white",
                    background_color="black",
                    width=280,
                    height=280,
                    drawing_mode="freedraw",
                    key="canvas"
                )
                if st.button("Dá»± Ä‘oÃ¡n sá»‘ Ä‘Ã£ váº½"):
                    if canvas_result.image_data is not None:
                        with st.spinner("Äang xá»­ lÃ½ váº½..."):
                            img = Image.fromarray((canvas_result.image_data * 255).astype(np.uint8)).convert('L').resize((28, 28))
                            img_array = np.array(img).flatten().reshape(1, -1)
                            if not is_normalized:
                                img_array = preprocess_input(img_array)
                            
                            prediction = st.session_state['model'].predict(img_array)[0]
                            proba = st.session_state['model'].predict_proba(img_array)[0]
                            confidence = max(proba) * 100
                            
                            st.success(f"Dá»± Ä‘oÃ¡n: **${prediction}$** | Äá»™ tin cáº­y: **${confidence:.2f}\\%$**")
                    else:
                        st.warning("Vui lÃ²ng váº½ má»™t chá»¯ sá»‘ trÆ°á»›c khi dá»± Ä‘oÃ¡n!")

    # Tab 7: ThÃ´ng tin huáº¥n luyá»‡n
    with tab_log_info:
        st.header("Theo dÃµi káº¿t quáº£")
        st.markdown("""
        Tab nÃ y cho phÃ©p báº¡n xem danh sÃ¡ch cÃ¡c láº§n huáº¥n luyá»‡n Ä‘Ã£ thá»±c hiá»‡n vÃ  chi tiáº¿t tá»«ng láº§n cháº¡y.
        """, unsafe_allow_html=True)

        try:
            client = MlflowClient()
            experiment = client.get_experiment_by_name("Neural Network ")
            if not experiment:
                st.error("KhÃ´ng tÃ¬m tháº¥y experiment 'Neural Network '.")
            else:
                runs = client.search_runs(experiment_ids=[experiment.experiment_id], order_by=["attributes.start_time DESC"])
                if not runs:
                    st.info("ChÆ°a cÃ³ láº§n cháº¡y nÃ o Ä‘Æ°á»£c ghi nháº­n.")
                else:
                    run_options = {run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") for run in runs}
                    selected_run_name = st.selectbox("Chá»n run:", list(run_options.values()))
                    selected_run_id = [k for k, v in run_options.items() if v == selected_run_name][0]
                    selected_run = client.get_run(selected_run_id)

                    st.subheader("ğŸ“˜ ThÃ´ng tin chi tiáº¿t")
                    st.write(f"**TÃªn láº§n cháº¡y:** {selected_run_name}")
                    st.write(f"**ID láº§n cháº¡y:** {selected_run_id}")
                    st.write(f"**Thá»i gian báº¯t Ä‘áº§u:** {datetime.fromtimestamp(selected_run.info.start_time / 1000)}")
                    st.markdown("**Tham sá»‘:**", unsafe_allow_html=True)
                    st.json(selected_run.data.params, expanded=True)
                    st.markdown("**Káº¿t quáº£:**", unsafe_allow_html=True)
                    st.json(selected_run.data.metrics, expanded=True)

        except Exception as e:
            st.error(f"Lá»—i káº¿t ná»‘i MLflow: {e}")

if __name__ == "__main__":
    run_mnist_neural_network_app()