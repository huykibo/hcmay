import os
import mlflow
import streamlit as st
import openml
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.neural_network import MLPClassifier
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from datetime import datetime
import time

def run_mnist_neural_network_app():
    # Thi·∫øt l·∫≠p MLflow
    try:
        os.environ["MLFLOW_TRACKING_USERNAME"] = st.secrets["mlflow"]["MLFLOW_TRACKING_USERNAME"]
        os.environ["MLFLOW_TRACKING_PASSWORD"] = st.secrets["mlflow"]["MLFLOW_TRACKING_PASSWORD"]
        mlflow.set_tracking_uri(st.secrets["mlflow"]["MLFLOW_TRACKING_URI"])
    except KeyError as e:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y kh√≥a {e} trong st.secrets. Vui l√≤ng c·∫•u h√¨nh secrets.")
        st.stop()

    st.title("Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Neural Network")

    # CSS cho tooltip v√† MathJax
    st.markdown("""
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
        <style>
            .tooltip {
                position: relative;
                display: inline-block;
                cursor: pointer;
                color: #1f77b4;
                font-weight: bold;
                margin-left: 5px;
            }
            .tooltip .tooltiptext {
                visibility: hidden;
                width: 400px;
                background-color: #f9f9f9;
                color: #333;
                text-align: left;
                border-radius: 6px;
                padding: 10px;
                position: absolute;
                z-index: 1;
                right: 105%;
                top: 50%;
                transform: translateY(-50%);
                opacity: 0;
                transition: opacity 0.3s;
                border: 1px solid #ccc;
                font-size: 0.9em;
                line-height: 1.4;
            }
            .tooltip:hover .tooltiptext {
                visibility: visible;
                opacity: 1;
            }
        </style>
    """, unsafe_allow_html=True)

    # C√°c tab
    tabs = st.tabs(["Th√¥ng tin", "T·∫£i d·ªØ li·ªáu", "X·ª≠ l√Ω d·ªØ li·ªáu", "Chia d·ªØ li·ªáu", "Hu·∫•n luy·ªán/ƒê√°nh gi√°", "Demo d·ª± ƒëo√°n", "Th√¥ng tin hu·∫•n luy·ªán"])
    tab_info, tab_load, tab_preprocess, tab_split, tab_train_eval, tab_demo, tab_log_info = tabs

    # Tab 1: Th√¥ng tin
    with tab_info:
        st.header("Gi·ªõi thi·ªáu v·ªÅ ·ª®ng d·ª•ng v√† M·∫°ng Neural Network")
        st.markdown("""
        Ch√†o b·∫°n! ƒê√¢y l√† ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay t·ª´ t·∫≠p d·ªØ li·ªáu **MNIST** b·∫±ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**. H√£y kh√°m ph√° c√°c t√≠nh nƒÉng v√† c√°ch ho·∫°t ƒë·ªông c·ªßa n√≥ nh√©!
        """, unsafe_allow_html=True)

        st.subheader("Ch·ªçn th√¥ng tin ƒë·ªÉ xem")
        info_option = st.selectbox(
            "",
            [
                "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?",
                "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a",
                "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o",
                "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)"
            ],
            label_visibility="collapsed",
            help="Ch·ªçn ƒë·ªÉ xem chi ti·∫øt v·ªÅ ·ª©ng d·ª•ng, d·ªØ li·ªáu, ho·∫∑c m√¥ h√¨nh."
        )

        if info_option == "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?":
            st.subheader("üìò 1. ·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?")
            st.markdown("""
            ƒê√¢y l√† m·ªôt ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu **MNIST**, s·ª≠ d·ª•ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**.  
            - **MNIST**: T·∫≠p d·ªØ li·ªáu g·ªìm $70,000$ ·∫£nh ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$, m·ªói ·∫£nh k√≠ch th∆∞·ªõc $28 \\times 28$ pixel (t·ªïng c·ªông $784$ ƒë·∫∑c tr∆∞ng).  
            - **M·ª•c ti√™u**:  
              - X√¢y d·ª±ng v√† hu·∫•n luy·ªán m·ªôt m·∫°ng n∆°-ron ƒë·ªÉ nh·∫≠n di·ªán ch√≠nh x√°c c√°c ch·ªØ s·ªë.  
              - Cung c·∫•p c√¥ng c·ª• tr·ª±c quan ƒë·ªÉ h·ªçc t·∫≠p v√† ƒë√°nh gi√° hi·ªáu qu·∫£ c·ªßa thu·∫≠t to√°n.  

            **Th√¥ng tin c∆° b·∫£n**:  
            - **$784$ ƒë·∫∑c tr∆∞ng**: M·ªói ·∫£nh ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng vector $784$ chi·ªÅu (gi√° tr·ªã pixel t·ª´ $0$ ƒë·∫øn $255$).  
            - **$70,000$ m·∫´u**: T·ªïng s·ªë ·∫£nh, ƒë∆∞·ª£c chia th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra.  
            - **Nhi·ªám v·ª•**: D·ª± ƒëo√°n nh√£n ($0$-$9$) d·ª±a tr√™n ƒë·∫∑c tr∆∞ng pixel.  
            """, unsafe_allow_html=True)

        elif info_option == "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a":
            st.subheader("üìò 2. T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a")
            st.markdown("""
            **MNIST** l√† t·∫≠p d·ªØ li·ªáu chu·∫©n trong h·ªçc m√°y, ƒë∆∞·ª£c t·∫°o b·ªüi Yann LeCun v√† c√°c c·ªông s·ª±.  
            - **ƒê·∫∑c ƒëi·ªÉm**:  
              - G·ªìm c√°c ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ h·ªçc sinh trung h·ªçc v√† nh√¢n vi√™n ƒëi·ªÅu tra d√¢n s·ªë M·ªπ.  
              - Chu·∫©n h√≥a th√†nh k√≠ch th∆∞·ªõc $28 \\times 28$ pixel, thang ƒë·ªô x√°m (gi√° tr·ªã t·ª´ $0$ ƒë·∫øn $255$).  

            **√ù nghƒ©a**:  
            - L√† b√†i to√°n c∆° b·∫£n ƒë·ªÉ ki·ªÉm tra kh·∫£ nƒÉng ph√¢n lo·∫°i c·ªßa c√°c m√¥ h√¨nh h·ªçc m√°y.  
            - ƒê∆°n gi·∫£n nh∆∞ng ƒë·ªß ph·ª©c t·∫°p ƒë·ªÉ ƒë√°nh gi√° kh·∫£ nƒÉng ph√¢n bi·ªát c√°c l·ªõp t∆∞∆°ng t·ª± (v√≠ d·ª•: "$4$" v√† "$9$").  
            - Ph√π h·ª£p cho c·∫£ ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu v√† nghi√™n c·ª©u m√¥ h√¨nh ph·ª©c t·∫°p.  
            """, unsafe_allow_html=True)

            st.subheader("üì∑ Minh h·ªça d·ªØ li·ªáu MNIST")
            st.markdown("""
            D∆∞·ªõi ƒë√¢y l√† ·∫£nh minh h·ªça $10$ ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$ t·ª´ t·∫≠p d·ªØ li·ªáu MNIST ƒë·ªÉ b·∫°n h√¨nh dung. M·ªói ch·ªØ s·ªë ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n $28 \\times 28$ pixel.
            """, unsafe_allow_html=True)
            with st.spinner("ƒêang t·∫£i ·∫£nh minh h·ªça..."):
                try:
                    mnist_image = Image.open("mnist.png")
                    st.image(mnist_image, caption="·∫¢nh minh h·ªça $10$ ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$ trong MNIST", width=800)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y file `mnist.png`. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

        elif info_option == "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o":
            st.subheader("üìä 3. Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o")
            st.markdown("""
            **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o)** l√† m·ªôt m√¥ h√¨nh h·ªçc m√°y m√¥ ph·ªèng c√°ch ho·∫°t ƒë·ªông c·ªßa m·∫°ng n∆°-ron sinh h·ªçc trong n√£o ng∆∞·ªùi.  
            - **C·∫•u tr√∫c**: G·ªìm c√°c **n∆°-ron nh√¢n t·∫°o** (nodes) ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh c√°c **l·ªõp (layers)**:  
              - **L·ªõp ƒë·∫ßu v√†o (Input Layer)**: Nh·∫≠n d·ªØ li·ªáu ($784$ pixel t·ª´ ·∫£nh MNIST).  
              - **L·ªõp ·∫©n (Hidden Layers)**: X·ª≠ l√Ω th√¥ng tin b·∫±ng c√°ch k·∫øt h·ª£p tuy·∫øn t√≠nh v√† √°p d·ª•ng h√†m k√≠ch ho·∫°t phi tuy·∫øn.  
              - **L·ªõp ƒë·∫ßu ra (Output Layer)**: ƒê∆∞a ra d·ª± ƒëo√°n (nh√£n t·ª´ $0$-$9$).  

            Neural Network ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ v·ªõi b√†i to√°n MNIST nh·ªù kh·∫£ nƒÉng h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu h√¨nh ·∫£nh.
            """, unsafe_allow_html=True)

            st.subheader("üõ†Ô∏è C√°c b∆∞·ªõc th·ª±c hi·ªán trong Neural Network")
            st.markdown("""
            1. **Kh·ªüi t·∫°o m√¥ h√¨nh**:  
               - X√°c ƒë·ªãnh c·∫•u tr√∫c m·∫°ng (s·ªë l·ªõp ·∫©n, s·ªë n∆°-ron m·ªói l·ªõp).  
               - Kh·ªüi t·∫°o **tr·ªçng s·ªë** $W$ v√† **bias** $b$ ng·∫´u nhi√™n ho·∫∑c b·∫±ng $0$.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step1_init.png"), caption="Minh h·ªça B∆∞·ªõc 1: Kh·ªüi t·∫°o m√¥ h√¨nh", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 1. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            2. **Lan truy·ªÅn thu·∫≠n (Feedforward)**:  
               - T√≠nh gi√° tr·ªã d·ª± ƒëo√°n $\\hat{Y}$ t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o $X$:  
                 - **L·ªõp ƒë·∫ßu v√†o**: $A^{(0)} = X$ (ma tr·∫≠n $N \\times 784$, $N$ l√† s·ªë m·∫´u).  
                 - **Cho m·ªói l·ªõp $l$**:  
                   - T·ªïng tuy·∫øn t√≠nh:  
                     $$ Z^{(l)} = A^{(l-1)} \\cdot W^{(l)} + b^{(l)} $$  
                   - √Åp d·ª•ng h√†m k√≠ch ho·∫°t:  
                     $$ A^{(l)} = \\sigma(Z^{(l)}) $$  
                 - **L·ªõp ƒë·∫ßu ra**: $\\hat{Y} = A^{(L)}$ (ma tr·∫≠n $N \\times 10$).  
               - V√≠ d·ª• h√†m k√≠ch ho·∫°t **sigmoid**:  
                 $$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step2_feedforward.png"), caption="Minh h·ªça B∆∞·ªõc 2: Lan truy·ªÅn thu·∫≠n", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 2. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            3. **T√≠nh h√†m m·∫•t m√°t (Loss Function)**:  
               - ƒêo ƒë·ªô sai l·ªách gi·ªØa $\\hat{Y}$ v√† $Y$ (gi√° tr·ªã th·ª±c). V·ªõi MNIST, d√πng **Cross-Entropy**:  
                 $$ L = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=0}^{9} y_{ij} \\cdot \\log(\\hat{y}_{ij}) $$  
               - Trong ƒë√≥:  
                 - $y_{ij}$: Nh√£n th·ª±c (d·∫°ng one-hot encoded).  
                 - $\\hat{y}_{ij}$: X√°c su·∫•t d·ª± ƒëo√°n cho l·ªõp $j$.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step3_loss.png"), caption="Minh h·ªça B∆∞·ªõc 3: T√≠nh h√†m m·∫•t m√°t", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 3. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            4. **Lan truy·ªÅn ng∆∞·ª£c (Backpropagation)**:  
               - T√≠nh ƒë·∫°o h√†m c·ªßa $L$ theo $W^{(l)}$ v√† $b^{(l)}$ ƒë·ªÉ c·∫≠p nh·∫≠t tham s·ªë:  
                 - T·∫°i **L·ªõp ƒë·∫ßu ra**:  
                   $$ \\delta^{(L)} = \\hat{Y} - Y $$  
                 - T·∫°i **L·ªõp ·∫©n**:  
                   $$ \\delta^{(l)} = (\\delta^{(l+1)} \\cdot (W^{(l+1)})^T) \\odot \\sigma'(Z^{(l)}) $$  
                   - $\\sigma'(z)$: ƒê·∫°o h√†m h√†m k√≠ch ho·∫°t (v·ªõi sigmoid: $\\sigma'(z) = \\sigma(z) \\cdot (1 - \\sigma(z))$).  
                 - ƒê·∫°o h√†m theo tr·ªçng s·ªë v√† bias:  
                   $$ \\frac{\\partial L}{\\partial W^{(l)}} = (A^{(l-1)})^T \\cdot \\delta^{(l)} $$  
                   $$ \\frac{\\partial L}{\\partial b^{(l)}} = \\sum_{i=1}^{N} \\delta^{(l)}_i $$
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step4_backprop.png"), caption="Minh h·ªça B∆∞·ªõc 4: Lan truy·ªÅn ng∆∞·ª£c", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 4. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            5. **C·∫≠p nh·∫≠t tham s·ªë (Gradient Descent)**:  
               - ƒêi·ªÅu ch·ªânh $W$ v√† $b$ ƒë·ªÉ gi·∫£m m·∫•t m√°t:  
                 $$ W^{(l)} = W^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial W^{(l)}} $$  
                 $$ b^{(l)} = b^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial b^{(l)}} $$  
               - Trong ƒë√≥: $\\eta$ l√† **t·ªëc ƒë·ªô h·ªçc (learning rate)**.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step5_gradient.png"), caption="Minh h·ªça B∆∞·ªõc 5: C·∫≠p nh·∫≠t tham s·ªë", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 5. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.markdown("""
            6. **L·∫∑p l·∫°i**:  
               - Quay l·∫°i b∆∞·ªõc $2$ qua nhi·ªÅu **epoch** cho ƒë·∫øn khi $L$ h·ªôi t·ª•.  
            """, unsafe_allow_html=True)
            try:
                st.image(os.path.join("plnw", "step6_repeat_improved.png"), caption="Minh h·ªça B∆∞·ªõc 6: L·∫∑p l·∫°i", width=600)
            except FileNotFoundError:
                st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 6. Vui l√≤ng ch·∫°y m√£ t·∫°o ·∫£nh tr∆∞·ªõc.")

            st.subheader("‚öôÔ∏è C√°c tham s·ªë c∆° b·∫£n v√† c√¥ng d·ª•ng")
            st.markdown("""
            D∆∞·ªõi ƒë√¢y l√† c√°c tham s·ªë b·∫°n s·∫Ω s·ª≠ d·ª•ng ƒë·ªÉ ƒëi·ªÅu ch·ªânh m√¥ h√¨nh trong ·ª©ng d·ª•ng n√†y:  
            - **hidden_layer_sizes**:  
              - **√ù nghƒ©a**: S·ªë n∆°-ron trong l·ªõp ·∫©n (v√≠ d·ª•: $128$).  
              - **C√¥ng d·ª•ng**: Quy·∫øt ƒë·ªãnh s·ª©c m·∫°nh c·ªßa m√¥ h√¨nh; nhi·ªÅu n∆°-ron h∆°n th√¨ h·ªçc ƒë∆∞·ª£c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p h∆°n nh∆∞ng t·ªën th·ªùi gian h∆°n.  
            - **learning_rate_init**:  
              - **√ù nghƒ©a**: T·ªëc ƒë·ªô h·ªçc ban ƒë·∫ßu (v√≠ d·ª•: $0.001$).  
              - **C√¥ng d·ª•ng**: ƒêi·ªÅu ch·ªânh t·ªëc ƒë·ªô c·∫≠p nh·∫≠t tr·ªçng s·ªë; nh·ªè h∆°n th√¨ h·ªçc ch·∫≠m nh∆∞ng ·ªïn ƒë·ªãnh h∆°n.  
            - **max_iter**:  
              - **√ù nghƒ©a**: S·ªë l·∫ßn hu·∫•n luy·ªán t·ªëi ƒëa (v√≠ d·ª•: $200$).  
              - **C√¥ng d·ª•ng**: Gi·ªõi h·∫°n s·ªë l·∫ßn m√¥ h√¨nh h·ªçc qua d·ªØ li·ªáu ƒë·ªÉ ƒë·∫°t ƒë·ªô ch√≠nh x√°c mong mu·ªën.  
            """, unsafe_allow_html=True)

            st.subheader("üü™ ∆Øu ƒëi·ªÉm v√† nh∆∞·ª£c ƒëi·ªÉm")
            st.markdown("""
            ##### ‚úÖ **∆Øu ƒëi·ªÉm**:  
            - H·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu h√¨nh ·∫£nh nh∆∞ MNIST.  
            - D·ªÖ s·ª≠ d·ª•ng v·ªõi c√°c tham s·ªë c∆° b·∫£n ƒë∆∞·ª£c t·ªëi ∆∞u s·∫µn.  

            ##### ‚ùå **Nh∆∞·ª£c ƒëi·ªÉm**:  
            - T·ªën th·ªùi gian hu·∫•n luy·ªán n·∫øu s·ªë m·∫´u l·ªõn ho·∫∑c s·ªë n∆°-ron nhi·ªÅu.  
            - C·∫ßn d·ªØ li·ªáu ƒë∆∞·ª£c chu·∫©n h√≥a ƒë·ªÉ ƒë·∫°t hi·ªáu qu·∫£ t·ªët nh·∫•t.  
            """, unsafe_allow_html=True)

        elif info_option == "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)":
            st.subheader("üìò 4. C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)")
            st.markdown("""
            ƒê·ªô ch√≠nh x√°c (**Accuracy**) ƒëo t·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng:  
            $$ \\text{Accuracy} = \\frac{\\text{S·ªë m·∫´u d·ª± ƒëo√°n ƒë√∫ng}}{\\text{T·ªïng s·ªë m·∫´u}} $$  
            - **V√≠ d·ª•**: D·ª± ƒëo√°n ƒë√∫ng $92/100$ ·∫£nh ‚Üí $\\text{Accuracy} = 92\\%$.  
            - **√ù nghƒ©a**: V·ªõi Neural Network, Accuracy ƒëo kh·∫£ nƒÉng m√¥ h√¨nh ph√¢n lo·∫°i ƒë√∫ng c√°c ch·ªØ s·ªë d·ª±a tr√™n ƒë·∫∑c tr∆∞ng pixel h·ªçc ƒë∆∞·ª£c.  
            """, unsafe_allow_html=True)

    # Tab 2: T·∫£i d·ªØ li·ªáu
    with tab_load:
        st.header("T·∫£i D·ªØ li·ªáu")
        if st.button("T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML"):
            with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ OpenML..."):
                try:
                    mnist = openml.datasets.get_dataset(554)
                    X, y, _, _ = mnist.get_data(target=mnist.default_target_attribute)
                    st.session_state['full_data'] = (X, y)
                    with mlflow.start_run(run_name="Data_Load"):
                        mlflow.log_param("total_samples", X.shape[0])
                    st.success("T·∫£i d·ªØ li·ªáu th√†nh c√¥ng!")
                    st.write("K√≠ch th∆∞·ªõc d·ªØ li·ªáu g·ªëc:", X.shape)
                except Exception as e:
                    st.error(f"Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu: {e}")

        if 'full_data' in st.session_state:
            X_full, y_full = st.session_state['full_data']
            num_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u:", 
                                    min_value=10, max_value=len(X_full), value=min(1000, len(X_full)), step=1)
            if st.button("Ch·ªët s·ªë l∆∞·ª£ng m·∫´u"):
                with st.spinner(f"ƒêang l·∫•y {num_samples} m·∫´u..."):
                    indices = np.random.choice(len(X_full), size=num_samples, replace=False)
                    X_sampled = X_full.iloc[indices]
                    y_sampled = y_full.iloc[indices]
                    st.session_state['data'] = (X_sampled, y_sampled)
                    with mlflow.start_run(run_name="Data_Sample"):
                        mlflow.log_param("num_samples", num_samples)
                    st.success(f"ƒê√£ ch·ªët {num_samples} m·∫´u!")

    # Tab 3: X·ª≠ l√Ω d·ªØ li·ªáu
    with tab_preprocess:
        st.header("X·ª≠ l√≠ D·ªØ li·ªáu")
        if 'data' not in st.session_state:
            st.info("Vui l√≤ng t·∫£i v√† ch·ªët s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc.")
        else:
            X, y = st.session_state['data']
            if "data_original" not in st.session_state:
                st.session_state["data_original"] = (X.copy(), y.copy())

            if "data_processed" in st.session_state:
                data_processed = st.session_state["data_processed"]
                if not (isinstance(data_processed, tuple) and len(data_processed) == 2):
                    st.session_state.pop("data_processed", None)

            st.subheader("D·ªØ li·ªáu G·ªëc")
            fig, axes = plt.subplots(2, 5, figsize=(10, 4))
            for i, ax in enumerate(axes.flat):
                ax.imshow(X.iloc[i].values.reshape(28, 28), cmap='gray')
                ax.set_title(f"Label: {y.iloc[i]}")
                ax.axis("off")
            st.pyplot(fig)

            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("Normalization", key="normalize_btn"):
                    X_norm = X / 255.0
                    st.session_state["data_processed"] = (X_norm, y)
                    st.success("ƒê√£ chu·∫©n ho√° d·ªØ li·ªáu!")
                    st.rerun()
            with col2:
                st.markdown("""
                    <div class="tooltip">
                        ?
                        <span class="tooltiptext">
                            ƒê∆∞a d·ªØ li·ªáu v·ªÅ kho·∫£ng [0, 1] b·∫±ng c√°ch chia cho 255.<br>
                            C√¥ng d·ª•ng: ƒê·∫£m b·∫£o thang ƒëo ƒë·ªìng nh·∫•t, h·ªØu √≠ch cho Neural Network.
                        </span>
                    </div>
                """, unsafe_allow_html=True)

            if "data_processed" in st.session_state:
                data_processed = st.session_state["data_processed"]
                if isinstance(data_processed, tuple) and len(data_processed) == 2:
                    try:
                        X_processed, y_processed = data_processed
                        st.subheader("D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω")
                        fig, axes = plt.subplots(2, 5, figsize=(10, 4))
                        for i, ax in enumerate(axes.flat):
                            ax.imshow(X_processed.iloc[i].values.reshape(28, 28), cmap='gray')
                            ax.set_title(f"Label: {y_processed.iloc[i]}")
                            ax.axis("off")
                        st.pyplot(fig)
                    except (ValueError, TypeError, AttributeError) as e:
                        st.error(f"L·ªói khi hi·ªÉn th·ªã d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω: {e}. Vui l√≤ng th·ª≠ chu·∫©n h√≥a l·∫°i d·ªØ li·ªáu.")
                        st.session_state.pop("data_processed", None)
                else:
                    st.error("D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng. Vui l√≤ng th·ª≠ chu·∫©n h√≥a l·∫°i d·ªØ li·ªáu.")
                    st.session_state.pop("data_processed", None)
            else:
                st.info("D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω. Vui l√≤ng nh·∫•n 'Normalization' ƒë·ªÉ x·ª≠ l√Ω.")

    # Tab 4: Chia d·ªØ li·ªáu
    with tab_split:
        st.header("Chia T·∫≠p D·ªØ li·ªáu")
        if 'data' not in st.session_state:
            st.info("Vui l√≤ng t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            data_source = st.session_state.get('data_processed', st.session_state['data'])
            X, y = data_source
            total_samples = len(X)
            st.write(f"T·ªïng s·ªë m·∫´u: {total_samples}")

            test_pct = st.slider("T·ª∑ l·ªá Test (%)", 0, 50, 20)
            valid_pct = st.slider("T·ª∑ l·ªá Validation (%)", 0, 50, 20)

            test_size = test_pct / 100
            X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
            valid_size = (valid_pct / 100) / (1 - test_size) if test_size < 1 else 0
            X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=valid_size, random_state=42)

            st.write(f"Train: {len(X_train)}, Validation: {len(X_valid)}, Test: {len(X_test)}")
            if st.button("X√°c nh·∫≠n", key="confirm_split_button"):
                st.session_state['split_data'] = {
                    "X_train": X_train, "y_train": y_train,
                    "X_valid": X_valid, "y_valid": y_valid,
                    "X_test": X_test, "y_test": y_test
                }
                st.success("ƒê√£ chia d·ªØ li·ªáu!")

    # Tab 5: Hu·∫•n luy·ªán/ƒê√°nh gi√°
    with tab_train_eval:
        st.header("Hu·∫•n luy·ªán v√† ƒê√°nh gi√°")
        if 'split_data' not in st.session_state:
            st.info("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            X_train = st.session_state['split_data']["X_train"]
            num_samples = len(X_train)
            st.write(f"S·ªë m·∫´u hu·∫•n luy·ªán: {num_samples}")

            st.subheader("‚öôÔ∏è C√†i ƒë·∫∑t tham s·ªë m√¥ h√¨nh")
            st.markdown("""
            D·ª±a tr√™n s·ªë l∆∞·ª£ng m·∫´u, ƒë√¢y l√† g·ª£i √Ω tham s·ªë t·ªëi ∆∞u:
            | S·ªë m·∫´u       | Hidden Layer Sizes | Learning Rate | Max Iter |
            |--------------|--------------------|---------------|----------|
            | <1000        | 50                | 0.01          | 100      |
            | 1000-5000    | 100               | 0.001         | 200      |
            | >5000        | 200               | 0.0001        | 300      |
            """, unsafe_allow_html=True)

            params = {}
            if num_samples < 1000:
                params["hidden_size"] = 50
                params["learning_rate"] = 0.01
                params["max_iter"] = 100
            elif 1000 <= num_samples <= 5000:
                params["hidden_size"] = 100
                params["learning_rate"] = 0.001
                params["max_iter"] = 200
            else:
                params["hidden_size"] = 200
                params["learning_rate"] = 0.0001
                params["max_iter"] = 300

            params["hidden_size"] = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n", 10, 500, params["hidden_size"])
            params["learning_rate"] = st.selectbox("T·ªëc ƒë·ªô h·ªçc", [0.01, 0.001, 0.0001], index=[0.01, 0.001, 0.0001].index(params["learning_rate"]))
            params["max_iter"] = st.number_input("S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa", 50, 500, params["max_iter"])

            if st.button("Th·ª±c hi·ªán Hu·∫•n luy·ªán", key="train_button"):
                with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
                    start_time = time.time()

                    X_train = st.session_state['split_data']["X_train"]
                    y_train = st.session_state['split_data']["y_train"]
                    X_valid = st.session_state['split_data']["X_valid"]
                    y_valid = st.session_state['split_data']["y_valid"]
                    X_test = st.session_state['split_data']["X_test"]
                    y_test = st.session_state['split_data']["y_test"]

                    pipeline = Pipeline([
                        ('pca', PCA(n_components=50)),
                        ('classifier', MLPClassifier(hidden_layer_sizes=(params["hidden_size"],), 
                                                     max_iter=params["max_iter"], 
                                                     learning_rate_init=params["learning_rate"],
                                                     solver='lbfgs'))
                    ])
                    pipeline.fit(X_train, y_train)

                    run_name = f"NeuralNetwork_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    with mlflow.start_run(run_name=run_name) as run:
                        mlflow.log_param("hidden_size", params["hidden_size"])
                        mlflow.log_param("learning_rate", params["learning_rate"])
                        mlflow.log_param("max_iter", params["max_iter"])

                        y_valid_pred = pipeline.predict(X_valid)
                        y_test_pred = pipeline.predict(X_test)
                        acc_valid = accuracy_score(y_valid, y_valid_pred)
                        acc_test = accuracy_score(y_test, y_test_pred)
                        cm_valid = confusion_matrix(y_valid, y_valid_pred)
                        cm_test = confusion_matrix(y_test, y_test_pred)

                        training_time = time.time() - start_time
                        mlflow.log_metric("accuracy_val", acc_valid)
                        mlflow.log_metric("accuracy_test", acc_test)
                        mlflow.log_metric("training_time_seconds", training_time)
                        mlflow.sklearn.log_model(pipeline, "model")

                        st.session_state['model'] = pipeline
                        st.session_state['training_results'] = {
                            'training_time': training_time,
                            'accuracy_val': acc_valid,
                            'accuracy_test': acc_test,
                            'cm_valid': cm_valid,
                            'cm_test': cm_test,
                            'run_name': run_name,
                            'run_id': run.info.run_id,
                            'params': params
                        }

                    st.success(f"Hu·∫•n luy·ªán ho√†n t·∫•t! Th·ªùi gian: {training_time:.2f} gi√¢y")
                    st.write(f"ƒê·ªô ch√≠nh x√°c Validation: {acc_valid:.4f}")
                    st.write(f"ƒê·ªô ch√≠nh x√°c Test: {acc_test:.4f}")

                    st.subheader("üìà Ma tr·∫≠n nh·∫ßm l·∫´n")
                    fig, ax = plt.subplots()
                    sns.heatmap(cm_valid, annot=True, fmt="d", cmap="Blues", ax=ax)
                    ax.set_title("Confusion Matrix - Validation")
                    st.pyplot(fig)

                    fig, ax = plt.subplots()
                    sns.heatmap(cm_test, annot=True, fmt="d", cmap="Blues", ax=ax)
                    ax.set_title("Confusion Matrix - Test")
                    st.pyplot(fig)

                    st.subheader("‚ÑπÔ∏è Chi ti·∫øt k·∫øt qu·∫£")
                    with st.expander("Xem chi ti·∫øt", expanded=True):
                        st.markdown("#### Th√¥ng tin l·∫ßn ch·∫°y:", unsafe_allow_html=True)
                        st.write(f"- **T√™n l·∫ßn ch·∫°y**: {run_name}")
                        st.write(f"- **ID l·∫ßn ch·∫°y**: {run.info.run_id}")

                        st.markdown("#### Tham s·ªë ƒë√£ ch·ªçn:", unsafe_allow_html=True)
                        st.write(f"- **S·ªë n∆°-ron l·ªõp ·∫©n**: {params['hidden_size']}")
                        st.write(f"- **T·ªëc ƒë·ªô h·ªçc**: {params['learning_rate']}")
                        st.write(f"- **S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa**: {params['max_iter']}")

                        st.markdown("#### K·∫øt qu·∫£ ƒë·∫°t ƒë∆∞·ª£c:", unsafe_allow_html=True)
                        st.write(f"- **ƒê·ªô ch√≠nh x√°c Validation**: {acc_valid*100:.2f}%")
                        st.write(f"- **ƒê·ªô ch√≠nh x√°c Test**: {acc_test*100:.2f}%")

    # Tab 6: Demo d·ª± ƒëo√°n
    with tab_demo:
        st.header("Demo D·ª± ƒëo√°n")
        if 'split_data' not in st.session_state or 'model' not in st.session_state:
            st.info("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
        else:
            mode = st.radio("Ch·ªçn ph∆∞∆°ng th·ª©c:", ["D·ªØ li·ªáu Test", "Upload ·∫£nh", "V·∫Ω s·ªë"])
            progress_bar = st.progress(0)
            status_text = st.empty()

            def preprocess_input(data):
                return data / 255.0

            is_normalized = 'data_processed' in st.session_state

            if mode == "D·ªØ li·ªáu Test":
                X_test = st.session_state['split_data']["X_test"]
                y_test = st.session_state['split_data']["y_test"]
                idx = st.slider("Ch·ªçn m·∫´u Test", 0, len(X_test)-1, 0)
                if st.button("D·ª± ƒëo√°n", key="predict_test_button"):
                    with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                        sample = X_test.iloc[idx].values.reshape(1, -1)
                        if not is_normalized:
                            sample = preprocess_input(sample)
                        pred = st.session_state['model'].predict(sample)[0]
                        true_label = y_test.iloc[idx]
                        st.success(f"D·ª± ƒëo√°n: {pred} | Th·ª±c t·∫ø: {true_label}")
                        fig, ax = plt.subplots()
                        ax.imshow(sample.reshape(28, 28), cmap='gray')
                        ax.axis('off')
                        st.pyplot(fig)

            elif mode == "Upload ·∫£nh":
                uploaded_images = st.file_uploader("Upload ·∫£nh (28x28, grayscale)", type=["png", "jpg"], accept_multiple_files=True)
                if uploaded_images:
                    for i, img_file in enumerate(uploaded_images):
                        with st.spinner(f"ƒêang x·ª≠ l√Ω ·∫£nh {i+1}..."):
                            img = Image.open(img_file).convert('L').resize((28, 28))
                            img_array = np.array(img).flatten().reshape(1, -1)
                            if not is_normalized:
                                img_array = preprocess_input(img_array)
                            pred = st.session_state['model'].predict(img_array)[0]
                            st.success(f"D·ª± ƒëo√°n ·∫£nh {i+1}: {pred}")
                            st.image(img, caption=f"·∫¢nh {i+1}", use_container_width=True)

            elif mode == "V·∫Ω s·ªë":
                st.write("V·∫Ω s·ªë t·ª´ 0-9 (28x28 pixel):")
                canvas_result = st_canvas(
                    fill_color="black", stroke_width=20, stroke_color="white",
                    background_color="black", width=280, height=280, drawing_mode="freedraw", key="canvas"
                )
                if st.button("D·ª± ƒëo√°n", key="predict_draw_button"):
                    if canvas_result.image_data is not None:
                        with st.spinner("ƒêang x·ª≠ l√Ω..."):
                            img = Image.fromarray((canvas_result.image_data * 255).astype(np.uint8)).convert('L').resize((28, 28))
                            img_array = np.array(img).flatten().reshape(1, -1)
                            if not is_normalized:
                                img_array = preprocess_input(img_array)
                            pred = st.session_state['model'].predict(img_array)[0]
                            st.success(f"D·ª± ƒëo√°n: {pred}")
                    else:
                        st.warning("Vui l√≤ng v·∫Ω tr∆∞·ªõc!")

    # Tab 7: Th√¥ng tin hu·∫•n luy·ªán
    with tab_log_info:
        st.header("Theo d√µi K·∫øt qu·∫£")
        st.markdown("""
        Tab n√†y cho ph√©p b·∫°n xem danh s√°ch c√°c l·∫ßn hu·∫•n luy·ªán ƒë√£ th·ª±c hi·ªán t·ª´ Experiment ID 5. Ch·ªçn m·ªôt l·∫ßn ch·∫°y ƒë·ªÉ xem chi ti·∫øt, ƒë·ªïi t√™n ho·∫∑c x√≥a.
        """, unsafe_allow_html=True)

        try:
            client = MlflowClient()
            experiment_id = "5"
            runs = client.search_runs(
                experiment_ids=[experiment_id],
                order_by=["attributes.start_time DESC"]
            )

            if not runs:
                st.info("Ch∆∞a c√≥ l·∫ßn ch·∫°y n√†o ƒë∆∞·ª£c ghi nh·∫≠n trong Experiment ID 5.")
            else:
                run_options = {run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") for run in runs}
                run_names = list(run_options.values())

                default_run_name = st.session_state.get('training_results', {}).get('run_name', run_names[0]) if 'training_results' in st.session_state else run_names[0]

                st.subheader("Danh s√°ch Run")
                selected_run_name = st.selectbox(
                    "Ch·ªçn run:",
                    options=run_names,
                    index=run_names.index(default_run_name) if default_run_name in run_names else 0,
                    key="main_select",
                    help="Ch·ªçn m·ªôt l·∫ßn ch·∫°y ƒë·ªÉ xem chi ti·∫øt, ƒë·ªïi t√™n ho·∫∑c x√≥a."
                )
                selected_run_id = [k for k, v in run_options.items() if v == selected_run_name][0]
                selected_run = client.get_run(selected_run_id)

                st.subheader("ƒê·ªïi t√™n Run")
                new_run_name = st.text_input(
                    "Nh·∫≠p t√™n m·ªõi:",
                    value=selected_run_name,
                    key="rename_input"
                )
                if st.button("C·∫≠p nh·∫≠t t√™n", key="rename_button"):
                    if new_run_name.strip() and new_run_name.strip() != selected_run_name:
                        with st.spinner("ƒêang c·∫≠p nh·∫≠t t√™n..."):
                            client.set_tag(selected_run_id, "mlflow.runName", new_run_name.strip())
                            if 'training_results' in st.session_state and st.session_state['training_results']['run_id'] == selected_run_id:
                                st.session_state['training_results']['run_name'] = new_run_name.strip()
                            st.success(f"ƒê√£ ƒë·ªïi t√™n th√†nh: {new_run_name.strip()}")
                            time.sleep(0.5)
                            st.rerun()
                    elif not new_run_name.strip():
                        st.warning("Vui l√≤ng nh·∫≠p t√™n h·ª£p l·ªá.")
                    else:
                        st.info("T√™n m·ªõi tr√πng v·ªõi t√™n hi·ªán t·∫°i.")

                st.subheader("X√≥a Run")
                if st.button("X√≥a l·∫ßn ch·∫°y", key="delete_button"):
                    with st.spinner("ƒêang x√≥a l·∫ßn ch·∫°y..."):
                        client.delete_run(selected_run_id)
                        if 'training_results' in st.session_state and st.session_state['training_results']['run_id'] == selected_run_id:
                            del st.session_state['training_results']
                        st.success(f"ƒê√£ x√≥a: {selected_run_name}")
                        time.sleep(0.5)
                        st.rerun()

                st.subheader("Th√¥ng tin chi ti·∫øt c·ªßa Run")
                st.write(f"**T√™n l·∫ßn ch·∫°y:** {selected_run_name}")
                st.write(f"**ID l·∫ßn ch·∫°y:** {selected_run_id}")
                st.write(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** {datetime.fromtimestamp(selected_run.info.start_time / 1000)}")

                st.markdown("**Tham s·ªë:**", unsafe_allow_html=True)
                if selected_run.data.params:
                    st.json(selected_run.data.params, expanded=True)
                else:
                    st.write("Kh√¥ng c√≥ tham s·ªë ƒë∆∞·ª£c ghi nh·∫≠n.")

                st.markdown("**K·∫øt qu·∫£:**", unsafe_allow_html=True)
                if selected_run.data.metrics:
                    metrics_display = {}
                    training_time = selected_run.data.metrics.get("training_time_seconds", "N/A")
                    metrics_display["Th·ªùi gian th·ª±c hi·ªán (gi√¢y)"] = f"{float(training_time):.2f}" if training_time != "N/A" else "N/A"
                    accuracy_val = selected_run.data.metrics.get("accuracy_val", "N/A")
                    metrics_display["ƒê·ªô ch√≠nh x√°c Validation"] = f"{float(accuracy_val)*100:.2f}%" if accuracy_val != "N/A" else "N/A"
                    accuracy_test = selected_run.data.metrics.get("accuracy_test", "N/A")
                    metrics_display["ƒê·ªô ch√≠nh x√°c Test"] = f"{float(accuracy_test)*100:.2f}%" if accuracy_test != "N/A" else "N/A"
                    st.json(metrics_display, expanded=True)
                else:
                    st.write("Kh√¥ng c√≥ k·∫øt qu·∫£ ƒë∆∞·ª£c ghi nh·∫≠n.")

                st.subheader("Truy c·∫≠p MLflow UI")
                mlflow_url = "https://dagshub.com/huykibo/streamlit_mlflow.mlflow"
                if st.button("M·ªü MLflow UI tr√™n Dagshub"):
                    st.markdown(f'[Click ƒë·ªÉ m·ªü MLflow UI]({mlflow_url})', unsafe_allow_html=True)

        except Exception as e:
            st.error(f"L·ªói k·∫øt n·ªëi MLflow ho·∫∑c kh√¥ng t√¨m th·∫•y Experiment ID 5: {e}. Vui l√≤ng ki·ªÉm tra MLFLOW_TRACKING_URI v√† th√¥ng tin x√°c th·ª±c.")

if __name__ == "__main__":
    run_mnist_neural_network_app()