import os
import mlflow
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from datetime import datetime
import time
import requests
import io
import sys
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
import gc

# H√†m ch·ªçn tham s·ªë t·ªëi ∆∞u d·ª±a tr√™n s·ªë m·∫´u
def get_optimal_params(num_samples):
    if num_samples <= 1000:
        return {
            "hidden_layer_sizes": (32,),
            "learning_rate": 0.001,
            "epochs": 30,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 32
        }
    elif num_samples <= 10000:
        return {
            "hidden_layer_sizes": (64, 32),
            "learning_rate": 0.0005,
            "epochs": 50,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 64
        }
    elif num_samples <= 50000:
        return {
            "hidden_layer_sizes": (128, 64),
            "learning_rate": 0.0003,
            "epochs": 70,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 128
        }
    else:  # > 50,000
        return {
            "hidden_layer_sizes": (128, 64, 32),
            "learning_rate": 0.0001,
            "epochs": 100,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 256
        }

def build_model(params):
    model = models.Sequential()
    model.add(layers.Input(shape=(784,)))
    for neurons in params["hidden_layer_sizes"]:
        model.add(layers.Dense(neurons, activation=params["activation"]))
    model.add(layers.Dense(10, activation='softmax'))
    optimizer = (tf.keras.optimizers.Adam(learning_rate=params["learning_rate"])
                 if params["solver"] == "adam" else
                 tf.keras.optimizers.SGD(learning_rate=params["learning_rate"]))
    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

def run_mnist_neural_network_app():
    # Thi·∫øt l·∫≠p MLflow
    mlflow_tracking_uri = "https://dagshub.com/huykibo/streamlit_mlflow.mlflow"
    try:
        os.environ["MLFLOW_TRACKING_USERNAME"] = st.secrets["mlflow"]["MLFLOW_TRACKING_USERNAME"]
        os.environ["MLFLOW_TRACKING_PASSWORD"] = st.secrets["mlflow"]["MLFLOW_TRACKING_PASSWORD"]
        mlflow.set_tracking_uri(mlflow_tracking_uri)
    except KeyError as e:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y kh√≥a {e} trong st.secrets.")
        st.stop()

    try:
        response = requests.get(mlflow_tracking_uri, timeout=5)
        if response.status_code != 200:
            st.error(f"K·∫øt n·ªëi MLflow th·∫•t b·∫°i. M√£ tr·∫°ng th√°i: {response.status_code}.")
            st.stop()
    except requests.exceptions.RequestException as e:
        st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi MLflow: {e}.")
        st.stop()

    EXPERIMENT_ID = "6"  # Updated to '6' as per requirement
    try:
        client = MlflowClient()
        experiment = client.get_experiment(EXPERIMENT_ID)
        if experiment is None:
            st.error(f"Experiment ID {EXPERIMENT_ID} kh√¥ng t·ªìn t·∫°i.")
            st.stop()
    except Exception as e:
        st.error(f"L·ªói truy xu·∫•t Experiment ID {EXPERIMENT_ID}: {e}.")
        st.stop()

    # T·∫£i d·ªØ li·ªáu MNIST t·ª± ƒë·ªông khi kh·ªüi ƒë·ªông
    if 'full_data' not in st.session_state:
        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
        X_full = np.concatenate([X_train, X_test], axis=0)
        y_full = np.concatenate([y_train, y_test], axis=0)
        X_full = X_full.reshape(-1, 784).astype(np.float32)
        y_full = y_full.astype(np.int32)
        st.session_state['full_data'] = (X_full, y_full)

    st.title("Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Neural Network")

    # CSS t√πy ch·ªânh
    st.markdown("""
        <style>
            .tooltip {
                position: relative;
                display: inline-block;
                cursor: pointer;
                color: #1f77b4;
                font-weight: bold;
                margin-left: 5px;
            }
            .tooltip .tooltiptext {
                visibility: hidden;
                width: 400px;
                background-color: #f9f9f9;
                color: #333;
                text-align: left;
                border-radius: 6px;
                padding: 10px;
                position: absolute;
                z-index: 1;
                right: 105%;
                top: 50%;
                transform: translateY(-50%);
                opacity: 0;
                transition: opacity 0.3s;
                border: 1px solid #ccc;
                font-size: 0.9em;
                line-height: 1.4;
            }
            .tooltip:hover .tooltiptext {
                visibility: visible;
                opacity: 1;
            }
            .section-title {
                font-size: 1.5em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 10px;
            }
            .info-box {
                background-color: #f8f9fa;
                padding: 10px;
                border-left: 4px solid #3498db;
                margin-bottom: 15px;
            }
            .action-container {
                background-color: #ffffff;
                padding: 15px;
                border-radius: 5px;
                box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
                margin-bottom: 20px;
            }
            .prediction-box {
                margin-top: 10px;
                padding: 10px;
                border: 1px solid #ccc;
                border-radius: 5px;
                background-color: #f9f9f9;
            }
            .mode-title {
                font-size: 1.2em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 10px;
            }
            .stCanvas {
                border: 1px solid #ddd;
                border-radius: 5px;
            }
        </style>
    """, unsafe_allow_html=True)

    # T·∫°o c√°c tab
    tab_names = ["Th√¥ng tin", "Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu", "X·ª≠ l√Ω d·ªØ li·ªáu", "Chia d·ªØ li·ªáu", "Hu·∫•n luy·ªán/ƒê√°nh gi√°", "Demo d·ª± ƒëo√°n", "Th√¥ng tin hu·∫•n luy·ªán"]
    tab_info, tab_load, tab_preprocess, tab_split, tab_train_eval, tab_demo, tab_log_info = st.tabs(tab_names)

   # Tab 1: Th√¥ng tin
    with tab_info:
        st.header("Gi·ªõi thi·ªáu ·ª®ng d·ª•ng Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Neural Network v√† Pseudo-Labeling")
        st.markdown("""
        Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay t·ª´ t·∫≠p d·ªØ li·ªáu **MNIST** s·ª≠ d·ª•ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)** k·∫øt h·ª£p v·ªõi k·ªπ thu·∫≠t **Pseudo-Labeling**. ·ª®ng d·ª•ng n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ cung c·∫•p tr·∫£i nghi·ªám tr·ª±c quan, h·ªó tr·ª£ h·ªçc t·∫≠p v√† nghi√™n c·ª©u v·ªÅ c√°c thu·∫≠t to√°n h·ªçc m√°y hi·ªán ƒë·∫°i.
        """, unsafe_allow_html=True)

        st.subheader("Ch·ªçn n·ªôi dung ƒë·ªÉ kh√°m ph√°")
        info_option = st.selectbox(
            "",
            [
                "T·ªïng quan v·ªÅ ·ª©ng d·ª•ng v√† m·ª•c ti√™u",
                "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a",
                "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o",
                "Pseudo-Labeling ‚Äì K·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t"
            ],
            label_visibility="collapsed",
            help="Kh√°m ph√° chi ti·∫øt v·ªÅ ·ª©ng d·ª•ng, d·ªØ li·ªáu, m√¥ h√¨nh v√† k·ªπ thu·∫≠t Pseudo-Labeling."
        )

        if info_option == "T·ªïng quan v·ªÅ ·ª©ng d·ª•ng v√† m·ª•c ti√™u":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                    time.sleep(0.05)
                st.subheader("üìå T·ªïng quan v·ªÅ ·ª©ng d·ª•ng v√† m·ª•c ti√™u")
                st.markdown("""
                ·ª®ng d·ª•ng n√†y t·∫≠p trung v√†o vi·ªác ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu **MNIST**, m·ªôt b·ªô d·ªØ li·ªáu ti√™u chu·∫©n trong lƒ©nh v·ª±c h·ªçc m√°y. K·∫øt h·ª£p **Neural Network** v√† **Pseudo-Labeling**, ·ª©ng d·ª•ng kh√¥ng ch·ªâ t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t m√¥ h√¨nh m√† c√≤n t·∫≠n d·ª•ng d·ªØ li·ªáu kh√¥ng c√≥ nh√£n ƒë·ªÉ n√¢ng cao kh·∫£ nƒÉng h·ªçc t·∫≠p.

                **M·ª•c ti√™u ch√≠nh:**
                - Ph√°t tri·ªÉn m·ªôt m√¥ h√¨nh Neural Network c√≥ kh·∫£ nƒÉng nh·∫≠n di·ªán ch√≠nh x√°c c√°c ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9.
                - √Åp d·ª•ng k·ªπ thu·∫≠t Pseudo-Labeling ƒë·ªÉ khai th√°c d·ªØ li·ªáu kh√¥ng c√≥ nh√£n, m√¥ ph·ªèng c√°c t√¨nh hu·ªëng th·ª±c t·∫ø khi d·ªØ li·ªáu c√≥ nh√£n h·∫°n ch·∫ø.
                - Cung c·∫•p giao di·ªán tr·ª±c quan ƒë·ªÉ ng∆∞·ªùi d√πng th·ª±c h√†nh, ƒë√°nh gi√° v√† t√πy ch·ªânh m√¥ h√¨nh.

                **Th√¥ng tin c∆° b·∫£n v·ªÅ d·ªØ li·ªáu:**
                - **Quy m√¥:** 70,000 ·∫£nh, m·ªói ·∫£nh k√≠ch th∆∞·ªõc 28x28 pixel (t·ªïng c·ªông 784 ƒë·∫∑c tr∆∞ng).
                - **ƒê·∫∑c tr∆∞ng:** Gi√° tr·ªã pixel t·ª´ 0 ƒë·∫øn 255, bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng vector 784 chi·ªÅu.
                - **Nhi·ªám v·ª•:** D·ª± ƒëo√°n nh√£n t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9.
                """, unsafe_allow_html=True)
               
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                    time.sleep(0.05)
                st.subheader("üìå T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a")
                st.markdown("""
                **MNIST** l√† m·ªôt t·∫≠p d·ªØ li·ªáu ti√™u chu·∫©n trong h·ªçc m√°y, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Yann LeCun v√† c√°c c·ªông s·ª±, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh ph√¢n lo·∫°i.

                **ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t:**
                - **Ngu·ªìn g·ªëc:** Bao g·ªìm ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ h·ªçc sinh trung h·ªçc v√† nh√¢n vi√™n ƒëi·ªÅu tra d√¢n s·ªë Hoa K·ª≥.
                - **K√≠ch th∆∞·ªõc:** M·ªói ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i 28x28 pixel, thang ƒë·ªô x√°m v·ªõi gi√° tr·ªã t·ª´ 0 ƒë·∫øn 255.
                - **Quy m√¥:** T·ªïng c·ªông 70,000 ·∫£nh, chia th√†nh t·∫≠p hu·∫•n luy·ªán (60,000 ·∫£nh) v√† t·∫≠p ki·ªÉm tra (10,000 ·∫£nh).

                **√ù nghƒ©a:**
                - L√† n·ªÅn t·∫£ng l√Ω t∆∞·ªüng ƒë·ªÉ th·ª≠ nghi·ªám c√°c thu·∫≠t to√°n h·ªçc m√°y, t·ª´ c∆° b·∫£n ƒë·∫øn n√¢ng cao.
                - Gi√∫p ƒë√°nh gi√° kh·∫£ nƒÉng ph√¢n bi·ªát c√°c l·ªõp t∆∞∆°ng t·ª± (v√≠ d·ª•: 4 v√† 9) trong c√°c m√¥ h√¨nh Neural Network.
                - H·ªó tr·ª£ nghi√™n c·ª©u v√† ƒë√†o t·∫°o cho c·∫£ ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu l·∫´n c√°c chuy√™n gia trong lƒ©nh v·ª±c h·ªçc s√¢u.
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("mnist.png"), caption="T·ªïng quan v·ªÅ t·∫≠p d·ªØ li·ªáu MNIST", width=800)
                except FileNotFoundError:
                    st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'mnist_overview.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìä 3. Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o")
                st.markdown("""
                **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o)** l√† m·ªôt m√¥ h√¨nh h·ªçc m√°y m√¥ ph·ªèng c√°ch ho·∫°t ƒë·ªông c·ªßa m·∫°ng n∆°-ron sinh h·ªçc trong n√£o ng∆∞·ªùi. N√≥ ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu, ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ v·ªõi b√†i to√°n nh·∫≠n di·ªán h√¨nh ·∫£nh nh∆∞ MNIST.
                """, unsafe_allow_html=True)

                st.subheader("üåê C·∫•u tr√∫c c∆° b·∫£n c·ªßa Neural Network")
                st.markdown("""
                - **L·ªõp ƒë·∫ßu v√†o (Input Layer)**: Nh·∫≠n d·ªØ li·ªáu th√¥ (v√≠ d·ª•: $784$ pixel t·ª´ ·∫£nh MNIST $28 \\times 28$).  
                - **L·ªõp ·∫©n (Hidden Layers)**: X·ª≠ l√Ω th√¥ng tin th√¥ng qua c√°c ph√©p t√≠nh tuy·∫øn t√≠nh v√† phi tuy·∫øn.  
                - **L·ªõp ƒë·∫ßu ra (Output Layer)**: ƒê∆∞a ra d·ª± ƒëo√°n (10 l·ªõp, t∆∞∆°ng ·ª©ng v·ªõi c√°c ch·ªØ s·ªë $0$-$9$).  
                """, unsafe_allow_html=True)

                st.subheader("üîß Quy tr√¨nh ho·∫°t ƒë·ªông")
                st.markdown("""
                Neural Network ho·∫°t ƒë·ªông qua c√°c b∆∞·ªõc sau, ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a d·ª±a tr√™n c√°c tham s·ªë b·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh trong tab **Hu·∫•n luy·ªán/ƒê√°nh gi√°**:
                """, unsafe_allow_html=True)

                st.subheader("1. Kh·ªüi t·∫°o m√¥ h√¨nh")
                st.markdown("""
                - X√°c ƒë·ªãnh c·∫•u tr√∫c m·∫°ng (s·ªë l·ªõp ·∫©n, s·ªë n∆°-ron m·ªói l·ªõp) v√† kh·ªüi t·∫°o **tr·ªçng s·ªë** ($W$) v√† **bias** ($b$) ng·∫´u nhi√™n (th∆∞·ªùng t·ª´ ph√¢n ph·ªëi Gaussian).  
                - **Tham s·ªë li√™n quan**: S·ªë l·ªõp ·∫©n, s·ªë n∆°-ron m·ªói l·ªõp.  
                - **Ch√∫ th√≠ch**:  
                  - $W$: Ma tr·∫≠n tr·ªçng s·ªë (weights) k·∫øt n·ªëi c√°c n∆°-ron gi·ªØa c√°c l·ªõp.  
                  - $b$: Vector bias (ƒë·ªô l·ªách) gi√∫p ƒëi·ªÅu ch·ªânh ƒë·∫ßu ra c·ªßa n∆°-ron.  
                - M·ª•c ƒë√≠ch: Thi·∫øt l·∫≠p c·∫•u tr√∫c ban ƒë·∫ßu ƒë·ªÉ b·∫Øt ƒë·∫ßu qu√° tr√¨nh h·ªçc.  
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step1_init.png"), caption="Minh h·ªça: Kh·ªüi t·∫°o m√¥ h√¨nh", width=700)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 1.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("2. Lan truy·ªÅn thu·∫≠n (Feedforward)")
                st.markdown("""
                - T√≠nh to√°n ƒë·∫ßu ra d·ª± ƒëo√°n ($\\hat{Y}$) t·ª´ ƒë·∫ßu v√†o $X$ qua c√°c l·ªõp:  
                  $$ Z^{(l)} = A^{(l-1)} \\cdot W^{(l)} + b^{(l)} $$  
                  $$ A^{(l)} = \\text{h√†m k√≠ch ho·∫°t}(Z^{(l)}) $$  
                - **Ch√∫ th√≠ch**:  
                  - $Z^{(l)}$: T·ªïng tr·ªçng s·ªë ƒë·∫ßu v√†o t·∫°i l·ªõp $l$ (tr∆∞·ªõc khi √°p d·ª•ng h√†m k√≠ch ho·∫°t).  
                  - $A^{(l-1)}$: ƒê·∫ßu ra c·ªßa l·ªõp tr∆∞·ªõc ($l-1$), l√† ƒë·∫ßu v√†o c·ªßa l·ªõp $l$.  
                  - $W^{(l)}$: Ma tr·∫≠n tr·ªçng s·ªë c·ªßa l·ªõp $l$.  
                  - $b^{(l)}$: Vector bias c·ªßa l·ªõp $l$.  
                  - $A^{(l)}$: ƒê·∫ßu ra c·ªßa l·ªõp $l$ sau khi √°p d·ª•ng h√†m k√≠ch ho·∫°t.  
                - M·ª•c ƒë√≠ch: T·∫°o d·ª± ƒëo√°n ban ƒë·∫ßu t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o qua c√°c l·ªõp n∆°-ron.  
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step2_feedforward.png"), caption="Minh h·ªça: Lan truy·ªÅn thu·∫≠n", width=700)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 2.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("3. T√≠nh h√†m m·∫•t m√°t (Loss Function)")
                st.markdown("""
                - ƒêo ƒë·ªô sai l·ªách gi·ªØa d·ª± ƒëo√°n ($\\hat{Y}$) v√† nh√£n th·ª±c ($Y$) b·∫±ng **Cross-Entropy**:  
                  $$ L = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=0}^{9} y_{ij} \\cdot \\log(\\hat{y}_{ij}) $$  
                - **Ch√∫ th√≠ch**:  
                  - $L$: Gi√° tr·ªã m·∫•t m√°t (loss) t·ªïng th·ªÉ c·ªßa m√¥ h√¨nh.  
                  - $N$: S·ªë l∆∞·ª£ng m·∫´u trong t·∫≠p d·ªØ li·ªáu.  
                  - $y_{ij}$: Gi√° tr·ªã th·ª±c t·∫ø (1 n·∫øu m·∫´u $i$ thu·ªôc l·ªõp $j$, 0 n·∫øu kh√¥ng).  
                  - $\\hat{y}_{ij}$: X√°c su·∫•t d·ª± ƒëo√°n b·ªüi m√¥ h√¨nh cho m·∫´u $i$ thu·ªôc l·ªõp $j$.  
                - M·ª•c ƒë√≠ch: ƒê·ªãnh l∆∞·ª£ng sai l·ªách ƒë·ªÉ ƒëi·ªÅu ch·ªânh m√¥ h√¨nh trong b∆∞·ªõc ti·∫øp theo.  
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step3_loss.png"), caption="Minh h·ªça: T√≠nh h√†m m·∫•t m√°t", width=700)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 3.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("4. Lan truy·ªÅn ng∆∞·ª£c (Backpropagation)")
                st.markdown("""
                - T√≠nh ƒë·∫°o h√†m c·ªßa $L$ ƒë·ªÉ c·∫≠p nh·∫≠t $W^{(l)}$ v√† $b^{(l)}$ nh·∫±m gi·∫£m sai s·ªë d·ª± ƒëo√°n.  
                - **Ch√∫ th√≠ch**:  
                  - $\\frac{\\partial L}{\\partial W^{(l)}}$: ƒê·∫°o h√†m ri√™ng c·ªßa m·∫•t m√°t $L$ theo tr·ªçng s·ªë $W^{(l)}$.  
                  - $\\frac{\\partial L}{\\partial b^{(l)}}$: ƒê·∫°o h√†m ri√™ng c·ªßa m·∫•t m√°t $L$ theo bias $b^{(l)}$.  
                - M·ª•c ƒë√≠ch: X√°c ƒë·ªãnh h∆∞·ªõng ƒëi·ªÅu ch·ªânh tham s·ªë d·ª±a tr√™n sai s·ªë.  
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step4_backprop.png"), caption="Minh h·ªça: Lan truy·ªÅn ng∆∞·ª£c", width=700)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 4.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("5. C·∫≠p nh·∫≠t tham s·ªë (Gradient Descent)")
                st.markdown("""
                - ƒêi·ªÅu ch·ªânh $W^{(l)}$ v√† $b^{(l)}$ ƒë·ªÉ gi·∫£m m·∫•t m√°t:  
                  $$ W^{(l)} = W^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial W^{(l)}} $$  
                  $$ b^{(l)} = b^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial b^{(l)}} $$  
                - **Ch√∫ th√≠ch**:  
                  - $\\eta$: T·ªëc ƒë·ªô h·ªçc (learning rate), ki·ªÉm so√°t m·ª©c ƒë·ªô thay ƒë·ªïi c·ªßa $W$ v√† $b$.  
                  - $\\frac{\\partial L}{\\partial W^{(l)}}$: Gradient c·ªßa $L$ theo $W^{(l)}$.  
                  - $\\frac{\\partial L}{\\partial b^{(l)}}$: Gradient c·ªßa $L$ theo $b^{(l)}$.  
                - M·ª•c ƒë√≠ch: T·ªëi ∆∞u h√≥a tham s·ªë ƒë·ªÉ gi·∫£m sai s·ªë d·ª± ƒëo√°n.  
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step5_gradient.png"), caption="Minh h·ªça: C·∫≠p nh·∫≠t tham s·ªë", width=700)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 5.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("6. L·∫∑p l·∫°i")
                st.markdown("""
                - L·∫∑p l·∫°i t·ª´ b∆∞·ªõc 2 qua nhi·ªÅu **epoch** cho ƒë·∫øn khi m·∫•t m√°t $L$ h·ªôi t·ª•.  
                - **Ch√∫ th√≠ch**:  
                  - **Epoch**: M·ªôt l·∫ßn l·∫∑p qua to√†n b·ªô t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán.  
                - M·ª•c ƒë√≠ch: Tinh ch·ªânh m√¥ h√¨nh qua nhi·ªÅu v√≤ng l·∫∑p ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t t·ªëi ∆∞u.  
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step6_repeat.png"), caption="Minh h·ªça: L·∫∑p l·∫°i", width=700)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 6.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("üîß C√°c tham s·ªë hu·∫•n luy·ªán: √ù nghƒ©a, ho·∫°t ƒë·ªông v√† c√¥ng th·ª©c")
                st.markdown("""
                D∆∞·ªõi ƒë√¢y l√† c√°c tham s·ªë ch√≠nh trong qu√° tr√¨nh hu·∫•n luy·ªán Neural Network, √Ω nghƒ©a c·ªßa ch√∫ng, c√°ch ho·∫°t ƒë·ªông v√† c√¥ng th·ª©c (n·∫øu c√≥):

                1. **S·ªë l·ªõp ·∫©n (Number of Hidden Layers):**  
                   - **√ù nghƒ©a**: Quy·∫øt ƒë·ªãnh ƒë·ªô s√¢u c·ªßa m·∫°ng, ·∫£nh h∆∞·ªüng ƒë·∫øn kh·∫£ nƒÉng h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p.  
                   - **Ho·∫°t ƒë·ªông**: TƒÉng s·ªë l·ªõp ·∫©n gi√∫p m·∫°ng h·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng c·∫•p cao h∆°n, nh∆∞ng qu√° nhi·ªÅu l·ªõp c√≥ th·ªÉ g√¢y kh√≥ h·ªôi t·ª• ho·∫∑c overfitting.  
                   - **C√¥ng th·ª©c**: Kh√¥ng c√≥ c√¥ng th·ª©c c·ª• th·ªÉ, th∆∞·ªùng ƒë∆∞·ª£c ch·ªçn d·ª±a tr√™n kinh nghi·ªám ho·∫∑c th·ª≠ nghi·ªám (trong ·ª©ng d·ª•ng n√†y: t·ª´ 1 ƒë·∫øn 5).  

                2. **S·ªë n∆°-ron m·ªói l·ªõp ·∫©n (Number of Neurons per Layer):**  
                   - **√ù nghƒ©a**: Quy·∫øt ƒë·ªãnh ƒë·ªô r·ªông c·ªßa m·∫°ng, t·ª©c l√† kh·∫£ nƒÉng bi·ªÉu di·ªÖn th√¥ng tin trong m·ªói l·ªõp.  
                   - **Ho·∫°t ƒë·ªông**: Nhi·ªÅu n∆°-ron h∆°n gi√∫p m·∫°ng h·ªçc ƒë∆∞·ª£c nhi·ªÅu ƒë·∫∑c tr∆∞ng h∆°n, nh∆∞ng c≈©ng tƒÉng chi ph√≠ t√≠nh to√°n.  
                   - **C√¥ng th·ª©c**: Kh√¥ng c√≥, th∆∞·ªùng l√† l≈©y th·ª´a c·ªßa 2 (16, 32, 64, 128, v.v.) ƒë·ªÉ t·ªëi ∆∞u h√≥a ph·∫ßn c·ª©ng.  

                3. **T·ªëc ƒë·ªô h·ªçc (Learning Rate - Œ∑):**  
                   - **√ù nghƒ©a**: ƒêi·ªÅu ch·ªânh m·ª©c ƒë·ªô thay ƒë·ªïi c·ªßa tr·ªçng s·ªë trong m·ªói l·∫ßn c·∫≠p nh·∫≠t.  
                   - **Ho·∫°t ƒë·ªông**: Gi√° tr·ªã nh·ªè (v√≠ d·ª•: 0.0001) l√†m m√¥ h√¨nh h·ªçc ch·∫≠m nh∆∞ng ·ªïn ƒë·ªãnh; gi√° tr·ªã l·ªõn (v√≠ d·ª•: 0.01) h·ªçc nhanh h∆°n nh∆∞ng d·ªÖ v∆∞·ª£t qua ƒëi·ªÉm t·ªëi ∆∞u.  
                   - **C√¥ng th·ª©c**:  
                     $$ W_{t+1} = W_t - \\eta \\cdot \\frac{\\partial L}{\\partial W_t} $$  
                     - $W_{t+1}$: Tr·ªçng s·ªë sau khi c·∫≠p nh·∫≠t.  
                     - $W_t$: Tr·ªçng s·ªë t·∫°i b∆∞·ªõc hi·ªán t·∫°i.  
                     - $\\eta$: T·ªëc ƒë·ªô h·ªçc.  
                     - $\\frac{\\partial L}{\\partial W_t}$: Gradient c·ªßa m·∫•t m√°t theo tr·ªçng s·ªë.  

                4. **S·ªë l·∫ßn l·∫∑p (Epochs):**  
                   - **√ù nghƒ©a**: S·ªë l·∫ßn to√†n b·ªô d·ªØ li·ªáu hu·∫•n luy·ªán ƒë∆∞·ª£c ƒë∆∞a qua m·∫°ng.  
                   - **Ho·∫°t ƒë·ªông**: TƒÉng s·ªë l·∫ßn l·∫∑p gi√∫p m·∫°ng h·ªçc t·ªët h∆°n, nh∆∞ng qu√° nhi·ªÅu c√≥ th·ªÉ d·∫´n ƒë·∫øn overfitting.  
                   - **C√¥ng th·ª©c**: Kh√¥ng c√≥, l√† tham s·ªë ng∆∞·ªùi d√πng ch·ªçn (trong ·ª©ng d·ª•ng n√†y: 10-200).  

                5. **K√≠ch th∆∞·ªõc batch (Batch Size):**  
                   - **√ù nghƒ©a**: S·ªë m·∫´u ƒë∆∞·ª£c x·ª≠ l√Ω tr∆∞·ªõc khi c·∫≠p nh·∫≠t tr·ªçng s·ªë.  
                   - **Ho·∫°t ƒë·ªông**: Batch nh·ªè (v√≠ d·ª•: 16) gi√∫p c·∫≠p nh·∫≠t th∆∞·ªùng xuy√™n h∆°n nh∆∞ng ch·∫≠m; batch l·ªõn (v√≠ d·ª•: 512) nhanh h∆°n nh∆∞ng c·∫ßn nhi·ªÅu b·ªô nh·ªõ.  
                   - **C√¥ng th·ª©c**: Kh√¥ng c√≥, th∆∞·ªùng l√† l≈©y th·ª´a c·ªßa 2 ƒë·ªÉ t·ªëi ∆∞u h√≥a t√≠nh to√°n.  

                6. **H√†m k√≠ch ho·∫°t (Activation Function):**  
                   - **√ù nghƒ©a**: Quy·∫øt ƒë·ªãnh c√°ch n∆°-ron "k√≠ch ho·∫°t" ƒë·∫ßu ra d·ª±a tr√™n ƒë·∫ßu v√†o.  
                   - **Ho·∫°t ƒë·ªông**: Chuy·ªÉn ƒë·ªïi ƒë·∫ßu ra tuy·∫øn t√≠nh th√†nh phi tuy·∫øn ƒë·ªÉ m·∫°ng h·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p.  
                   - **Chi ti·∫øt c√°c h√†m k√≠ch ho·∫°t ph·ªï bi·∫øn:**  
                     - **ReLU (Rectified Linear Unit):**  
                       - **√ù nghƒ©a**: ƒê∆°n gi·∫£n, nhanh, tr√°nh v·∫•n ƒë·ªÅ bi·∫øn m·∫•t gradient.  
                       - **Ho·∫°t ƒë·ªông**: Ch·ªâ cho ph√©p c√°c gi√° tr·ªã d∆∞∆°ng ƒëi qua, ƒë·∫∑t gi√° tr·ªã √¢m v·ªÅ 0.  
                       - **C√¥ng th·ª©c**:  
                         $$ f(x) = \\max(0, x) $$  
                         - $x$: ƒê·∫ßu v√†o c·ªßa h√†m.  
                     - **Tanh (Hyperbolic Tangent):**  
                       - **√ù nghƒ©a**: Chu·∫©n h√≥a ƒë·∫ßu ra v·ªÅ kho·∫£ng [-1, 1], ph√π h·ª£p khi c·∫ßn c√¢n b·∫±ng gi√° tr·ªã √¢m/d∆∞∆°ng.  
                       - **Ho·∫°t ƒë·ªông**: T·∫°o ƒë·∫ßu ra phi tuy·∫øn, nh∆∞ng d·ªÖ g·∫∑p v·∫•n ƒë·ªÅ bi·∫øn m·∫•t gradient v·ªõi m·∫°ng s√¢u.  
                       - **C√¥ng th·ª©c**:  
                         $$ f(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}} $$  
                         - $x$: ƒê·∫ßu v√†o c·ªßa h√†m.  
                     - **Softmax:**  
                       - **√ù nghƒ©a**: D√πng ·ªü l·ªõp ƒë·∫ßu ra ƒë·ªÉ chuy·ªÉn ƒë·ªïi th√†nh x√°c su·∫•t cho ph√¢n lo·∫°i ƒëa l·ªõp.  
                       - **Ho·∫°t ƒë·ªông**: Chu·∫©n h√≥a t·ªïng c√°c ƒë·∫ßu ra th√†nh 1, gi√∫p d·ª± ƒëo√°n l·ªõp c√≥ x√°c su·∫•t cao nh·∫•t.  
                       - **C√¥ng th·ª©c**:  
                         $$ f(x_i) = \\frac{e^{x_i}}{\\sum_{j=0}^{k} e^{x_j}} $$  
                         - $x_i$: ƒê·∫ßu v√†o c·ªßa n∆°-ron th·ª© $i$.  
                         - $k$: S·ªë l·ªõp (·ªü ƒë√¢y l√† 10).  

                7. **Tr√¨nh t·ªëi ∆∞u (Optimizer):**  
                   - **√ù nghƒ©a**: Thu·∫≠t to√°n ƒëi·ªÅu ch·ªânh tr·ªçng s·ªë ƒë·ªÉ gi·∫£m h√†m m·∫•t m√°t.  
                   - **Ho·∫°t ƒë·ªông**: D√πng gradient ƒë·ªÉ c·∫≠p nh·∫≠t tham s·ªë, v·ªõi c√°ch ti·∫øp c·∫≠n kh√°c nhau t√πy thu·∫≠t to√°n.  
                   - **V√≠ d·ª• ph·ªï bi·∫øn:**  
                     - **SGD (Stochastic Gradient Descent):**  
                       - **√ù nghƒ©a**: C·∫≠p nh·∫≠t tr·ªçng s·ªë d·ª±a tr√™n gradient c·ªßa m·ªôt m·∫´u/mini-batch.  
                       - **C√¥ng th·ª©c**:  
                         $$ W_{t+1} = W_t - \\eta \\cdot \\frac{\\partial L}{\\partial W_t} $$  
                         - $W_t$: Tr·ªçng s·ªë hi·ªán t·∫°i.  
                         - $\\eta$: T·ªëc ƒë·ªô h·ªçc.  
                         - $\\frac{\\partial L}{\\partial W_t}$: Gradient.  
                       - **∆Øu ƒëi·ªÉm**: ƒê∆°n gi·∫£n, nhanh v·ªõi d·ªØ li·ªáu l·ªõn.  
                       - **Nh∆∞·ª£c ƒëi·ªÉm**: Dao ƒë·ªông, h·ªôi t·ª• ch·∫≠m.  
                     - **Adam (Adaptive Moment Estimation):**  
                       - **√ù nghƒ©a**: K·∫øt h·ª£p ƒë·ªông l∆∞·ª£ng v√† RMSProp, th√≠ch nghi t·ªëc ƒë·ªô h·ªçc cho t·ª´ng tham s·ªë.  
                       - **C√¥ng th·ª©c**:  
                         1. $m_t = \\beta_1 \\cdot m_{t-1} + (1 - \\beta_1) \\cdot g_t$ (moment b·∫≠c 1).  
                         2. $v_t = \\beta_2 \\cdot v_{t-1} + (1 - \\beta_2) \\cdot g_t^2$ (moment b·∫≠c 2).  
                         3. $\\hat{m}_t = \\frac{m_t}{1 - \\beta_1^t}, \\hat{v}_t = \\frac{v_t}{1 - \\beta_2^t}$ (hi·ªáu ch·ªânh).  
                         4. $W_{t+1} = W_t - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}$.  
                         - $g_t$: Gradient.  
                         - $\\beta_1 \\approx 0.9, \\beta_2 \\approx 0.999, \\epsilon \\approx 10^{-8}$.  
                       - **∆Øu ƒëi·ªÉm**: Nhanh, ·ªïn ƒë·ªãnh, hi·ªáu qu·∫£.  
                       - **Nh∆∞·ª£c ƒëi·ªÉm**: Ph·ª©c t·∫°p, ƒë√¥i khi k√©m tr√™n h√†m kh√¥ng l·ªìi.  
                   - **So s√°nh**: SGD ch·∫≠m, dao ƒë·ªông; Adam nhanh, ·ªïn ƒë·ªãnh.  
                """, unsafe_allow_html=True)

                st.subheader("üåü ∆Øu ƒëi·ªÉm v√† nh∆∞·ª£c ƒëi·ªÉm c·ªßa Neural Network")
                st.markdown("""
                #### **∆Øu ƒëi·ªÉm:**  
                - **Kh·∫£ nƒÉng h·ªçc phi tuy·∫øn t√≠nh**: Neural Network c√≥ th·ªÉ h·ªçc c√°c m·ªëi quan h·ªá ph·ª©c t·∫°p, phi tuy·∫øn t√≠nh trong d·ªØ li·ªáu m√† c√°c m√¥ h√¨nh tuy·∫øn t√≠nh kh√¥ng l√†m ƒë∆∞·ª£c.  
                - **Kh·∫£ nƒÉng m·ªü r·ªông**: C√≥ th·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn v√† nhi·ªÅu chi·ªÅu (nh∆∞ ·∫£nh, √¢m thanh) khi ƒë∆∞·ª£c hu·∫•n luy·ªán ƒë√∫ng c√°ch.  
                - **T√≠nh linh ho·∫°t**: C√≥ th·ªÉ √°p d·ª•ng cho nhi·ªÅu b√†i to√°n kh√°c nhau (ph√¢n lo·∫°i, h·ªìi quy, nh·∫≠n di·ªán h√¨nh ·∫£nh, v.v.).  
                - **T·ª± ƒë·ªông h·ªçc ƒë·∫∑c tr∆∞ng**: Kh√¥ng c·∫ßn tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng th·ªß c√¥ng, m·∫°ng t·ª± ƒë·ªông h·ªçc t·ª´ d·ªØ li·ªáu th√¥.  

                #### **Nh∆∞·ª£c ƒëi·ªÉm:**  
                - **ƒê√≤i h·ªèi t√†i nguy√™n l·ªõn**: C·∫ßn nhi·ªÅu d·ªØ li·ªáu v√† s·ª©c m·∫°nh t√≠nh to√°n (CPU/GPU) ƒë·ªÉ hu·∫•n luy·ªán hi·ªáu qu·∫£.  
                - **Kh√≥ gi·∫£i th√≠ch**: M·∫°ng ho·∫°t ƒë·ªông nh∆∞ "h·ªôp ƒëen", kh√≥ hi·ªÉu t·∫°i sao l·∫°i ƒë∆∞a ra d·ª± ƒëo√°n c·ª• th·ªÉ.  
                - **D·ªÖ b·ªã overfitting**: N·∫øu kh√¥ng ƒë∆∞·ª£c ƒëi·ªÅu ch·ªânh t·ªët (v√≠ d·ª•: thi·∫øu d·ªØ li·ªáu ho·∫∑c kh√¥ng d√πng regularization), m√¥ h√¨nh c√≥ th·ªÉ h·ªçc qu√° m·ª©c d·ªØ li·ªáu hu·∫•n luy·ªán.  
                - **Th·ªùi gian hu·∫•n luy·ªán l√¢u**: ƒê·∫∑c bi·ªát v·ªõi m·∫°ng s√¢u ho·∫∑c d·ªØ li·ªáu l·ªõn.  
                """, unsafe_allow_html=True)

        elif info_option == "Pseudo-Labeling ‚Äì K·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                    time.sleep(0.05)
                st.subheader("üìå Pseudo-Labeling ‚Äì K·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t")
                st.markdown("""
                **Pseudo-Labeling** l√† m·ªôt ph∆∞∆°ng ph√°p h·ªçc b√°n gi√°m s√°t (semi-supervised learning) gi√∫p t·∫≠n d·ª•ng c·∫£ d·ªØ li·ªáu c√≥ nh√£n v√† kh√¥ng c√≥ nh√£n ƒë·ªÉ n√¢ng cao hi·ªáu su·∫•t m√¥ h√¨nh, ƒë·∫∑c bi·ªát h·ªØu √≠ch khi d·ªØ li·ªáu c√≥ nh√£n khan hi·∫øm. K·ªπ thu·∫≠t n√†y s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n nh√£n gi·∫£ (pseudo-labels) cho d·ªØ li·ªáu kh√¥ng c√≥ nh√£n, sau ƒë√≥ k·∫øt h·ª£p ch√∫ng v√†o qu√° tr√¨nh hu·∫•n luy·ªán.

                **C√°c b∆∞·ªõc th·ª±c hi·ªán Pseudo-Labeling v·ªõi Neural Network:**
                1. **Chu·∫©n b·ªã d·ªØ li·ªáu v√† chia t·∫≠p train/test**  
                   - Chu·∫©n h√≥a d·ªØ li·ªáu (v√≠ d·ª•: ƒë∆∞a v·ªÅ thang [0, 1]) v√† chia th√†nh t·∫≠p hu·∫•n luy·ªán (train) v√† t·∫≠p ki·ªÉm tra (test).  
                   - Minh h·ªça:  
                   """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("mhpersoudo", "pseudo_step1.png"), caption="Chu·∫©n b·ªã d·ªØ li·ªáu v√† chia t·∫≠p", width=600)
                except FileNotFoundError:
                    st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'pseudo_step1.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                st.markdown("""
                2. **L·∫•y 1% s·ªë l∆∞·ª£ng ·∫£nh cho m·ªói l·ªõp (0-9) l√†m t·∫≠p ban ƒë·∫ßu**  
                   - Ch·ªçn 1% m·∫´u t·ª´ m·ªói l·ªõp trong t·∫≠p train ƒë·ªÉ t·∫°o t·∫≠p d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu, ph·∫ßn c√≤n l·∫°i (99%) l√† d·ªØ li·ªáu kh√¥ng c√≥ nh√£n.  
                   - Minh h·ªça:  
                   """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("mhpersoudo", "pseudo_step2.png"), caption="L·∫•y 1% d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu", width=600)
                except FileNotFoundError:
                    st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'pseudo_step2.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                st.markdown("""
                3. **Hu·∫•n luy·ªán m√¥ h√¨nh Neural Network tr√™n t·∫≠p 1% ban ƒë·∫ßu**  
                   - S·ª≠ d·ª•ng t·∫≠p d·ªØ li·ªáu c√≥ nh√£n (1%) ƒë·ªÉ hu·∫•n luy·ªán m·ªôt m√¥ h√¨nh Neural Network c∆° b·∫£n.  
                   - Minh h·ªça:  
                   """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("mhpersoudo", "pseudo_step3.png"), caption="Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n 1% d·ªØ li·ªáu", width=600)
                except FileNotFoundError:
                    st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'pseudo_step3.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                st.markdown("""
                4. **D·ª± ƒëo√°n nh√£n cho d·ªØ li·ªáu kh√¥ng c√≥ nh√£n (99%)**  
                   - S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n nh√£n v√† ƒë·ªô tin c·∫≠y cho t·∫≠p d·ªØ li·ªáu kh√¥ng c√≥ nh√£n.  
                   - Minh h·ªça:  
                   """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("mhpersoudo", "pseudo_step4.png"), caption="D·ª± ƒëo√°n nh√£n cho d·ªØ li·ªáu kh√¥ng c√≥ nh√£n", width=600)
                except FileNotFoundError:
                    st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'pseudo_step4.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                st.markdown("""
                5. **G√°n nh√£n gi·∫£ v·ªõi ng∆∞·ª°ng tin c·∫≠y (threshold = 0.95)**  
                   - L·ªçc c√°c d·ª± ƒëo√°n c√≥ ƒë·ªô tin c·∫≠y ‚â• 0.95 ƒë·ªÉ g√°n nh√£n gi·∫£, c√°c m·∫´u c√≤n l·∫°i gi·ªØ nguy√™n l√† kh√¥ng c√≥ nh√£n.  
                   - Minh h·ªça:  
                   """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("mhpersoudo", "pseudo_step5.png"), caption="G√°n nh√£n gi·∫£ v·ªõi ng∆∞·ª°ng tin c·∫≠y", width=600)
                except FileNotFoundError:
                    st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'pseudo_step5.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                st.markdown("""
                6. **Hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh v·ªõi t·∫≠p d·ªØ li·ªáu m·ªõi**  
                   - K·∫øt h·ª£p t·∫≠p 1% ban ƒë·∫ßu v·ªõi d·ªØ li·ªáu v·ª´a g√°n nh√£n gi·∫£ ƒë·ªÉ hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh.  
                   - Minh h·ªça:  
                   """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("mhpersoudo", "pseudo_step6.png"), caption="Hu·∫•n luy·ªán l·∫°i v·ªõi d·ªØ li·ªáu m·ªõi", width=600)
                except FileNotFoundError:
                    st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'pseudo_step6.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                st.markdown("""
                7. **L·∫∑p l·∫°i c√°c b∆∞·ªõc 4-6 cho ƒë·∫øn khi ƒë·∫°t ƒëi·ªÅu ki·ªán d·ª´ng**  
                   - Ti·∫øp t·ª•c d·ª± ƒëo√°n, g√°n nh√£n gi·∫£ v√† hu·∫•n luy·ªán l·∫°i cho ƒë·∫øn khi kh√¥ng c√≤n d·ªØ li·ªáu kh√¥ng c√≥ nh√£n ho·∫∑c ƒë·∫°t s·ªë v√≤ng l·∫∑p t·ªëi ƒëa (v√≠ d·ª•: 5 v√≤ng).  
                   - Minh h·ªça:  
                   """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("mhpersoudo", "pseudo_step7.png"), caption="L·∫∑p l·∫°i quy tr√¨nh cho ƒë·∫øn ƒëi·ªÅu ki·ªán d·ª´ng", width=600)
                except FileNotFoundError:
                    st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'pseudo_step7.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                st.markdown("""
                8. **Hu·∫•n luy·ªán l·∫ßn cu·ªëi v√† ƒë√°nh gi√°**  
                   - Hu·∫•n luy·ªán m√¥ h√¨nh cu·ªëi c√πng tr√™n to√†n b·ªô d·ªØ li·ªáu ƒë√£ g·∫Øn nh√£n v√† ƒë√°nh gi√° tr√™n t·∫≠p test.  
                   - Minh h·ªça:  
                   """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("mhpersoudo", "pseudo_step8.png"), caption="Hu·∫•n luy·ªán l·∫ßn cu·ªëi v√† ƒë√°nh gi√°", width=600)
                except FileNotFoundError:
                    st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'pseudo_step8.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.markdown("""
                **L·ª£i √≠ch:**
                - T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t m√¥ h√¨nh b·∫±ng c√°ch khai th√°c d·ªØ li·ªáu kh√¥ng c√≥ nh√£n.
                - Gi·∫£m chi ph√≠ g·∫Øn nh√£n th·ªß c√¥ng trong c√°c d·ª± √°n th·ª±c t·∫ø.

                **Th√°ch th·ª©c:**
                - Nh√£n gi·∫£ c√≥ th·ªÉ ch·ª©a nhi·ªÖu n·∫øu m√¥ h√¨nh ban ƒë·∫ßu ch∆∞a ƒë·ªß ch√≠nh x√°c.
                - Y√™u c·∫ßu ƒëi·ªÅu ch·ªânh ng∆∞·ª°ng tin c·∫≠y ƒë·ªÉ c√¢n b·∫±ng gi·ªØa ch·∫•t l∆∞·ª£ng v√† s·ªë l∆∞·ª£ng nh√£n gi·∫£.
                """, unsafe_allow_html=True)

                st.subheader("‚öôÔ∏è C√°c tham s·ªë c·ªßa Pseudo-Labeling trong Hu·∫•n luy·ªán")
                st.markdown("""
                Trong qu√° tr√¨nh hu·∫•n luy·ªán b√†i to√°n ph√¢n lo·∫°i MNIST v·ªõi Pseudo-Labeling, c√°c tham s·ªë sau ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒëi·ªÅu khi·ªÉn k·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t n√†y:

                | **Tham s·ªë**            | **M√¥ t·∫£**                                                                |
                |-----------------------|---------------------------------------------------------------------------|
                | **Ng∆∞·ª°ng tin c·∫≠y**    | M·ª©c ƒë·ªô tin c·∫≠y t·ªëi thi·ªÉu ƒë·ªÉ g√°n nh√£n gi·∫£ cho d·ªØ li·ªáu kh√¥ng c√≥ nh√£n.       |
                | **S·ªë v√≤ng l·∫∑p t·ªëi ƒëa**| S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa c·ªßa quy tr√¨nh Pseudo-Labeling ƒë·ªÉ g·∫Øn nh√£n v√† hu·∫•n luy·ªán.|

                **Chi ti·∫øt:**
                - **Ng∆∞·ª°ng tin c·∫≠y (threshold)**:  
                - C√¥ng th·ª©c: N·∫øu ƒë·ªô tin c·∫≠y d·ª± ƒëo√°n $P(y|x) \geq \text{threshold}$, m·∫´u s·∫Ω ƒë∆∞·ª£c g√°n nh√£n gi·∫£.  
                - V√≠ d·ª•: V·ªõi threshold = 0.95, ch·ªâ c√°c d·ª± ƒëo√°n c√≥ ƒë·ªô tin c·∫≠y ‚â• 95% ƒë∆∞·ª£c ch·∫•p nh·∫≠n.  
                - T√°c ƒë·ªông: Gi√° tr·ªã cao ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng nh√£n gi·∫£ nh∆∞ng gi·∫£m s·ªë l∆∞·ª£ng m·∫´u ƒë∆∞·ª£c g·∫Øn nh√£n; gi√° tr·ªã th·∫•p tƒÉng s·ªë l∆∞·ª£ng m·∫´u nh∆∞ng c√≥ th·ªÉ g√¢y nhi·ªÖu.

                - **S·ªë v√≤ng l·∫∑p t·ªëi ƒëa (max_iterations)**:  
                - Quy ƒë·ªãnh s·ªë l·∫ßn m√¥ h√¨nh d·ª± ƒëo√°n nh√£n gi·∫£ v√† hu·∫•n luy·ªán l·∫°i tr√™n d·ªØ li·ªáu m·ªõi.  
                - ƒêi·ªÅu ki·ªán d·ª´ng: Quy tr√¨nh k·∫øt th√∫c khi h·∫øt d·ªØ li·ªáu kh√¥ng c√≥ nh√£n ho·∫∑c ƒë·∫°t s·ªë v√≤ng l·∫∑p t·ªëi ƒëa.  
                - T√°c ƒë·ªông: Gi√° tr·ªã l·ªõn tƒÉng c∆° h·ªôi khai th√°c d·ªØ li·ªáu kh√¥ng nh√£n nh∆∞ng k√©o d√†i th·ªùi gian hu·∫•n luy·ªán.
""", unsafe_allow_html=True)


    # Tab 2: Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu (Gi·ªØ nguy√™n)
    with tab_load:
        st.markdown('<div class="section-title">Ch·ªçn S·ªë l∆∞·ª£ng D·ªØ li·ªáu</div>', unsafe_allow_html=True)
        X_full, y_full = st.session_state['full_data']
        st.subheader("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u")
        sample_options = {
            "1000 m·∫´u (Th·ª≠ nghi·ªám nhanh)": 1000,
            "10,000 m·∫´u (Ki·ªÉm tra c∆° b·∫£n)": 10000,
            "50,000 m·∫´u (C√¢n b·∫±ng hi·ªáu su·∫•t)": 50000,
            "70,000 m·∫´u (Hu·∫•n luy·ªán chuy√™n s√¢u)": 70000,
            "T√πy ch·ªânh": "custom"
        }
        selected_option = st.selectbox("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u:", list(sample_options.keys()), help="Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u c√≥ s·∫µn ho·∫∑c nh·∫≠p t√πy ch·ªânh")
        if selected_option == "T√πy ch·ªânh":
            num_samples = st.number_input("Nh·∫≠p s·ªë l∆∞·ª£ng m·∫´u:", min_value=1, max_value=len(X_full), value=1000)
        else:
            num_samples = sample_options[selected_option]

        if st.button("X√°c nh·∫≠n s·ªë l∆∞·ª£ng", type="primary"):
            with st.spinner(f"ƒêang l·∫•y {num_samples} m·∫´u..."):
                indices = np.random.choice(len(X_full), size=num_samples, replace=False)
                X_sampled = X_full[indices]
                y_sampled = y_full[indices]
                st.session_state['data'] = (X_sampled.copy(), y_sampled.copy())
                st.session_state['optimal_params'] = get_optimal_params(num_samples)
                with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name="Data_Sample"):
                    mlflow.log_param("num_samples", num_samples)
                st.success(f"ƒê√£ ch·ªçn {num_samples} m·∫´u!")
                del X_full, y_full, X_sampled, y_sampled
                gc.collect()

    # Tab 3: X·ª≠ l√Ω d·ªØ li·ªáu (Gi·ªØ nguy√™n)
    with tab_preprocess:
        st.markdown('<div class="section-title">X·ª≠ l√Ω D·ªØ li·ªáu</div>', unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui l√≤ng ch·ªçn s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc.")
        else:
            X, y = st.session_state['data']
            if "data_original" not in st.session_state:
                st.session_state["data_original"] = (X.copy(), y.copy())

            st.subheader("D·ªØ li·ªáu G·ªëc")
            fig, axes = plt.subplots(2, 5, figsize=(10, 4))
            for i, ax in enumerate(axes.flat):
                ax.imshow(X[i].reshape(28, 28), cmap='gray')
                ax.set_title(f"Label: {y[i]}")
                ax.axis("off")
            st.pyplot(fig)
            plt.close(fig)

            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("Chu·∫©n h√≥a d·ªØ li·ªáu (Normalization)", type="primary", help="Chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ thang [0, 1]"):
                    with st.spinner("ƒêang chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ [0, 1]..."):
                        X_norm = X / 255.0
                        st.session_state["data_processed"] = (X_norm.copy(), y.copy())
                        st.success("ƒê√£ x·ª≠ l√Ω d·ªØ li·ªáu!")
                        del X, y, X_norm
                        gc.collect()
                        st.rerun()
            with col2:
                st.markdown("""
                    <div class="tooltip">? (Norm)
                        <span class="tooltiptext">
                            ƒê∆∞a d·ªØ li·ªáu v·ªÅ $[0, 1]$ b·∫±ng c√°ch chia cho $255$.<br>
                            C√¥ng d·ª•ng: ƒê·∫£m b·∫£o thang ƒëo ƒë·ªìng nh·∫•t cho Neural Network.
                        </span>
                    </div>
                """, unsafe_allow_html=True)

            if "data_processed" in st.session_state:
                X_processed, y_processed = st.session_state["data_processed"]
                st.success("ƒê√£ x·ª≠ l√Ω d·ªØ li·ªáu!")

    # Tab 4: Chia d·ªØ li·ªáu
    with tab_split:
        st.markdown('<div class="section-title">Chia T·∫≠p D·ªØ li·ªáu</div>', unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui l√≤ng ch·ªçn v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            data_source = st.session_state.get('data_processed', st.session_state['data'])
            X, y = data_source
            total_samples = len(X)
            st.write(f"T·ªïng s·ªë m·∫´u: {total_samples}")

            col1, col2 = st.columns(2)
            with col1:
                test_pct = st.slider("T·ª∑ l·ªá Test (%)", 0, 50, 20, help="T·ª∑ l·ªá d·ªØ li·ªáu d√πng ƒë·ªÉ ki·ªÉm tra m√¥ h√¨nh")
            with col2:
                valid_pct = st.slider("T·ª∑ l·ªá Validation (%)", 0, 50, 20, help="T·ª∑ l·ªá d·ªØ li·ªáu d√πng ƒë·ªÉ x√°c th·ª±c m√¥ h√¨nh")

            test_size = test_pct / 100
            X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
            valid_size = (valid_pct / 100) / (1 - test_size) if test_size < 1 else 0
            X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=valid_size, random_state=42)

            st.write(f"**Ph√¢n b·ªï d·ªØ li·ªáu**: Train: {len(X_train)}, Validation: {len(X_valid)}, Test: {len(X_test)}")
            if st.button("X√°c nh·∫≠n ph√¢n chia", type="primary"):
                with st.spinner("ƒêang chia d·ªØ li·ªáu..."):
                    st.session_state['split_data'] = {
                        "X_train": X_train.copy(), "y_train": y_train.copy(),
                        "X_valid": X_valid.copy(), "y_valid": y_valid.copy(),
                        "X_test": X_test.copy(), "y_test": y_test.copy()
                    }
                    st.success("ƒê√£ chia d·ªØ li·ªáu th√†nh c√¥ng!")
                    del X, y, X_temp, y_temp, X_test, y_test, X_train, X_valid, y_train, y_valid
                    gc.collect()

    # Tab 5: Hu·∫•n luy·ªán/ƒê√°nh gi√° (C·∫≠p nh·∫≠t th√™m Pseudo Labelling)
    with tab_train_eval:
        st.markdown('<div class="section-title">Hu·∫•n luy·ªán v√† ƒê√°nh gi√° M√¥ h√¨nh</div>', unsafe_allow_html=True)

        if 'split_data' not in st.session_state:
            st.info("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            split_data = st.session_state['split_data'].copy()
            X_train = split_data["X_train"]
            y_train = split_data["y_train"]
            X_valid = split_data["X_valid"]
            y_valid = split_data["y_valid"]
            X_test = split_data["X_test"]
            y_test = split_data["y_test"]

            X_train = np.array(X_train, dtype=np.float32)
            y_train = np.array(y_train, dtype=np.int32)
            X_valid = np.array(X_valid, dtype=np.float32)
            y_valid = np.array(y_valid, dtype=np.int32)
            X_test = np.array(X_test, dtype=np.float32)
            y_test = np.array(y_test, dtype=np.int32)

            if np.any(np.isnan(X_train)) or np.any(np.isnan(y_train)):
                st.error("D·ªØ li·ªáu hu·∫•n luy·ªán ch·ª©a gi√° tr·ªã NaN. ƒêang x·ª≠ l√Ω...")
                X_train = np.nan_to_num(X_train, nan=0.0)
                y_train = np.nan_to_num(y_train, nan=0.0)
                st.success("ƒê√£ thay th·∫ø NaN b·∫±ng 0 trong d·ªØ li·ªáu hu·∫•n luy·ªán!")

            num_samples = len(X_train)
            st.write(f"**S·ªë m·∫´u hu·∫•n luy·ªán**: {num_samples}")
            if X_train.shape[0] != y_train.shape[0]:
                st.error("S·ªë m·∫´u c·ªßa X_train v√† y_train kh√¥ng kh·ªõp!")
                st.stop()

            if "optimal_params" not in st.session_state:
                st.session_state["optimal_params"] = get_optimal_params(num_samples)
            
            params = st.session_state.get("training_params", st.session_state["optimal_params"].copy())

            # B·ªë c·ª•c chuy√™n nghi·ªáp
            st.subheader("‚öôÔ∏è C·∫•u h√¨nh M√¥ h√¨nh")
            with st.expander("Tham s·ªë Tham kh·∫£o", expanded=False):
                st.markdown("""
                | S·ªë m·∫´u       | S·ªë l·ªõp ·∫©n | K√≠ch th∆∞·ªõc l·ªõp ·∫©n | T·ªëc ƒë·ªô h·ªçc | S·ªë l·∫ßn l·∫∑p | H√†m k√≠ch ho·∫°t | Tr√¨nh t·ªëi ∆∞u | K√≠ch th∆∞·ªõc batch |
                |--------------|-----------|-------------------|------------|------------|---------------|--------------|------------------|
                | ‚â§ 1,000      | 1         | 32                | 0.001      | 30         | ReLU          | Adam         | 32               |
                | ‚â§ 10,000     | 2         | (64, 32)          | 0.0005     | 50         | ReLU          | Adam         | 64               |
                | ‚â§ 50,000     | 2         | (128, 64)         | 0.0003     | 70         | ReLU          | Adam         | 128              |
                | > 50,000     | 3         | (128, 64, 32)     | 0.0001     | 100        | ReLU          | Adam         | 256              |
                """, unsafe_allow_html=True)
                st.info(f"Tham s·ªë t·ªëi ∆∞u cho {num_samples} m·∫´u: {st.session_state['optimal_params']}")

            col_param1, col_param2 = st.columns(2)
            with col_param1:
                with st.expander("üß† C·∫•u tr√∫c M·∫°ng", expanded=True):
                    st.markdown("**T√πy ch·ªânh s·ªë l·ªõp ·∫©n v√† n∆°-ron**", unsafe_allow_html=True)
                    num_hidden_layers = st.number_input("S·ªë l·ªõp ·∫©n", min_value=1, value=len(params["hidden_layer_sizes"]), 
                                                       help="Ch·ªçn s·ªë l·ªõp ·∫©n ƒë·ªÉ ƒëi·ªÅu ch·ªânh ƒë·ªô ph·ª©c t·∫°p c·ªßa m√¥ h√¨nh.")
                    hidden_sizes = []
                    for i in range(num_hidden_layers):
                        default_value = params["hidden_layer_sizes"][i] if i < len(params["hidden_layer_sizes"]) else 32
                        hidden_size = st.number_input(f"S·ªë n∆°-ron l·ªõp ·∫©n {i+1}", min_value=1, value=default_value, 
                                                      help=f"S·ªë n∆°-ron cho l·ªõp ·∫©n th·ª© {i+1}.")
                        hidden_sizes.append(hidden_size)
                    params["hidden_layer_sizes"] = tuple(hidden_sizes)
                    params["activation"] = st.selectbox("H√†m k√≠ch ho·∫°t (l·ªõp ·∫©n)", ["relu", "tanh", "softmax"], 
                                                        index=["relu", "tanh", "softmax"].index(params["activation"]) if params["activation"] in ["relu", "tanh", "softmax"] else 0,
                                                        help="Ch·ªçn h√†m k√≠ch ho·∫°t cho l·ªõp ·∫©n.")
            
            with col_param2:
                with st.expander("üîß T·ªëi ∆∞u h√≥a", expanded=True):
                    st.markdown("**C·∫•u h√¨nh hu·∫•n luy·ªán**", unsafe_allow_html=True)
                    params["learning_rate"] = st.number_input("T·ªëc ƒë·ªô h·ªçc", min_value=0.0, step=0.0001, value=params["learning_rate"], 
                                                              format="%.4f", help="T·ªëc ƒë·ªô h·ªçc c√†ng nh·ªè c√†ng ·ªïn ƒë·ªãnh nh∆∞ng ch·∫≠m.")
                    params["epochs"] = st.number_input("S·ªë l·∫ßn l·∫∑p (Epochs)", min_value=1, value=params["epochs"], 
                                                       help="S·ªë l·∫ßn l·∫∑p qua to√†n b·ªô d·ªØ li·ªáu.")
                    params["batch_size"] = st.number_input("K√≠ch th∆∞·ªõc batch", min_value=1, value=params["batch_size"], 
                                                           help="S·ªë m·∫´u m·ªói l·∫ßn c·∫≠p nh·∫≠t tr·ªçng s·ªë.")
                    params["solver"] = st.selectbox("Tr√¨nh t·ªëi ∆∞u", ["adam", "sgd"], 
                                                    index=["adam", "sgd"].index(params["solver"]),
                                                    help="Adam (nhanh, hi·ªáu qu·∫£), SGD (ƒë∆°n gi·∫£n, ch·∫≠m h∆°n).")
                    early_stopping = st.checkbox("D·ª´ng s·ªõm (Early Stopping)", value=False, 
                                                 help="D·ª´ng hu·∫•n luy·ªán n·∫øu kh√¥ng c·∫£i thi·ªán tr√™n t·∫≠p validation sau 10 epochs.")

            # Th√™m t√πy ch·ªçn ch·∫ø ƒë·ªô hu·∫•n luy·ªán
            st.subheader("üîÑ Ch·∫ø ƒë·ªô Hu·∫•n luy·ªán")
            training_mode = st.selectbox("Ch·ªçn ch·∫ø ƒë·ªô hu·∫•n luy·ªán", ["Standard", "Pseudo Labelling"],
                                         help="Standard: Hu·∫•n luy·ªán th√¥ng th∆∞·ªùng. Pseudo Labelling: S·ª≠ d·ª•ng g√°n nh√£n gi·∫£ ƒë·ªÉ c·∫£i thi·ªán m√¥ h√¨nh.")

            pseudo_params = {}
            if training_mode == "Pseudo Labelling":
                with st.expander("‚öôÔ∏è C·∫•u h√¨nh Pseudo Labelling", expanded=True):
                    pseudo_params["labeled_pct"] = st.number_input("T·ª∑ l·ªá d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu m·ªói l·ªõp (%)", min_value=0.1, max_value=100.0, value=1.0,
                                                                  help="T·ª∑ l·ªá ph·∫ßn trƒÉm d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu cho m·ªói l·ªõp (0-9). M·∫∑c ƒë·ªãnh: 1%.")
                    pseudo_params["threshold"] = st.number_input("Ng∆∞·ª°ng tin c·∫≠y (Threshold)", min_value=0.0, max_value=1.0, value=0.95,
                                                                help="Ng∆∞·ª°ng x√°c su·∫•t ƒë·ªÉ g√°n nh√£n gi·∫£. M·∫∑c ƒë·ªãnh: 0.95.")
                    pseudo_params["max_iterations"] = st.number_input("S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa", min_value=1, value=10,
                                                                     help="S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa cho Pseudo Labelling. M·∫∑c ƒë·ªãnh: 10.")

            col_reset, col_empty = st.columns([1, 3])
            with col_reset:
                if st.button("üîÑ Kh√¥i ph·ª•c tham s·ªë t·ªëi ∆∞u", key="reset_params"):
                    st.session_state["training_params"] = st.session_state["optimal_params"].copy()
                    st.success("ƒê√£ kh√¥i ph·ª•c tham s·ªë t·ªëi ∆∞u!")
                    st.rerun()

            st.session_state["training_params"] = params

            # Ph·∫ßn hu·∫•n luy·ªán
            st.subheader("üöÄ Hu·∫•n luy·ªán M√¥ h√¨nh")
            with st.container():
                if 'model_name' not in st.session_state:
                    st.session_state['model_name'] = f"Model_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                model_name = st.text_input("ƒê·∫∑t t√™n cho m√¥ h√¨nh:", value=st.session_state['model_name'], 
                                           help="ƒê·∫∑t t√™n tr∆∞·ªõc khi hu·∫•n luy·ªán ƒë·ªÉ l∆∞u tr·ªØ tr√™n MLflow.")
                st.session_state['model_name'] = model_name

                if st.button("B·∫Øt ƒë·∫ßu Hu·∫•n luy·ªán", type="primary", key="start_training"):
                    try:
                        with st.spinner(f"ƒêang hu·∫•n luy·ªán m√¥ h√¨nh ({training_mode})..."):
                            start_time = time.time()
                            progress_bar = st.progress(0)
                            status_text = st.empty()

                            class ProgressCallback(callbacks.Callback):
                                def on_epoch_end(self, epoch, logs=None):
                                    progress = (epoch + 1) / params["epochs"]
                                    progress_bar.progress(min(progress, 1.0))
                                    status_text.text(f"Epoch {epoch+1}/{params['epochs']}, Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}")

                            callbacks_list = [ProgressCallback()]
                            if early_stopping and training_mode == "Standard":
                                callbacks_list.append(callbacks.EarlyStopping(monitor='val_loss', patience=10))

                            if training_mode == "Standard":
                                # Hu·∫•n luy·ªán th√¥ng th∆∞·ªùng
                                model = build_model(params)
                                history = model.fit(X_train, y_train, epochs=params["epochs"], batch_size=params["batch_size"],
                                                    validation_data=(X_valid, y_valid), callbacks=callbacks_list, verbose=0)

                                y_valid_pred = np.argmax(model.predict(X_valid, verbose=0), axis=1)
                                y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                                acc_valid = accuracy_score(y_valid, y_valid_pred)
                                acc_test = accuracy_score(y_test, y_test_pred)
                                cm_valid = confusion_matrix(y_valid, y_valid_pred)
                                cm_test = confusion_matrix(y_test, y_test_pred)

                                with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=model_name) as run:
                                    mlflow.log_params({k: v for k, v in params.items()})
                                    mlflow.log_metric("accuracy_val", acc_valid)
                                    mlflow.log_metric("accuracy_test", acc_test)
                                    mlflow.log_metric("training_time", time.time() - start_time)
                                    mlflow.log_metric("n_iter_actual", len(history.history['loss']))
                                    mlflow.keras.log_model(model, "model")

                                results = {
                                    'accuracy_val': acc_valid, 'accuracy_test': acc_test,
                                    'cm_valid': cm_valid, 'cm_test': cm_test,
                                    'run_name': model_name, 'run_id': run.info.run_id,
                                    'params': params, 'training_time': time.time() - start_time,
                                    'loss_history': history.history['loss'],
                                    'val_loss_history': history.history['val_loss'] if 'val_loss' in history.history else [],
                                    'accuracy_history': history.history['accuracy'],
                                    'val_accuracy_history': history.history['val_accuracy'] if 'val_accuracy' in history.history else [],
                                    'n_iter_actual': len(history.history['loss'])
                                }

                            else:  # Pseudo Labelling
                                # (1) L·∫•y 1% s·ªë l∆∞·ª£ng ·∫£nh cho m·ªói class
                                labeled_indices = []
                                unlabeled_indices = []
                                for digit in range(10):
                                    digit_indices = np.where(y_train == digit)[0]
                                    labeled_digit, unlabeled_digit = train_test_split(digit_indices, 
                                                                                      train_size=pseudo_params["labeled_pct"]/100, 
                                                                                      random_state=42)
                                    labeled_indices.extend(labeled_digit)
                                    unlabeled_indices.extend(unlabeled_digit)
                                labeled_indices = np.array(labeled_indices)
                                unlabeled_indices = np.array(unlabeled_indices)
                                y_labeled = y_train[labeled_indices].copy()

                                # Kh·ªüi t·∫°o bi·∫øn theo d√µi
                                test_accuracies = []
                                pseudo_counts = []
                                pseudo_samples_history = []

                                with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=model_name) as run:
                                    mlflow.log_params({**params, **pseudo_params})

                                    # (2) Hu·∫•n luy·ªán ban ƒë·∫ßu v·ªõi 1% d·ªØ li·ªáu
                                    model = build_model(params)
                                    X_labeled = X_train[labeled_indices]
                                    history = model.fit(X_labeled, y_labeled, epochs=params["epochs"], 
                                                        batch_size=params["batch_size"], callbacks=callbacks_list, verbose=0)

                                    # ƒê√°nh gi√° ban ƒë·∫ßu
                                    y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                                    acc_test = accuracy_score(y_test, y_test_pred)
                                    test_accuracies.append(acc_test)
                                    pseudo_counts.append(0)
                                    mlflow.log_metric("test_accuracy", acc_test, step=0)

                                    # V√≤ng l·∫∑p Pseudo Labelling
                                    for iteration in range(pseudo_params["max_iterations"]):
                                        if len(unlabeled_indices) == 0:
                                            status_text.text("ƒê√£ g√°n nh√£n h·∫øt d·ªØ li·ªáu!")
                                            break

                                        # (3) D·ª± ƒëo√°n tr√™n t·∫≠p unlabeled
                                        X_unlabeled = X_train[unlabeled_indices]
                                        predictions = model.predict(X_unlabeled, verbose=0)
                                        max_probs = np.max(predictions, axis=1)
                                        pseudo_mask = max_probs > pseudo_params["threshold"]

                                        if not np.any(pseudo_mask):
                                            status_text.text(f"Kh√¥ng c√≤n m·∫´u n√†o v∆∞·ª£t ng∆∞·ª°ng t·∫°i v√≤ng {iteration+1}!")
                                            break

                                        # (4) G√°n nh√£n gi·∫£
                                        pseudo_indices = unlabeled_indices[pseudo_mask]
                                        pseudo_labels = np.argmax(predictions[pseudo_mask], axis=1)
                                        pseudo_confidences = max_probs[pseudo_mask]

                                        # L∆∞u m·∫´u minh h·ªça
                                        display_indices = pseudo_indices[:min(5, len(pseudo_indices))]
                                        display_labels = pseudo_labels[:min(5, len(pseudo_labels))]
                                        display_confidences = pseudo_confidences[:min(5, len(pseudo_confidences))]
                                        pseudo_samples_history.append((display_indices, display_labels, display_confidences))

                                        # (5) C·∫≠p nh·∫≠t t·∫≠p labeled v√† unlabeled
                                        labeled_indices = np.concatenate((labeled_indices, pseudo_indices))
                                        y_labeled = np.concatenate((y_labeled, pseudo_labels))
                                        unlabeled_indices = unlabeled_indices[~pseudo_mask]

                                        # Hu·∫•n luy·ªán l·∫°i v·ªõi t·∫≠p d·ªØ li·ªáu m·ªõi
                                        X_labeled = X_train[labeled_indices]
                                        model = build_model(params)  # Reset model ƒë·ªÉ tr√°nh t√≠ch l≈©y tr·ªçng s·ªë sai l·ªách
                                        history = model.fit(X_labeled, y_labeled, epochs=params["epochs"], 
                                                            batch_size=params["batch_size"], callbacks=callbacks_list, verbose=0)

                                        # ƒê√°nh gi√° sau m·ªói v√≤ng
                                        y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                                        acc_test = accuracy_score(y_test, y_test_pred)
                                        test_accuracies.append(acc_test)
                                        pseudo_counts.append(len(pseudo_indices))
                                        mlflow.log_metric("test_accuracy", acc_test, step=iteration+1)
                                        mlflow.log_metric("pseudo_labeled_count", len(pseudo_indices), step=iteration+1)

                                        progress = (iteration + 1) / pseudo_params["max_iterations"]
                                        progress_bar.progress(min(progress, 1.0))
                                        status_text.text(f"V√≤ng {iteration+1}/{pseudo_params['max_iterations']}, Test Acc: {acc_test:.4f}, S·ªë m·∫´u g√°n nh√£n: {len(pseudo_indices)}")

                                    # ƒê√°nh gi√° cu·ªëi c√πng
                                    y_valid_pred = np.argmax(model.predict(X_valid, verbose=0), axis=1)
                                    y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                                    acc_valid = accuracy_score(y_valid, y_valid_pred)
                                    acc_test = accuracy_score(y_test, y_test_pred)
                                    cm_valid = confusion_matrix(y_valid, y_valid_pred)
                                    cm_test = confusion_matrix(y_test, y_test_pred)

                                    mlflow.log_metric("final_accuracy_val", acc_valid)
                                    mlflow.log_metric("final_accuracy_test", acc_test)
                                    mlflow.log_metric("training_time", time.time() - start_time)
                                    mlflow.keras.log_model(model, "model")

                                    results = {
                                        'accuracy_val': acc_valid, 'accuracy_test': acc_test,
                                        'cm_valid': cm_valid, 'cm_test': cm_test,
                                        'run_name': model_name, 'run_id': run.info.run_id,
                                        'params': params, 'training_time': time.time() - start_time,
                                        'loss_history': history.history['loss'],
                                        'accuracy_history': history.history['accuracy'],
                                        'n_iter_actual': len(history.history['loss']),
                                        'test_accuracies': test_accuracies,
                                        'pseudo_counts': pseudo_counts,
                                        'pseudo_samples_history': pseudo_samples_history,
                                        'mode': 'Pseudo Labelling'
                                    }

                            st.session_state['model'] = model
                            st.session_state['training_results'] = results
                            st.session_state['latest_run_id'] = run.info.run_id
                            st.success(f"ƒê√£ hu·∫•n luy·ªán xong ({training_mode})! Th·ªùi gian: {results['training_time']:.2f} gi√¢y")
                            tf.keras.backend.clear_session()

                    except Exception as e:
                        st.error(f"L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán: {e}")

            # K·∫øt qu·∫£ hu·∫•n luy·ªán
            if 'training_results' in st.session_state:
                results = st.session_state['training_results']
                st.subheader("üìä K·∫øt qu·∫£ Hu·∫•n luy·ªán")
                with st.container():
                    col_result1, col_result2, col_result3 = st.columns(3)
                    with col_result1:
                        st.metric("Th·ªùi gian hu·∫•n luy·ªán", f"{results['training_time']:.2f} gi√¢y")
                    with col_result2:
                        st.metric("ƒê·ªô ch√≠nh x√°c Validation", f"{results['accuracy_val']*100:.2f}%")
                    with col_result3:
                        st.metric("ƒê·ªô ch√≠nh x√°c Test", f"{results['accuracy_test']*100:.2f}%")

                    st.markdown("#### üìà Ma tr·∫≠n Nh·∫ßm l·∫´n")
                    st.markdown("""
                    - Ma tr·∫≠n nh·∫ßm l·∫´n cho th·∫•y s·ªë l∆∞·ª£ng d·ª± ƒëo√°n ƒë√∫ng v√† sai c·ªßa m√¥ h√¨nh cho t·ª´ng l·ªõp ($0$-$9$):  
                      - **H√†ng**: Nh√£n th·ª±c t·∫ø.  
                      - **C·ªôt**: Nh√£n d·ª± ƒëo√°n.  
                      - **S·ªë tr√™n ƒë∆∞·ªùng ch√©o**: S·ªë m·∫´u d·ª± ƒëo√°n ƒë√∫ng.  
                      - **S·ªë ngo√†i ƒë∆∞·ªùng ch√©o**: S·ªë m·∫´u d·ª± ƒëo√°n sai (nh·∫ßm l·∫´n gi·ªØa c√°c l·ªõp).  
                    """, unsafe_allow_html=True)
                    col_cm1, col_cm2 = st.columns(2)
                    with col_cm1:
                        fig, ax = plt.subplots(figsize=(6, 5))
                        sns.heatmap(results['cm_valid'], annot=True, fmt="d", cmap="Blues", ax=ax, cbar=True)
                        ax.set_title("Validation")
                        ax.set_xlabel("D·ª± ƒëo√°n")
                        ax.set_ylabel("Th·ª±c t·∫ø")
                        st.pyplot(fig)
                        plt.close(fig)
                    with col_cm2:
                        fig, ax = plt.subplots(figsize=(6, 5))
                        sns.heatmap(results['cm_test'], annot=True, fmt="d", cmap="Blues", ax=ax, cbar=True)
                        ax.set_title("Test")
                        ax.set_xlabel("D·ª± ƒëo√°n")
                        ax.set_ylabel("Th·ª±c t·∫ø")
                        st.pyplot(fig)
                        plt.close(fig)

                    st.markdown("#### üìâ Bi·ªÉu ƒë·ªì K·∫øt qu·∫£ Hu·∫•n luy·ªán")
                    if results.get('mode') == 'Pseudo Labelling':
                        st.markdown("""
                        - **ƒê·ªô ch√≠nh x√°c Test qua c√°c v√≤ng**: Th·ªÉ hi·ªán s·ª± c·∫£i thi·ªán c·ªßa m√¥ h√¨nh sau m·ªói l·∫ßn g√°n nh√£n gi·∫£.  
                        - **S·ªë m·∫´u g√°n nh√£n gi·∫£**: Cho th·∫•y s·ªë l∆∞·ª£ng m·∫´u ƒë∆∞·ª£c th√™m v√†o t·∫≠p labeled m·ªói v√≤ng.  
                        - **Minh h·ªça m·∫´u g√°n nh√£n**: Hi·ªÉn th·ªã 5 m·∫´u ƒë∆∞·ª£c g√°n nh√£n gi·∫£ m·ªói v√≤ng v·ªõi nh√£n v√† ƒë·ªô tin c·∫≠y.  
                        """, unsafe_allow_html=True)
                        col_acc, col_pseudo = st.columns(2)
                        with col_acc:
                            fig, ax = plt.subplots(figsize=(6, 4))
                            ax.plot(range(len(results['test_accuracies'])), results['test_accuracies'], 
                                    marker='o', linestyle='-', color='blue', linewidth=2, markersize=8)
                            ax.set_xlabel("V√≤ng l·∫∑p (0: Ban ƒë·∫ßu)")
                            ax.set_ylabel("ƒê·ªô ch√≠nh x√°c Test")
                            ax.set_title("ƒê·ªô ch√≠nh x√°c Test qua c√°c v√≤ng")
                            ax.grid(True, linestyle='--', alpha=0.7)
                            st.pyplot(fig)
                            plt.close(fig)
                        with col_pseudo:
                            fig, ax = plt.subplots(figsize=(6, 4))
                            ax.bar(range(len(results['pseudo_counts'])), results['pseudo_counts'], 
                                   color='orange', edgecolor='black')
                            ax.set_xlabel("V√≤ng l·∫∑p (0: Ban ƒë·∫ßu)")
                            ax.set_ylabel("S·ªë m·∫´u g√°n nh√£n")
                            ax.set_title("S·ªë m·∫´u g√°n nh√£n gi·∫£ m·ªói v√≤ng")
                            ax.grid(True, linestyle='--', alpha=0.7)
                            st.pyplot(fig)
                            plt.close(fig)

                        st.markdown("#### üñºÔ∏è Minh h·ªça c√°c m·∫´u ƒë∆∞·ª£c g√°n nh√£n gi·∫£")
                        for iteration, (indices, labels, confidences) in enumerate(results['pseudo_samples_history']):
                            st.write(f"**V√≤ng {iteration+1}:**")
                            cols = st.columns(5)
                            for i, (idx, label, conf) in enumerate(zip(indices, labels, confidences)):
                                with cols[i]:
                                    fig, ax = plt.subplots(figsize=(1.5, 1.5))
                                    ax.imshow(X_train[idx].reshape(28, 28), cmap='gray')
                                    ax.axis('off')
                                    ax.set_title(f"Label: {label}\nConf: {conf:.2f}", fontsize=8)
                                    st.pyplot(fig)
                                    plt.close(fig)

                    else:
                        st.markdown("""
                        - **Bi·ªÉu ƒë·ªì Loss**: Th·ªÉ hi·ªán gi√° tr·ªã h√†m m·∫•t m√°t qua c√°c epoch, gi√∫p ƒë√°nh gi√° m·ª©c ƒë·ªô h·ªôi t·ª• c·ªßa m√¥ h√¨nh.  
                        - **Bi·ªÉu ƒë·ªì Accuracy**: Th·ªÉ hi·ªán ƒë·ªô ch√≠nh x√°c qua c√°c epoch tr√™n t·∫≠p hu·∫•n luy·ªán v√† validation.  
                        """, unsafe_allow_html=True)
                        col_loss, col_acc = st.columns(2)
                        with col_loss:
                            if results['loss_history']:
                                epochs = list(range(1, len(results['loss_history']) + 1))
                                fig, ax = plt.subplots(figsize=(6, 4))
                                ax.plot(epochs, results['loss_history'], label='Training Loss', color='blue', linewidth=2)
                                if results.get('val_loss_history'):
                                    ax.plot(epochs, results['val_loss_history'], label='Validation Loss', color='orange', linestyle='--', linewidth=2)
                                ax.set_xlabel("Epochs")
                                ax.set_ylabel("Loss")
                                ax.set_title("Loss qua c√°c Epoch")
                                ax.legend()
                                ax.grid(True, linestyle='--', alpha=0.7)
                                st.pyplot(fig)
                                plt.close(fig)
                        with col_acc:
                            if results['accuracy_history']:
                                epochs = list(range(1, len(results['accuracy_history']) + 1))
                                fig, ax = plt.subplots(figsize=(6, 4))
                                ax.plot(epochs, results['accuracy_history'], label='Training Accuracy', color='green', linewidth=2)
                                if results.get('val_accuracy_history'):
                                    ax.plot(epochs, results['val_accuracy_history'], label='Validation Accuracy', color='red', linestyle='--', linewidth=2)
                                ax.set_xlabel("Epochs")
                                ax.set_ylabel("Accuracy")
                                ax.set_title("Accuracy qua c√°c Epoch")
                                ax.legend()
                                ax.grid(True, linestyle='--', alpha=0.7)
                                st.pyplot(fig)
                                plt.close(fig)

                    st.markdown("#### üìã T√≥m t·∫Øt K·∫øt qu·∫£ Hu·∫•n luy·ªán")
                    if results.get('mode') == 'Pseudo Labelling':
                        df_full = pd.DataFrame({
                            "V√≤ng": list(range(len(results['test_accuracies']))),
                            "Test Accuracy": results['test_accuracies'],
                            "S·ªë m·∫´u g√°n nh√£n": results['pseudo_counts']
                        })
                    else:
                        df_full = pd.DataFrame({
                            "Epoch": list(range(1, len(results['loss_history']) + 1)),
                            "Loss": results['loss_history'],
                            "Accuracy": results['accuracy_history'],
                        })
                        if results.get('val_loss_history'):
                            df_full["Val Loss"] = results['val_loss_history']
                            df_full["Val Accuracy"] = results['val_accuracy_history']

                    if 'display_epochs' not in st.session_state:
                        st.session_state['display_epochs'] = 5
                    st.table(df_full.head(st.session_state['display_epochs']))

                    if len(df_full) > st.session_state['display_epochs']:
                        if st.button("Xem th√™m 10 d√≤ng", key="show_more"):
                            st.session_state['display_epochs'] += 10
                            st.rerun()
                    if st.session_state['display_epochs'] > 5:
                        if st.button("Thu g·ªçn", key="collapse"):
                            st.session_state['display_epochs'] = 5
                            st.rerun()

                    with st.expander("Xem chi ti·∫øt", expanded=False):
                        st.markdown("**Th√¥ng tin l·∫ßn ch·∫°y:**")
                        st.write(f"- T√™n: {results['run_name']}")
                        st.write(f"- ID: {results['run_id']}")
                        st.write(f"- Th·ªùi gian hu·∫•n luy·ªán: {results['training_time']:.2f} gi√¢y")
                        st.write(f"- ƒê·ªô ch√≠nh x√°c Validation: {results['accuracy_val']*100:.2f}%")
                        st.write(f"- ƒê·ªô ch√≠nh x√°c Test: {results['accuracy_test']*100:.2f}%")
                        st.markdown("**Tham s·ªë ƒë√£ ch·ªçn:**")
                        st.json({**results['params'], **pseudo_params if training_mode == "Pseudo Labelling" else {}})

    # Tab 6: Demo d·ª± ƒëo√°n (C·∫≠p nh·∫≠t th√™m n√∫t "L√†m m·ªõi" v√† "S·ª≠ d·ª•ng m√¥ h√¨nh")
    with tab_demo:
        st.markdown('<div class="section-title">Demo D·ª± ƒëo√°n Ch·ªØ s·ªë</div>', unsafe_allow_html=True)
        st.header("D·ª± ƒëo√°n s·ªë vi·∫øt tay")
        st.write("Ch·ªçn c√°ch nh·∫≠p li·ªáu: t·∫£i l√™n h√¨nh ·∫£nh, s·ª≠ d·ª•ng d·ªØ li·ªáu Test ho·∫∑c v·∫Ω tr·ª±c ti·∫øp.")

        if 'split_data' not in st.session_state:
            st.warning("‚ö†Ô∏è Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc trong tab 'Chia d·ªØ li·ªáu'!")
        else:
            if 'mlflow_client' not in st.session_state:
                st.session_state['mlflow_client'] = MlflowClient()

            # N√∫t l√†m m·ªõi danh s√°ch m√¥ h√¨nh
            if st.button("L√†m m·ªõi danh s√°ch m√¥ h√¨nh"):
                with st.spinner("ƒêang t·∫£i danh s√°ch m√¥ h√¨nh..."):
                    runs = st.session_state['mlflow_client'].search_runs(
                        experiment_ids=[EXPERIMENT_ID], 
                        order_by=["attributes.start_time DESC"]
                    )
                    st.session_state['model_options'] = {
                        run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") 
                        for run in runs if 'mlflow.runName' in run.data.tags
                    }
                    st.success("ƒê√£ l√†m m·ªõi danh s√°ch m√¥ h√¨nh!")

            model_options = st.session_state.get('model_options', {})
            if not model_options:
                runs = st.session_state['mlflow_client'].search_runs(
                    experiment_ids=[EXPERIMENT_ID], 
                    order_by=["attributes.start_time DESC"]
                )
                model_options = {
                    run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") 
                    for run in runs if 'mlflow.runName' in run.data.tags
                }
                st.session_state['model_options'] = model_options

            if model_options:
                default_run_id = st.session_state.get('latest_run_id', list(model_options.keys())[0])
                default_model_name = model_options.get(default_run_id, list(model_options.values())[0])
                
                selected_model_name = st.selectbox(
                    "Ch·ªçn m√¥ h√¨nh:", 
                    list(model_options.values()), 
                    index=list(model_options.values()).index(default_model_name),
                    key="model_select"
                )
                selected_run_id = [k for k, v in model_options.items() if v == selected_model_name][0]

                # N√∫t s·ª≠ d·ª•ng m√¥ h√¨nh
                if st.button("S·ª≠ d·ª•ng m√¥ h√¨nh"):
                    with st.spinner("ƒêang t·∫£i m√¥ h√¨nh..."):
                        model_uri = f"runs:/{selected_run_id}/model"
                        try:
                            model = mlflow.keras.load_model(model_uri)
                            st.session_state['selected_model'] = model
                            st.session_state['selected_run_id'] = selected_run_id
                            st.success(f"ƒê√£ ch·ªçn m√¥ h√¨nh: {selected_model_name}")
                        except Exception as e:
                            st.error(f"Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh t·ª´ MLflow: {e}")
                            model = None
                else:
                    model = st.session_state.get('selected_model', None)
                    if model and st.session_state.get('selected_run_id') == selected_run_id:
                        st.write(f"**M√¥ h√¨nh hi·ªán t·∫°i**: {selected_model_name}")
                    else:
                        st.info("Nh·∫•n 'S·ª≠ d·ª•ng m√¥ h√¨nh' ƒë·ªÉ t·∫£i m√¥ h√¨nh ƒë√£ ch·ªçn.")

                if model is not None:
                    input_method = st.selectbox(
                        "Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p li·ªáu", 
                        ["T·∫£i ·∫£nh l√™n", "D·ªØ li·ªáu Test", "V·∫Ω tr·ª±c ti·∫øp"],
                        key="input_method"
                    )
                    is_normalized = 'data_processed' in st.session_state

                    def preprocess_input(data, is_normalized):
                        if not is_normalized:
                            data = data / 255.0
                        return data

                    if input_method == "T·∫£i ·∫£nh l√™n":
                        st.markdown('<p class="mode-title">D·ª± ƒëo√°n t·ª´ ·∫¢nh T·∫£i l√™n</p>', unsafe_allow_html=True)
                        uploaded_file = st.file_uploader("T·∫£i l√™n h√¨nh ·∫£nh", type=["png", "jpg", "jpeg"])
                        if uploaded_file is not None:
                            image = Image.open(uploaded_file).convert('L')
                            image = image.resize((28, 28))
                            st.image(image, caption="H√¨nh ·∫£nh ƒë·∫ßu v√†o", width=100)

                            if st.button("D·ª± ƒëo√°n", key="predict_upload_button"):
                                with st.spinner("ƒêang x·ª≠ l√Ω ·∫£nh..."):
                                    image_array = np.array(image, dtype=np.float32)
                                    image_array = image_array.reshape(1, 784)
                                    image_processed = preprocess_input(image_array, is_normalized)
                                    prediction = model.predict(image_processed, verbose=0)[0]
                                    predicted_class = np.argmax(prediction)
                                    confidence = prediction[predicted_class] * 100
                                    st.markdown(f"""
                                        <div>
                                            <strong>D·ª± ƒëo√°n:</strong> {predicted_class}<br>
                                            <strong>ƒê·ªô tin c·∫≠y:</strong> {confidence:.2f}%
                                        </div>
                                    """, unsafe_allow_html=True)
                                    fig, ax = plt.subplots(figsize=(6, 4))
                                    ax.bar(range(10), prediction * 100, color='blue')
                                    ax.set_xlabel("Ch·ªØ s·ªë")
                                    ax.set_ylabel("X√°c su·∫•t (%)")
                                    ax.set_title("Ph√¢n b·ªë x√°c su·∫•t")
                                    st.pyplot(fig)
                                    plt.close(fig)
                                    st.success("D·ª± ƒëo√°n ho√†n t·∫•t!")

                    elif input_method == "D·ªØ li·ªáu Test":
                        st.markdown('<p class="mode-title">D·ª± ƒëo√°n t·ª´ D·ªØ li·ªáu Test</p>', unsafe_allow_html=True)
                        X_test = st.session_state['split_data']["X_test"]
                        y_test = st.session_state['split_data']["y_test"]
                        if len(X_test) == 0:
                            st.warning("T·∫≠p Test r·ªóng. Vui l√≤ng chia l·∫°i d·ªØ li·ªáu v·ªõi t·ª∑ l·ªá Test > 0%.")
                        else:
                            col_select, col_display = st.columns([3, 2])
                            with col_select:
                                idx = st.slider("Ch·ªçn m·∫´u Test", 0, min(len(X_test) - 1, 100), 0)
                            with col_display:
                                st.write("**·∫¢nh m·∫´u Test:**")
                                fig, ax = plt.subplots(figsize=(2, 2))
                                ax.imshow(X_test[idx].reshape(28, 28), cmap='gray')
                                ax.axis('off')
                                st.pyplot(fig)
                                plt.close(fig)
                                st.write(f"**Nh√£n th·ª±c t·∫ø:** {y_test[idx]}")

                            if st.button("üîç D·ª± ƒëo√°n", key="predict_test"):
                                with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                                    sample = X_test[idx].reshape(1, -1)
                                    sample_processed = preprocess_input(sample, is_normalized)
                                    prediction = model.predict(sample_processed, verbose=0)[0]
                                    predicted_class = np.argmax(prediction)
                                    confidence = prediction[predicted_class] * 100
                                    st.markdown(f"""
                                        <div class="prediction-box">
                                            <strong>D·ª± ƒëo√°n:</strong> {predicted_class}<br>
                                            <strong>ƒê·ªô tin c·∫≠y:</strong> {confidence:.2f}%<br>
                                            <strong>Nh√£n th·ª±c t·∫ø:</strong> {y_test[idx]}
                                        </div>
                                    """, unsafe_allow_html=True)
                                    fig, ax = plt.subplots(figsize=(6, 4))
                                    ax.bar(range(10), prediction * 100, color='blue')
                                    ax.set_xlabel("Ch·ªØ s·ªë")
                                    ax.set_ylabel("X√°c su·∫•t (%)")
                                    ax.set_title("Ph√¢n b·ªë x√°c su·∫•t")
                                    st.pyplot(fig)
                                    plt.close(fig)
                                    st.success("D·ª± ƒëo√°n ho√†n t·∫•t!")

                    elif input_method == "V·∫Ω tr·ª±c ti·∫øp":
                        st.markdown('<p class="mode-title">V·∫Ω tr·ª±c ti·∫øp</p>', unsafe_allow_html=True)
                        st.write("V·∫Ω ch·ªØ s·ªë t·ª´ 0-9 (n√©t tr·∫Øng tr√™n n·ªÅn ƒëen):")

                        if 'canvas_result' not in st.session_state:
                            st.session_state['canvas_result'] = None

                        canvas_result = st_canvas(
                            fill_color="rgba(255, 165, 0, 0.3)",
                            stroke_width=20,
                            stroke_color="#FFFFFF",
                            background_color="#000000",
                            height=280,
                            width=280,
                            drawing_mode="freedraw",
                            key="canvas_fixed_key",
                            update_streamlit=False
                        )

                        if canvas_result.image_data is not None:
                            st.session_state['canvas_result'] = canvas_result

                        col_pred, col_clear = st.columns([2, 1])
                        with col_pred:
                            if st.button("D·ª± ƒëo√°n", key="predict_button"):
                                if st.session_state['canvas_result'] is not None:
                                    with st.spinner("ƒêang x·ª≠ l√Ω h√¨nh v·∫Ω..."):
                                        image = Image.fromarray(
                                            st.session_state['canvas_result'].image_data.astype('uint8'), 'RGBA'
                                        ).convert('L')
                                        image_resized = image.resize((28, 28))
                                        image_array = np.array(image_resized, dtype=np.float32).reshape(1, 784)
                                        image_processed = preprocess_input(image_array, is_normalized)
                                        prediction = model.predict(image_processed, verbose=0)[0]
                                        predicted_class = np.argmax(prediction)
                                        confidence = prediction[predicted_class] * 100
                                        st.markdown(f"""
                                            <div>
                                                <strong>D·ª± ƒëo√°n:</strong> {predicted_class}<br>
                                                <strong>ƒê·ªô tin c·∫≠y:</strong> {confidence:.2f}%
                                            </div>
                                        """, unsafe_allow_html=True)
                                        fig, ax = plt.subplots(figsize=(6, 4))
                                        ax.bar(range(10), prediction * 100, color='blue')
                                        ax.set_xlabel("Ch·ªØ s·ªë")
                                        ax.set_ylabel("X√°c su·∫•t (%)")
                                        ax.set_title("Ph√¢n b·ªë x√°c su·∫•t")
                                        st.pyplot(fig)
                                        plt.close(fig)
                                        st.success("D·ª± ƒëo√°n ho√†n t·∫•t!")
                                else:
                                    st.warning("Vui l√≤ng v·∫Ω tr∆∞·ªõc khi d·ª± ƒëo√°n!")
            else:
                st.warning("Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c l∆∞u trong MLflow.")

    # Tab 7: Th√¥ng tin hu·∫•n luy·ªán
    with tab_log_info:
        st.markdown('<div class="section-title">Theo d√µi K·∫øt qu·∫£</div>', unsafe_allow_html=True)
        try:
            with st.spinner("ƒêang t·∫£i th√¥ng tin hu·∫•n luy·ªán..."):
                client = MlflowClient()
                runs = client.search_runs(experiment_ids=[EXPERIMENT_ID], order_by=["attributes.start_time DESC"])
                if not runs:
                    st.info(f"Ch∆∞a c√≥ l·∫ßn ch·∫°y n√†o trong Experiment ID {EXPERIMENT_ID}.")
                else:
                    run_options = {run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") for run in runs}
                    selected_run_name = st.selectbox("Ch·ªçn run:", list(run_options.values()))
                    selected_run_id = [k for k, v in run_options.items() if v == selected_run_name][0]
                    selected_run = client.get_run(selected_run_id)

                    st.subheader("ƒê·ªïi t√™n Run")
                    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", value=selected_run_name)
                    if st.button("C·∫≠p nh·∫≠t t√™n"):
                        client.set_tag(selected_run_id, "mlflow.runName", new_run_name.strip())
                        st.success(f"ƒê√£ ƒë·ªïi t√™n th√†nh: {new_run_name.strip()}")
                        st.rerun()

                    st.subheader("X√≥a Run")
                    if st.button("X√≥a l·∫ßn ch·∫°y"):
                        client.delete_run(selected_run_id)
                        st.success(f"ƒê√£ x√≥a: {selected_run_name}")
                        st.rerun()

                    st.subheader("Th√¥ng tin chi ti·∫øt")
                    st.write(f"**T√™n:** {selected_run_name}")
                    st.write(f"**ID:** {selected_run_id}")
                    st.write(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** {datetime.fromtimestamp(selected_run.info.start_time / 1000)}")
                    
                    st.markdown("**Tham s·ªë hu·∫•n luy·ªán:**")
                    st.json(selected_run.data.params, expanded=True)
                    
                    st.markdown("**S·ªë li·ªáu hu·∫•n luy·ªán:**")
                    st.json(selected_run.data.metrics, expanded=True)

                    st.subheader("üìà L·ªãch s·ª≠ Hu·∫•n luy·ªán")
                    col_loss, col_acc = st.columns(2)
                    with col_loss:
                        if 'training_results' in st.session_state and selected_run_id == st.session_state['training_results']['run_id']:
                            results = st.session_state['training_results']
                            if results.get('mode') == 'Pseudo Labelling' and results['test_accuracies']:
                                fig, ax = plt.subplots(figsize=(6, 4))
                                ax.plot(range(len(results['test_accuracies'])), results['test_accuracies'], 
                                        marker='o', linestyle='-', color='blue', linewidth=2, markersize=8)
                                ax.set_xlabel("V√≤ng l·∫∑p")
                                ax.set_ylabel("Test Accuracy")
                                ax.set_title("Test Accuracy qua c√°c v√≤ng")
                                ax.grid(True)
                                st.pyplot(fig)
                                plt.close(fig)
                            elif results['loss_history']:
                                fig, ax = plt.subplots(figsize=(6, 4))
                                ax.plot(range(1, len(results['loss_history']) + 1), results['loss_history'], 
                                        label='Training Loss', color='blue', linewidth=2)
                                if results.get('val_loss_history'):
                                    ax.plot(range(1, len(results['val_loss_history']) + 1), results['val_loss_history'], 
                                            label='Validation Loss', color='orange', linestyle='--', linewidth=2)
                                ax.set_xlabel("Epochs")
                                ax.set_ylabel("Loss")
                                ax.set_title("L·ªãch s·ª≠ M·∫•t m√°t")
                                ax.legend()
                                ax.grid(True)
                                st.pyplot(fig)
                                plt.close(fig)
                    with col_acc:
                        if 'training_results' in st.session_state and selected_run_id == st.session_state['training_results']['run_id']:
                            results = st.session_state['training_results']
                            if results.get('mode') == 'Pseudo Labelling' and results['pseudo_counts']:
                                fig, ax = plt.subplots(figsize=(6, 4))
                                ax.bar(range(len(results['pseudo_counts'])), results['pseudo_counts'], 
                                       color='orange', edgecolor='black')
                                ax.set_xlabel("V√≤ng l·∫∑p")
                                ax.set_ylabel("S·ªë m·∫´u g√°n nh√£n")
                                ax.set_title("S·ªë m·∫´u g√°n nh√£n m·ªói v√≤ng")
                                ax.grid(True)
                                st.pyplot(fig)
                                plt.close(fig)
                            elif results['accuracy_history']:
                                fig, ax = plt.subplots(figsize=(6, 4))
                                ax.plot(range(1, len(results['accuracy_history']) + 1), results['accuracy_history'], 
                                        label='Training Accuracy', color='green', linewidth=2)
                                if results.get('val_accuracy_history'):
                                    ax.plot(range(1, len(results['val_accuracy_history']) + 1), results['val_accuracy_history'], 
                                            label='Validation Accuracy', color='red', linestyle='--', linewidth=2)
                                ax.set_xlabel("Epochs")
                                ax.set_ylabel("Accuracy")
                                ax.set_title("L·ªãch s·ª≠ ƒê·ªô ch√≠nh x√°c")
                                ax.legend()
                                ax.grid(True)
                                st.pyplot(fig)
                                plt.close(fig)

                    st.subheader("So s√°nh c√°c Run")
                    selected_runs = st.multiselect("Ch·ªçn c√°c run ƒë·ªÉ so s√°nh:", list(run_options.values()), default=[selected_run_name])
                    if selected_runs:
                        selected_run_ids = [k for k, v in run_options.items() if v in selected_runs]
                        comparison_data = []
                        for run_id in selected_run_ids:
                            run = client.get_run(run_id)
                            run_data = {
                                "T√™n": run.data.tags.get('mlflow.runName', run_id),
                                "Accuracy Val": run.data.metrics.get('accuracy_val', run.data.metrics.get('final_accuracy_val', 'N/A')),
                                "Accuracy Test": run.data.metrics.get('accuracy_test', run.data.metrics.get('final_accuracy_test', 'N/A')),
                                "Th·ªùi gian": run.data.metrics.get('training_time', 'N/A'),
                                "S·ªë l·ªõp ·∫©n": run.data.params.get('hidden_layer_sizes', 'N/A'),
                                "Learning Rate": run.data.params.get('learning_rate', 'N/A'),
                                "Epochs": run.data.params.get('epochs', 'N/A')
                            }
                            comparison_data.append(run_data)
                        st.table(pd.DataFrame(comparison_data))

        except Exception as e:
            st.error(f"L·ªói khi t·∫£i th√¥ng tin hu·∫•n luy·ªán: {e}. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi MLflow ho·∫∑c th√¥ng tin Experiment ID.")
        mlflow_ui_link = f"{mlflow_tracking_uri}/#/experiments/{EXPERIMENT_ID}"
        st.markdown("---")
        st.markdown(f"üìä **Xem chi ti·∫øt tr√™n MLflow UI**: [Nh·∫•n v√†o ƒë√¢y]({mlflow_ui_link})", unsafe_allow_html=True)

if __name__ == "__main__":
    run_mnist_neural_network_app()