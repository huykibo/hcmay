import os
import mlflow
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from datetime import datetime
import time
import requests
import io
import sys
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
import gc

# H√†m ch·ªçn tham s·ªë t·ªëi ∆∞u d·ª±a tr√™n s·ªë m·∫´u
def get_optimal_params(num_samples):
    """X√°c ƒë·ªãnh tham s·ªë t·ªëi ∆∞u cho m√¥ h√¨nh d·ª±a tr√™n s·ªë l∆∞·ª£ng m·∫´u."""
    if num_samples <= 1000:
        return {
            "hidden_layer_sizes": (32,),
            "learning_rate": 0.001,
            "epochs": 30,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 32,
            "threshold": 0.95,  # Pseudo-Labeling
            "max_iterations": 5  # Pseudo-Labeling
        }
    elif num_samples <= 10000:
        return {
            "hidden_layer_sizes": (64, 32),
            "learning_rate": 0.0005,
            "epochs": 50,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 64,
            "threshold": 0.95,
            "max_iterations": 10
        }
    elif num_samples <= 50000:
        return {
            "hidden_layer_sizes": (128, 64),
            "learning_rate": 0.0003,
            "epochs": 70,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 128,
            "threshold": 0.95,
            "max_iterations": 15
        }
    else:  # > 50,000
        return {
            "hidden_layer_sizes": (128, 64, 32),
            "learning_rate": 0.0001,
            "epochs": 100,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 256,
            "threshold": 0.95,
            "max_iterations": 20
        }

# H√†m x√¢y d·ª±ng m√¥ h√¨nh Neural Network
def build_model(params):
    """X√¢y d·ª±ng m√¥ h√¨nh Neural Network d·ª±a tr√™n tham s·ªë."""
    model = models.Sequential()
    model.add(layers.InputLayer(input_shape=(784,)))
    for units in params["hidden_layer_sizes"]:
        model.add(layers.Dense(units, activation=params["activation"]))
    model.add(layers.Dense(10, activation='softmax'))
    optimizer = tf.keras.optimizers.Adam(learning_rate=params["learning_rate"]) if params["solver"] == "adam" else tf.keras.optimizers.SGD(learning_rate=params["learning_rate"])
    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model

# ·ª®ng d·ª•ng ch√≠nh
def run_mnist_pseudo_labeling_app():
    """Ch·∫°y ·ª©ng d·ª•ng Streamlit ƒë·ªÉ ph√¢n lo·∫°i ch·ªØ s·ªë MNIST v·ªõi Neural Network v√† Pseudo-Labeling."""

    ### Thi·∫øt l·∫≠p MLflow
    mlflow_tracking_uri = "https://dagshub.com/huykibo/streamlit_mlflow.mlflow"
    try:
        os.environ["MLFLOW_TRACKING_USERNAME"] = st.secrets["mlflow"]["MLFLOW_TRACKING_USERNAME"]
        os.environ["MLFLOW_TRACKING_PASSWORD"] = st.secrets["mlflow"]["MLFLOW_TRACKING_PASSWORD"]
        mlflow.set_tracking_uri(mlflow_tracking_uri)
    except KeyError as e:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y kh√≥a {e} trong st.secrets.")
        st.stop()

    try:
        response = requests.get(mlflow_tracking_uri, timeout=5)
        if response.status_code != 200:
            st.error(f"K·∫øt n·ªëi MLflow th·∫•t b·∫°i. M√£ tr·∫°ng th√°i: {response.status_code}.")
            st.stop()
    except requests.exceptions.RequestException as e:
        st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi MLflow: {e}.")
        st.stop()

    EXPERIMENT_ID = "6"
    try:
        client = MlflowClient()
        experiment = client.get_experiment(EXPERIMENT_ID)
        if experiment is None:
            st.error(f"Experiment ID {EXPERIMENT_ID} kh√¥ng t·ªìn t·∫°i.")
            st.stop()
    except Exception as e:
        st.error(f"L·ªói truy xu·∫•t Experiment ID {EXPERIMENT_ID}: {e}.")
        st.stop()

    ### T·∫£i d·ªØ li·ªáu MNIST
    if 'full_data' not in st.session_state:
        with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu MNIST..."):
            (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
            X_full = np.concatenate([X_train, X_test], axis=0)
            y_full = np.concatenate([y_train, y_test], axis=0)
            X_full = X_full.reshape(-1, 784).astype(np.float32)
            y_full = y_full.astype(np.int32)
            st.session_state['full_data'] = (X_full, y_full)

    st.title("Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Neural Network v√† Pseudo-Labeling")

    ### CSS t√πy ch·ªânh
    st.markdown("""
        <style>
            .section-title {
                font-size: 1.5em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 10px;
            }
            .stCanvas {
                border: 1px solid #ddd;
                border-radius: 5px;
            }
            .tooltip {
                position: relative;
                display: inline-block;
                cursor: pointer;
                color: #3498db;
                font-weight: bold;
            }
            .tooltip .tooltiptext {
                visibility: hidden;
                width: 220px;
                background-color: #555;
                color: #fff;
                text-align: center;
                border-radius: 6px;
                padding: 5px;
                position: absolute;
                z-index: 1;
                bottom: 125%;
                left: 50%;
                margin-left: -110px;
                opacity: 0;
                transition: opacity 0.3s;
            }
            .tooltip:hover .tooltiptext {
                visibility: visible;
                opacity: 1;
            }
        </style>
    """, unsafe_allow_html=True)

    ### T·∫°o c√°c tab
    tab_names = ["Th√¥ng tin", "Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu", "X·ª≠ l√Ω d·ªØ li·ªáu", "Chia d·ªØ li·ªáu", 
                 "Hu·∫•n luy·ªán/ƒê√°nh gi√°", "Demo d·ª± ƒëo√°n", "Th√¥ng tin hu·∫•n luy·ªán"]
    tab_info, tab_load, tab_preprocess, tab_split, tab_train_eval, tab_demo, tab_log_info = st.tabs(tab_names)

    # Tab 1: Th√¥ng tin
    with tab_info:
        # T·∫°o container ri√™ng ƒë·ªÉ ch·ª©a n·ªôi dung c·ªßa tab n√†y
        info_container = st.container()
        with info_container:
            st.header("Gi·ªõi thi·ªáu ·ª®ng d·ª•ng Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Neural Network v√† Pseudo-Labeling")
            st.markdown("""
            Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay t·ª´ t·∫≠p d·ªØ li·ªáu **MNIST** s·ª≠ d·ª•ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)** k·∫øt h·ª£p v·ªõi k·ªπ thu·∫≠t **Pseudo-Labeling**. ·ª®ng d·ª•ng n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ cung c·∫•p tr·∫£i nghi·ªám tr·ª±c quan, h·ªó tr·ª£ h·ªçc t·∫≠p v√† nghi√™n c·ª©u v·ªÅ c√°c thu·∫≠t to√°n h·ªçc m√°y hi·ªán ƒë·∫°i.
            """, unsafe_allow_html=True)

            st.subheader("Ch·ªçn n·ªôi dung ƒë·ªÉ kh√°m ph√°")
            info_option = st.selectbox(
                "",
                [
                    "T·ªïng quan v·ªÅ ·ª©ng d·ª•ng v√† m·ª•c ti√™u",
                    "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a",
                    "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o",
                    "Pseudo-Labeling ‚Äì K·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t"
                ],
                label_visibility="collapsed",
                help="Kh√°m ph√° chi ti·∫øt v·ªÅ ·ª©ng d·ª•ng, d·ªØ li·ªáu, m√¥ h√¨nh v√† k·ªπ thu·∫≠t Pseudo-Labeling."
            )

            # T·∫°o placeholder ƒë·ªÉ ch·ª©a n·ªôi dung ƒë·ªông
            content_placeholder = st.empty()

            # Hi·ªÉn th·ªã n·ªôi dung m·ªõi d·ª±a tr√™n l·ª±a ch·ªçn
            with content_placeholder.container():
                if info_option == "T·ªïng quan v·ªÅ ·ª©ng d·ª•ng v√† m·ª•c ti√™u":
                    with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        for i in range(0, 101, 10):
                            progress_bar.progress(i)
                            status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                            time.sleep(0.05)
                        st.subheader("üìå T·ªïng quan v·ªÅ ·ª©ng d·ª•ng v√† m·ª•c ti√™u")
                        st.markdown("""
                        ·ª®ng d·ª•ng n√†y t·∫≠p trung v√†o vi·ªác ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu **MNIST**, m·ªôt b·ªô d·ªØ li·ªáu ti√™u chu·∫©n trong lƒ©nh v·ª±c h·ªçc m√°y. K·∫øt h·ª£p **Neural Network** v√† **Pseudo-Labeling**, ·ª©ng d·ª•ng kh√¥ng ch·ªâ t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t m√¥ h√¨nh m√† c√≤n t·∫≠n d·ª•ng d·ªØ li·ªáu kh√¥ng c√≥ nh√£n ƒë·ªÉ n√¢ng cao kh·∫£ nƒÉng h·ªçc t·∫≠p.

                        **M·ª•c ti√™u ch√≠nh:**
                        - Ph√°t tri·ªÉn m·ªôt m√¥ h√¨nh Neural Network c√≥ kh·∫£ nƒÉng nh·∫≠n di·ªán ch√≠nh x√°c c√°c ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9.
                        - √Åp d·ª•ng k·ªπ thu·∫≠t Pseudo-Labeling ƒë·ªÉ khai th√°c d·ªØ li·ªáu kh√¥ng c√≥ nh√£n, m√¥ ph·ªèng c√°c t√¨nh hu·ªëng th·ª±c t·∫ø khi d·ªØ li·ªáu c√≥ nh√£n h·∫°n ch·∫ø.
                        - Cung c·∫•p giao di·ªán tr·ª±c quan ƒë·ªÉ ng∆∞·ªùi d√πng th·ª±c h√†nh, ƒë√°nh gi√° v√† t√πy ch·ªânh m√¥ h√¨nh.

                        **Th√¥ng tin c∆° b·∫£n v·ªÅ d·ªØ li·ªáu:**
                        - **Quy m√¥:** 70,000 ·∫£nh, m·ªói ·∫£nh k√≠ch th∆∞·ªõc 28x28 pixel (t·ªïng c·ªông 784 ƒë·∫∑c tr∆∞ng).
                        - **ƒê·∫∑c tr∆∞ng:** Gi√° tr·ªã pixel t·ª´ 0 ƒë·∫øn 255, bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng vector 784 chi·ªÅu.
                        - **Nhi·ªám v·ª•:** D·ª± ƒëo√°n nh√£n t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9.
                        """, unsafe_allow_html=True)
                        time.sleep(0.5)
                        status_text.empty()
                        progress_bar.empty()

                elif info_option == "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a":
                    with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        for i in range(0, 101, 10):
                            progress_bar.progress(i)
                            status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                            time.sleep(0.05)
                        st.subheader("üìå T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a")
                        st.markdown("""
                        **MNIST** l√† m·ªôt t·∫≠p d·ªØ li·ªáu ti√™u chu·∫©n trong h·ªçc m√°y, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Yann LeCun v√† c√°c c·ªông s·ª±, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh ph√¢n lo·∫°i.

                        **ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t:**
                        - **Ngu·ªìn g·ªëc:** Bao g·ªìm ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ h·ªçc sinh trung h·ªçc v√† nh√¢n vi√™n ƒëi·ªÅu tra d√¢n s·ªë Hoa K·ª≥.
                        - **K√≠ch th∆∞·ªõc:** M·ªói ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i 28x28 pixel, thang ƒë·ªô x√°m v·ªõi gi√° tr·ªã t·ª´ 0 ƒë·∫øn 255.
                        - **Quy m√¥:** T·ªïng c·ªông 70,000 ·∫£nh, chia th√†nh t·∫≠p hu·∫•n luy·ªán (60,000 ·∫£nh) v√† t·∫≠p ki·ªÉm tra (10,000 ·∫£nh).

                        **√ù nghƒ©a:**
                        - L√† n·ªÅn t·∫£ng l√Ω t∆∞·ªüng ƒë·ªÉ th·ª≠ nghi·ªám c√°c thu·∫≠t to√°n h·ªçc m√°y, t·ª´ c∆° b·∫£n ƒë·∫øn n√¢ng cao.
                        - Gi√∫p ƒë√°nh gi√° kh·∫£ nƒÉng ph√¢n bi·ªát c√°c l·ªõp t∆∞∆°ng t·ª± (v√≠ d·ª•: 4 v√† 9) trong c√°c m√¥ h√¨nh Neural Network.
                        - H·ªó tr·ª£ nghi√™n c·ª©u v√† ƒë√†o t·∫°o cho c·∫£ ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu l·∫´n c√°c chuy√™n gia trong lƒ©nh v·ª±c h·ªçc s√¢u.
                        """, unsafe_allow_html=True)
                        try:
                            st.image(os.path.join("mnist.png"), caption="T·ªïng quan v·ªÅ t·∫≠p d·ªØ li·ªáu MNIST", width=800)
                        except FileNotFoundError:
                            st.warning("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça 'mnist.png'. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                        except Exception as e:
                            st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                        status_text.text("ƒê√£ t·∫£i xong! 100%")
                        time.sleep(0.5)
                        status_text.empty()
                        progress_bar.empty()

                elif info_option == "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o":
                    with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        for i in range(0, 101, 10):
                            progress_bar.progress(i)
                            status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                            time.sleep(0.05)
                        st.subheader("üìå Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o")
                        st.markdown("""
                        **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o)** l√† m·ªôt m√¥ h√¨nh h·ªçc m√°y m√¥ ph·ªèng c√°ch ho·∫°t ƒë·ªông c·ªßa m·∫°ng n∆°-ron sinh h·ªçc trong n√£o ng∆∞·ªùi. N√≥ ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu, ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ v·ªõi b√†i to√°n nh·∫≠n di·ªán h√¨nh ·∫£nh nh∆∞ MNIST.

                        **C·∫•u tr√∫c c∆° b·∫£n:**
                        - **L·ªõp ƒë·∫ßu v√†o (Input Layer)**: Nh·∫≠n d·ªØ li·ªáu th√¥ (v√≠ d·ª•: 784 pixel t·ª´ ·∫£nh MNIST).
                        - **L·ªõp ·∫©n (Hidden Layers)**: X·ª≠ l√Ω th√¥ng tin th√¥ng qua c√°c ph√©p t√≠nh tuy·∫øn t√≠nh v√† phi tuy·∫øn.
                        - **L·ªõp ƒë·∫ßu ra (Output Layer)**: ƒê∆∞a ra d·ª± ƒëo√°n (10 l·ªõp, t·ª´ 0-9).

                        **∆Øu ƒëi·ªÉm:**
                        - C√≥ kh·∫£ nƒÉng h·ªçc c√°c m·ªëi quan h·ªá phi tuy·∫øn t√≠nh ph·ª©c t·∫°p.
                        - T·ª± ƒë·ªông tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng m√† kh√¥ng c·∫ßn x·ª≠ l√Ω th·ªß c√¥ng.

                        **Nh∆∞·ª£c ƒëi·ªÉm:**
                        - Y√™u c·∫ßu nhi·ªÅu d·ªØ li·ªáu v√† t√†i nguy√™n t√≠nh to√°n.
                        - Kh√≥ gi·∫£i th√≠ch k·∫øt qu·∫£ d·ª± ƒëo√°n.
                        """, unsafe_allow_html=True)
                        status_text.empty()
                        progress_bar.empty()

                elif info_option == "Pseudo-Labeling ‚Äì K·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t":
                    with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        for i in range(0, 101, 10):
                            progress_bar.progress(i)
                            status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                            time.sleep(0.05)
                        st.subheader("üìå Pseudo-Labeling ‚Äì K·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t")
                        st.markdown("""
                        **Pseudo-Labeling** l√† m·ªôt k·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t nh·∫±m t·∫≠n d·ª•ng d·ªØ li·ªáu kh√¥ng c√≥ nh√£n ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t m√¥ h√¨nh khi d·ªØ li·ªáu c√≥ nh√£n khan hi·∫øm.

                        **Quy tr√¨nh:**
                        1. Hu·∫•n luy·ªán m√¥ h√¨nh ban ƒë·∫ßu tr√™n t·∫≠p d·ªØ li·ªáu c√≥ nh√£n nh·ªè.
                        2. D·ª± ƒëo√°n nh√£n cho d·ªØ li·ªáu kh√¥ng c√≥ nh√£n.
                        3. G√°n nh√£n gi·∫£ (pseudo-labels) cho c√°c m·∫´u c√≥ ƒë·ªô tin c·∫≠y cao.
                        4. K·∫øt h·ª£p d·ªØ li·ªáu c√≥ nh√£n v√† nh√£n gi·∫£ ƒë·ªÉ hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh.
                        5. L·∫∑p l·∫°i cho ƒë·∫øn khi ƒë·∫°t ƒëi·ªÅu ki·ªán d·ª´ng.

                        **L·ª£i √≠ch:**
                        - TƒÉng c∆∞·ªùng hi·ªáu su·∫•t m√† kh√¥ng c·∫ßn th√™m d·ªØ li·ªáu c√≥ nh√£n.
                        - Ph√π h·ª£p v·ªõi th·ª±c t·∫ø khi vi·ªác g·∫Øn nh√£n th·ªß c√¥ng t·ªën k√©m.

                        **Th√°ch th·ª©c:**
                        - Nh√£n gi·∫£ c√≥ th·ªÉ ch·ª©a nhi·ªÖu n·∫øu m√¥ h√¨nh ban ƒë·∫ßu kh√¥ng ƒë·ªß t·ªët.
                        - C·∫ßn ƒëi·ªÅu ch·ªânh ng∆∞·ª°ng tin c·∫≠y ƒë·ªÉ c√¢n b·∫±ng gi·ªØa s·ªë l∆∞·ª£ng v√† ch·∫•t l∆∞·ª£ng nh√£n gi·∫£.
                        """, unsafe_allow_html=True)
                        status_text.empty()
                        progress_bar.empty()

    # Tab 2: Ch·ªçn s·ªë l∆∞·ª£ng d·ªØ li·ªáu
    with tab_load:
        load_container = st.container()
        with load_container:
            st.markdown('<div class="section-title">Ch·ªçn S·ªë l∆∞·ª£ng D·ªØ li·ªáu</div>', unsafe_allow_html=True)
            X_full, y_full = st.session_state['full_data']
            st.subheader("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u")
            sample_options = {
                "1000 m·∫´u": 1000,
                "10,000 m·∫´u": 10000,
                "50,000 m·∫´u": 50000,
                "70,000 m·∫´u": 70000,
                "T√πy ch·ªânh": "custom"
            }
            selected_option = st.selectbox("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u:", list(sample_options.keys()))
            if selected_option == "T√πy ch·ªânh":
                num_samples = st.number_input("Nh·∫≠p s·ªë l∆∞·ª£ng m·∫´u:", min_value=1, max_value=len(X_full), value=1000)
            else:
                num_samples = sample_options[selected_option]

            if st.button("X√°c nh·∫≠n s·ªë l∆∞·ª£ng", type="primary"):
                with st.spinner(f"ƒêang l·∫•y {num_samples} m·∫´u..."):
                    indices = np.random.choice(len(X_full), size=num_samples, replace=False)
                    X_sampled = X_full[indices]
                    y_sampled = y_full[indices]
                    st.session_state['data'] = (X_sampled.copy(), y_sampled.copy())
                    st.session_state['optimal_params'] = get_optimal_params(num_samples)
                    with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name="Data_Sample"):
                        mlflow.log_param("num_samples", num_samples)
                    st.success(f"ƒê√£ ch·ªçn {num_samples} m·∫´u!")
                    del X_full, y_full, X_sampled, y_sampled
                    gc.collect()

    # Tab 3: X·ª≠ l√Ω d·ªØ li·ªáu
    with tab_preprocess:
        preprocess_container = st.container()
        with preprocess_container:
            st.markdown('<div class="section-title">X·ª≠ l√Ω D·ªØ li·ªáu</div>', unsafe_allow_html=True)
            if 'data' not in st.session_state:
                st.info("Vui l√≤ng ch·ªçn s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc.")
            else:
                X, y = st.session_state['data']
                if "data_original" not in st.session_state:
                    st.session_state["data_original"] = (X.copy(), y.copy())

                st.subheader("D·ªØ li·ªáu G·ªëc")
                fig, axes = plt.subplots(2, 5, figsize=(12, 5))
                for i, ax in enumerate(axes.flat):
                    ax.imshow(X[i].reshape(28, 28), cmap='gray')
                    ax.set_title(f"Label: {y[i]}")
                    ax.axis("off")
                plt.tight_layout()
                st.pyplot(fig)
                plt.close(fig)

                col1, col2 = st.columns([3, 1])
                with col1:
                    if st.button("Chu·∫©n h√≥a d·ªØ li·ªáu (Normalization)", type="primary", help="Chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ thang [0, 1]"):
                        with st.spinner("ƒêang chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ [0, 1]..."):
                            X_norm = X / 255.0
                            st.session_state["data_processed"] = (X_norm.copy(), y.copy())
                            st.success("ƒê√£ x·ª≠ l√Ω d·ªØ li·ªáu!")
                            del X, y, X_norm
                            gc.collect()
                            st.rerun()
                with col2:
                    st.markdown("""
                        <div class="tooltip">? (Norm)
                            <span class="tooltiptext">
                                ƒê∆∞a d·ªØ li·ªáu v·ªÅ $[0, 1]$ b·∫±ng c√°ch chia cho $255$.<br>
                                C√¥ng d·ª•ng: ƒê·∫£m b·∫£o thang ƒëo ƒë·ªìng nh·∫•t cho Neural Network.
                            </span>
                        </div>
                    """, unsafe_allow_html=True)

                if "data_processed" in st.session_state:
                    X_processed, y_processed = st.session_state["data_processed"]
                    st.subheader("D·ªØ li·ªáu sau khi x·ª≠ l√Ω")
                    fig, axes = plt.subplots(2, 5, figsize=(12, 5))
                    for i, ax in enumerate(axes.flat):
                        ax.imshow(X_processed[i].reshape(28, 28), cmap='gray')
                        ax.set_title(f"Label: {y_processed[i]}")
                        ax.axis("off")
                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.close(fig)

    # Tab 4: Chia d·ªØ li·ªáu
    with tab_split:
        split_container = st.container()
        with split_container:
            st.markdown('<div class="section-title">Chia T·∫≠p D·ªØ li·ªáu</div>', unsafe_allow_html=True)
            if 'data' not in st.session_state:
                st.info("Vui l√≤ng ch·ªçn v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc.")
            else:
                data_source = st.session_state.get('data_processed', st.session_state['data'])
                X, y = data_source
                total_samples = len(X)
                st.write(f"T·ªïng s·ªë m·∫´u: {total_samples}")

                test_pct = st.slider("T·ª∑ l·ªá Test (%)", 0, 50, 20)
                test_size = test_pct / 100
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

                st.write(f"**Ph√¢n b·ªï d·ªØ li·ªáu**: Train: {len(X_train)}, Test: {len(X_test)}")
                if st.button("X√°c nh·∫≠n ph√¢n chia", type="primary"):
                    with st.spinner("ƒêang chia d·ªØ li·ªáu..."):
                        st.session_state['split_data'] = {
                            "X_train": X_train.copy(), "y_train": y_train.copy(),
                            "X_test": X_test.copy(), "y_test": y_test.copy()
                        }
                        st.success("ƒê√£ chia d·ªØ li·ªáu th√†nh c√¥ng!")
                        del X, y, X_train, X_test, y_train, y_test
                        gc.collect()

    # Tab 5: Hu·∫•n luy·ªán/ƒê√°nh gi√°
    with tab_train_eval:
        train_eval_container = st.container()
        with train_eval_container:
            st.markdown('<div class="section-title">Hu·∫•n luy·ªán v√† ƒê√°nh gi√°</div>', unsafe_allow_html=True)
            if 'split_data' not in st.session_state:
                st.info("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc.")
            else:
                split_data = st.session_state['split_data'].copy()
                X_train = split_data["X_train"]
                y_train = split_data["y_train"]
                X_test = split_data["X_test"]
                y_test = split_data["y_test"]

                X_train = np.array(X_train, dtype=np.float32)
                y_train = np.array(y_train, dtype=np.int32)
                X_test = np.array(X_test, dtype=np.float32)
                y_test = np.array(y_test, dtype=np.int32)

                num_samples = len(X_train)
                st.write(f"**S·ªë m·∫´u hu·∫•n luy·ªán**: {num_samples}")

                # T·ª± ƒë·ªông ch·ªçn tham s·ªë t·ªëi ∆∞u
                if "optimal_params" not in st.session_state:
                    st.session_state["optimal_params"] = get_optimal_params(num_samples)
                params = st.session_state.get("training_params", st.session_state["optimal_params"].copy())

                # Th√™m b·∫£ng tham s·ªë t·ªëi ∆∞u (·∫©n ban ƒë·∫ßu, d√πng expander)
                with st.expander("üîß Tham s·ªë t·ªëi ∆∞u ƒë·ªÅ xu·∫•t", expanded=False):
                    optimal_table = pd.DataFrame({
                        "S·ªë m·∫´u": ["‚â§ 1,000", "‚â§ 10,000", "‚â§ 50,000", "> 50,000"],
                        "S·ªë l·ªõp ·∫©n": [1, 2, 2, 3],
                        "K√≠ch th∆∞·ªõc l·ªõp ·∫©n": ["(32,)", "(64, 32)", "(128, 64)", "(128, 64, 32)"],
                        "T·ªëc ƒë·ªô h·ªçc": [0.001, 0.0005, 0.0003, 0.0001],
                        "S·ªë l·∫ßn l·∫∑p": [30, 50, 70, 100],
                        "H√†m k√≠ch ho·∫°t": ["ReLU", "ReLU", "ReLU", "ReLU"],
                        "Tr√¨nh t·ªëi ∆∞u": ["Adam", "Adam", "Adam", "Adam"],
                        "K√≠ch th∆∞·ªõc batch": [32, 64, 128, 256],
                        "Ng∆∞·ª°ng tin c·∫≠y": [0.95, 0.95, 0.95, 0.95],
                        "S·ªë v√≤ng l·∫∑p t·ªëi ƒëa": [5, 10, 15, 20]
                    })
                    st.table(optimal_table)
                    if st.button("S·ª≠ d·ª•ng tham s·ªë ƒë·ªÅ xu·∫•t"):
                        st.session_state["training_params"] = st.session_state["optimal_params"].copy()
                        st.rerun()

                # Hi·ªÉn th·ªã t·ª∑ l·ªá m·∫´u ban ƒë·∫ßu v√† s·ªë l∆∞·ª£ng m·∫´u
                st.subheader("üìä T·ª∑ l·ªá m·∫´u ban ƒë·∫ßu")
                labeled_pct = st.number_input("T·ª∑ l·ªá d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu m·ªói l·ªõp (%)", min_value=0.1, max_value=100.0, value=1.0)
                num_labeled = int(num_samples * (labeled_pct / 100))
                num_unlabeled = num_samples - num_labeled
                st.write(f"**S·ªë m·∫´u c√≥ nh√£n ban ƒë·∫ßu**: {num_labeled}")
                st.write(f"**S·ªë m·∫´u kh√¥ng c√≥ nh√£n**: {num_unlabeled}")

                # C·∫•u h√¨nh m√¥ h√¨nh
                st.subheader("‚öôÔ∏è C·∫•u h√¨nh M√¥ h√¨nh")
                col_param1, col_param2 = st.columns(2)
                with col_param1:
                    num_hidden_layers = st.number_input("S·ªë l·ªõp ·∫©n", min_value=1, value=len(params["hidden_layer_sizes"]))
                    hidden_sizes = []
                    for i in range(num_hidden_layers):
                        default_value = params["hidden_layer_sizes"][i] if i < len(params["hidden_layer_sizes"]) else 32
                        hidden_size = st.number_input(f"S·ªë n∆°-ron l·ªõp ·∫©n {i+1}", min_value=1, value=default_value)
                        hidden_sizes.append(hidden_size)
                    params["hidden_layer_sizes"] = tuple(hidden_sizes)
                    params["activation"] = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "tanh", "softmax"], 
                                                        index=["relu", "tanh", "softmax"].index(params["activation"]))

                with col_param2:
                    params["learning_rate"] = st.number_input("T·ªëc ƒë·ªô h·ªçc", min_value=0.0, step=0.0001, 
                                                              value=params["learning_rate"], format="%.4f")
                    params["epochs"] = st.number_input("S·ªë epoch", min_value=1, value=params["epochs"])
                    params["batch_size"] = st.number_input("K√≠ch th∆∞·ªõc batch", min_value=1, value=params["batch_size"])
                    params["solver"] = st.selectbox("Tr√¨nh t·ªëi ∆∞u", ["adam", "sgd"], 
                                                    index=["adam", "sgd"].index(params["solver"]))

                # C·∫•u h√¨nh Pseudo-Labeling
                st.subheader("üîÑ C·∫•u h√¨nh Pseudo-Labeling")
                threshold = st.number_input("Ng∆∞·ª°ng tin c·∫≠y", min_value=0.0, max_value=1.0, value=params["threshold"])
                max_iterations = st.number_input("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa", min_value=1, value=params["max_iterations"])

                # ƒê·∫∑t t√™n cho m√¥ h√¨nh
                st.subheader("ƒê·∫∑t t√™n cho m√¥ h√¨nh")
                if 'model_name' not in st.session_state:
                    st.session_state['model_name'] = f"Model_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                model_name = st.text_input("Nh·∫≠p t√™n m√¥ h√¨nh:", value=st.session_state['model_name'])
                st.session_state['model_name'] = model_name

                if st.button("B·∫Øt ƒë·∫ßu Hu·∫•n luy·ªán", type="primary"):
                    # Ki·ªÉm tra t√™n m√¥ h√¨nh kh√¥ng tr·ªëng
                    if not model_name.strip():
                        st.error("T√™n m√¥ h√¨nh kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng! Vui l√≤ng nh·∫≠p t√™n m√¥ h√¨nh.")
                    else:
                        with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=model_name.strip()) as run:
                            mlflow.log_params({**params, "labeled_pct": labeled_pct, "threshold": threshold, "max_iterations": max_iterations})
                            run_id = run.info.run_id

                            with st.spinner("ƒêang hu·∫•n luy·ªán v·ªõi Pseudo-Labeling..."):
                                start_time = time.time()
                                progress_bar = st.progress(0)
                                status_text = st.empty()
                                epoch_text = st.empty()
                                loss_text = st.empty()
                                acc_text = st.empty()

                                # T·∫°o t·∫≠p d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu (d·ª±a tr√™n labeled_pct m·ªói l·ªõp)
                                labeled_indices = []
                                for digit in range(10):
                                    digit_indices = np.where(y_train == digit)[0]
                                    if len(digit_indices) > 0:
                                        train_size = min(int(len(digit_indices) * (labeled_pct / 100)), len(digit_indices))
                                        if train_size < 1 and len(digit_indices) > 0:
                                            train_size = 1
                                        if train_size > 0:
                                            labeled_digit, _ = train_test_split(digit_indices, train_size=train_size, random_state=42)
                                            labeled_indices.extend(labeled_digit)
                                labeled_indices = np.array(labeled_indices)
                                unlabeled_indices = np.setdiff1d(np.arange(len(X_train)), labeled_indices)

                                X_labeled = X_train[labeled_indices]
                                y_labeled = y_train[labeled_indices]
                                X_unlabeled = X_train[unlabeled_indices]

                                loss_history = []
                                accuracy_history = []
                                pseudo_samples_history = []  # L∆∞u tr·ªØ m·∫´u Pseudo-Labeling
                                iteration = 0

                                # Callback ƒë·ªÉ c·∫≠p nh·∫≠t th√¥ng tin trong qu√° tr√¨nh hu·∫•n luy·ªán
                                class CustomCallback(tf.keras.callbacks.Callback):
                                    def __init__(self, iteration, max_iterations):
                                        super().__init__()
                                        self.iteration = iteration
                                        self.max_iterations = max_iterations

                                    def on_epoch_end(self, epoch, logs=None):
                                        epoch_text.write(f"Epoch {epoch + 1}/{params['epochs']}")
                                        loss_text.write(f"Loss: {logs['loss']:.4f}")
                                        acc_text.write(f"Accuracy: {logs['accuracy']:.4f}")

                                # Qu√° tr√¨nh hu·∫•n luy·ªán v·ªõi Pseudo-Labeling
                                while iteration < max_iterations and len(unlabeled_indices) > 0:
                                    iteration += 1
                                    status_text.write(f"V√≤ng {iteration}/{max_iterations}")

                                    # Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n t·∫≠p d·ªØ li·ªáu c√≥ nh√£n hi·ªán t·∫°i
                                    model = build_model(params)
                                    history = model.fit(
                                        X_labeled, y_labeled,
                                        epochs=params["epochs"],
                                        batch_size=params["batch_size"],
                                        verbose=0,
                                        callbacks=[CustomCallback(iteration, max_iterations)]
                                    )
                                    loss_history.append(history.history['loss'][-1])
                                    accuracy_history.append(history.history['accuracy'][-1])

                                    # D·ª± ƒëo√°n nh√£n cho t·∫≠p d·ªØ li·ªáu kh√¥ng c√≥ nh√£n
                                    predictions = model.predict(X_unlabeled, verbose=0)
                                    max_probs = np.max(predictions, axis=1)
                                    pseudo_labels = np.argmax(predictions, axis=1)

                                    # L·ªçc c√°c m·∫´u c√≥ ƒë·ªô tin c·∫≠y cao
                                    high_confidence_mask = max_probs >= threshold
                                    if not np.any(high_confidence_mask):
                                        break

                                    # G√°n nh√£n gi·∫£ v√† th√™m v√†o t·∫≠p d·ªØ li·ªáu c√≥ nh√£n
                                    pseudo_indices = unlabeled_indices[high_confidence_mask]
                                    pseudo_y = pseudo_labels[high_confidence_mask]
                                    pseudo_probs = max_probs[high_confidence_mask]
                                    X_pseudo = X_unlabeled[high_confidence_mask]

                                    # L∆∞u tr·ªØ m·ªôt s·ªë m·∫´u Pseudo-Labeling ƒë·ªÉ minh h·ªça (t·ªëi ƒëa 5 m·∫´u m·ªói v√≤ng)
                                    num_samples_to_show = min(5, len(X_pseudo))
                                    pseudo_samples_history.append({
                                        'iteration': iteration,
                                        'X_pseudo': X_pseudo[:num_samples_to_show],
                                        'pseudo_labels': pseudo_y[:num_samples_to_show],
                                        'confidence': pseudo_probs[:num_samples_to_show]
                                    })

                                    X_labeled = np.vstack((X_labeled, X_unlabeled[high_confidence_mask]))
                                    y_labeled = np.hstack((y_labeled, pseudo_y))

                                    # C·∫≠p nh·∫≠t t·∫≠p d·ªØ li·ªáu kh√¥ng c√≥ nh√£n
                                    unlabeled_indices = unlabeled_indices[~high_confidence_mask]
                                    X_unlabeled = X_unlabeled[~high_confidence_mask]

                                    # C·∫≠p nh·∫≠t progress bar
                                    progress = iteration / max_iterations
                                    progress_bar.progress(min(progress, 1.0))

                                # Hu·∫•n luy·ªán l·∫ßn cu·ªëi tr√™n to√†n b·ªô d·ªØ li·ªáu ƒë√£ g·∫Øn nh√£n
                                model = build_model(params)
                                history = model.fit(
                                    X_labeled, y_labeled,
                                    epochs=params["epochs"],
                                    batch_size=params["batch_size"],
                                    verbose=0,
                                    callbacks=[CustomCallback(iteration, max_iterations)]
                                )
                                loss_history.append(history.history['loss'][-1])
                                accuracy_history.append(history.history['accuracy'][-1])

                                # ƒê√°nh gi√° tr√™n t·∫≠p test
                                y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                                acc_test = accuracy_score(y_test, y_test_pred)
                                cm_test = confusion_matrix(y_test, y_test_pred)

                                # L∆∞u k·∫øt qu·∫£ v√†o MLflow
                                mlflow.log_metric("accuracy_test", acc_test)
                                mlflow.log_metric("training_time", time.time() - start_time)
                                mlflow.keras.log_model(model, "model")

                                # L∆∞u k·∫øt qu·∫£ v√†o session_state
                                results = {
                                    'accuracy_test': acc_test,
                                    'cm_test': cm_test,
                                    'loss_history': loss_history,
                                    'accuracy_history': accuracy_history,
                                    'pseudo_samples_history': pseudo_samples_history,
                                    'iterations': iteration,
                                    'training_time': time.time() - start_time,
                                    'run_id': run.info.run_id,
                                    'run_name': model_name.strip(),
                                    'params': params,
                                    'n_iter_actual': iteration
                                }
                                st.session_state['training_results'] = results
                                st.success(f"ƒê√£ hu·∫•n luy·ªán xong sau {iteration} v√≤ng! Th·ªùi gian: {results['training_time']:.2f} gi√¢y")

                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                if 'training_results' in st.session_state:
                    results = st.session_state['training_results']
                    st.subheader("üìä K·∫øt qu·∫£ Hu·∫•n luy·ªán")

                    # Th√¥ng tin c∆° b·∫£n
                    col1, col2 = st.columns(2)
                    col1.metric("Th·ªùi gian hu·∫•n luy·ªán", f"{results['training_time']:.2f} gi√¢y")
                    col2.metric("ƒê·ªô ch√≠nh x√°c Test", f"{results['accuracy_test']*100:.2f}%")

                    # Tham s·ªë hu·∫•n luy·ªán
                    st.subheader("‚öôÔ∏è Tham s·ªë Hu·∫•n luy·ªán")
                    st.json({
                        "S·ªë l·ªõp ·∫©n": len(results['params']['hidden_layer_sizes']),
                        "S·ªë n∆°-ron m·ªói l·ªõp": results['params']['hidden_layer_sizes'],
                        "T·ªëc ƒë·ªô h·ªçc": results['params']['learning_rate'],
                        "S·ªë l·∫ßn l·∫∑p": results['params']['epochs'],
                        "K√≠ch th∆∞·ªõc batch": results['params']['batch_size'],
                        "H√†m k√≠ch ho·∫°t": results['params']['activation'],
                        "Tr√¨nh t·ªëi ∆∞u": results['params']['solver'],
                        "Ng∆∞·ª°ng tin c·∫≠y": threshold,
                        "S·ªë v√≤ng l·∫∑p t·ªëi ƒëa": max_iterations
                    })

                    # Bi·ªÉu ƒë·ªì Loss v√† Accuracy
                    st.subheader("üìà Bi·ªÉu ƒë·ªì Loss v√† Accuracy")
                    col_loss, col_acc = st.columns(2)
                    with col_loss:
                        fig, ax = plt.subplots(figsize=(6, 4))
                        ax.plot(range(1, len(results['loss_history']) + 1), results['loss_history'], 
                                color='blue', label='Loss', linewidth=2)
                        ax.set_title("Loss qua c√°c v√≤ng", fontsize=12)
                        ax.set_xlabel("V√≤ng", fontsize=10)
                        ax.set_ylabel("Loss", fontsize=10)
                        ax.grid(True, linestyle='--', alpha=0.7)
                        ax.legend()
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)
                    with col_acc:
                        fig, ax = plt.subplots(figsize=(6, 4))
                        ax.plot(range(1, len(results['accuracy_history']) + 1), results['accuracy_history'], 
                                color='green', label='Accuracy', linewidth=2)
                        ax.set_title("Accuracy qua c√°c v√≤ng", fontsize=12)
                        ax.set_xlabel("V√≤ng", fontsize=10)
                        ax.set_ylabel("Accuracy", fontsize=10)
                        ax.grid(True, linestyle='--', alpha=0.7)
                        ax.legend()
                        plt.tight_layout()
                        st.pyplot(fig)
                        plt.close(fig)

                    # Ma tr·∫≠n Nh·∫ßm l·∫´n
                    st.subheader("üî¢ Ma tr·∫≠n Nh·∫ßm l·∫´n")
                    fig, ax = plt.subplots(figsize=(8, 6))
                    sns.heatmap(results['cm_test'], annot=True, fmt="d", cmap="Blues", ax=ax)
                    ax.set_title("Ma tr·∫≠n Nh·∫ßm l·∫´n tr√™n t·∫≠p Test", fontsize=14)
                    ax.set_xlabel("D·ª± ƒëo√°n", fontsize=12)
                    ax.set_ylabel("Th·ª±c t·∫ø", fontsize=12)
                    plt.tight_layout()
                    st.pyplot(fig)
                    plt.close(fig)

                    # Minh h·ªça c√°c m·∫´u Pseudo-Labeling
                    st.subheader("üîÑ Minh h·ªça Pseudo-Labeling")
                    if results['pseudo_samples_history']:
                        for pseudo_data in results['pseudo_samples_history']:
                            st.markdown(f"**V√≤ng {pseudo_data['iteration']}**")
                            fig, axes = plt.subplots(1, len(pseudo_data['X_pseudo']), figsize=(len(pseudo_data['X_pseudo']) * 2, 2.5))
                            if len(pseudo_data['X_pseudo']) == 1:
                                axes = [axes]  # ƒê·∫£m b·∫£o axes l√† danh s√°ch ngay c·∫£ khi ch·ªâ c√≥ 1 m·∫´u
                            for i, ax in enumerate(axes):
                                ax.imshow(pseudo_data['X_pseudo'][i].reshape(28, 28), cmap='gray')
                                ax.set_title(f"Label: {pseudo_data['pseudo_labels'][i]}\nConf: {pseudo_data['confidence'][i]:.2f}", fontsize=10)
                                ax.axis("off")
                            plt.tight_layout()
                            st.pyplot(fig)
                            plt.close(fig)
                    else:
                        st.info("Kh√¥ng c√≥ m·∫´u Pseudo-Labeling n√†o ƒë∆∞·ª£c g√°n.")

                    # T√≥m t·∫Øt k·∫øt qu·∫£ hu·∫•n luy·ªán
                    st.subheader("üìã T√≥m t·∫Øt K·∫øt qu·∫£")
                    full_data = {
                        "V√≤ng": list(range(1, len(results['loss_history']) + 1)),
                        "Loss": results['loss_history'],
                        "Accuracy": results['accuracy_history'],
                    }
                    df_full = pd.DataFrame(full_data)
                    st.table(df_full)

                    # Chi ti·∫øt l·∫ßn ch·∫°y
                    with st.expander("Xem chi ti·∫øt l·∫ßn ch·∫°y", expanded=False):
                        st.markdown("**Th√¥ng tin l·∫ßn ch·∫°y:**")
                        st.write(f"- T√™n: {results['run_name']}")
                        st.write(f"- ID: {results['run_id']}")
                        st.write(f"- Th·ªùi gian hu·∫•n luy·ªán: {results['training_time']:.2f} gi√¢y")
                        st.write(f"- S·ªë l·∫ßn l·∫∑p th·ª±c t·∫ø: {results['n_iter_actual']}")

    # Tab 6: Demo d·ª± ƒëo√°n
    with tab_demo:
        demo_container = st.container()
        with demo_container:
            st.markdown('<div class="section-title">Demo D·ª± ƒëo√°n</div>', unsafe_allow_html=True)
            if 'split_data' not in st.session_state:
                st.warning("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc!")
            else:
                if st.button("L√†m m·ªõi danh s√°ch m√¥ h√¨nh"):
                    st.rerun()

                runs = client.search_runs(experiment_ids=[EXPERIMENT_ID], order_by=["attributes.start_time DESC"])
                model_options = {run.info.run_id: run.data.tags.get('mlflow.runName', run.info.run_id) for run in runs}
                if not model_options:
                    st.info("Ch∆∞a c√≥ m√¥ h√¨nh n√†o ƒë∆∞·ª£c hu·∫•n luy·ªán.")
                else:
                    selected_run_id = st.selectbox("Ch·ªçn m√¥ h√¨nh:", list(model_options.keys()), 
                                                   format_func=lambda x: model_options[x])
                    if st.button("S·ª≠ d·ª•ng m√¥ h√¨nh n√†y"):
                        with st.spinner("ƒêang t·∫£i m√¥ h√¨nh..."):
                            model = mlflow.keras.load_model(f"runs:/{selected_run_id}/model")
                            st.session_state['selected_model'] = model
                            st.success("ƒê√£ t·∫£i m√¥ h√¨nh!")

                    if 'selected_model' in st.session_state:
                        model = st.session_state['selected_model']
                        input_method = st.selectbox("Ph∆∞∆°ng th·ª©c nh·∫≠p li·ªáu", ["T·∫£i ·∫£nh l√™n", "D·ªØ li·ªáu Test", "V·∫Ω tr·ª±c ti·∫øp"])

                        if input_method == "T·∫£i ·∫£nh l√™n":
                            uploaded_file = st.file_uploader("T·∫£i l√™n h√¨nh ·∫£nh", type=["png", "jpg"])
                            if uploaded_file:
                                image = Image.open(uploaded_file).convert('L').resize((28, 28))
                                st.image(image, caption="H√¨nh ·∫£nh t·∫£i l√™n", width=100)
                                image_array = np.array(image).reshape(1, 784) / 255.0
                                if st.button("D·ª± ƒëo√°n"):
                                    pred = model.predict(image_array, verbose=0)
                                    st.write(f"D·ª± ƒëo√°n: {np.argmax(pred)} (ƒê·ªô tin c·∫≠y: {np.max(pred)*100:.2f}%)")

                        elif input_method == "D·ªØ li·ªáu Test":
                            X_test = st.session_state['split_data']['X_test']
                            y_test = st.session_state['split_data']['y_test']
                            idx = st.slider("Ch·ªçn m·∫´u", 0, len(X_test)-1, 0)
                            st.image(X_test[idx].reshape(28, 28), caption=f"Nh√£n th·ª±c t·∫ø: {y_test[idx]}", width=100)
                            if st.button("D·ª± ƒëo√°n"):
                                pred = model.predict(X_test[idx:idx+1], verbose=0)
                                st.write(f"D·ª± ƒëo√°n: {np.argmax(pred)} (ƒê·ªô tin c·∫≠y: {np.max(pred)*100:.2f}%)")

                        elif input_method == "V·∫Ω tr·ª±c ti·∫øp":
                            canvas_result = st_canvas(stroke_width=20, stroke_color="#FFFFFF", background_color="#000000", 
                                                      height=280, width=280, drawing_mode="freedraw")
                            if canvas_result.image_data is not None:
                                image = Image.fromarray(canvas_result.image_data).convert('L').resize((28, 28))
                                st.image(image, caption="H√¨nh ·∫£nh v·∫Ω tay", width=100)
                                image_array = np.array(image).reshape(1, 784) / 255.0
                                if st.button("D·ª± ƒëo√°n"):
                                    pred = model.predict(image_array, verbose=0)
                                    st.write(f"D·ª± ƒëo√°n: {np.argmax(pred)} (ƒê·ªô tin c·∫≠y: {np.max(pred)*100:.2f}%)")

    # Tab 7: Th√¥ng tin hu·∫•n luy·ªán
    with tab_log_info:
        log_info_container = st.container()
        with log_info_container:
            st.markdown('<div class="section-title">Theo d√µi K·∫øt qu·∫£</div>', unsafe_allow_html=True)
            try:
                with st.spinner("ƒêang t·∫£i th√¥ng tin hu·∫•n luy·ªán..."):
                    client = MlflowClient()
                    runs = client.search_runs(experiment_ids=[EXPERIMENT_ID], order_by=["attributes.start_time DESC"])
                    if not runs:
                        st.info(f"Ch∆∞a c√≥ l·∫ßn ch·∫°y n√†o trong Experiment ID {EXPERIMENT_ID}.")
                    else:
                        run_options = {run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") for run in runs}
                        selected_run_name = st.selectbox("Ch·ªçn run:", list(run_options.values()))
                        selected_run_id = [k for k, v in run_options.items() if v == selected_run_name][0]
                        selected_run = client.get_run(selected_run_id)

                        st.subheader("ƒê·ªïi t√™n Run")
                        new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", value=selected_run_name)
                        if st.button("C·∫≠p nh·∫≠t t√™n"):
                            client.set_tag(selected_run_id, "mlflow.runName", new_run_name.strip())
                            st.success(f"ƒê√£ ƒë·ªïi t√™n th√†nh: {new_run_name.strip()}")
                            st.rerun()

                        st.subheader("X√≥a Run")
                        if st.button("X√≥a l·∫ßn ch·∫°y"):
                            client.delete_run(selected_run_id)
                            st.success(f"ƒê√£ x√≥a: {selected_run_name}")
                            st.rerun()

                        st.subheader("Th√¥ng tin chi ti·∫øt")
                        st.write(f"**T√™n:** {selected_run_name}")
                        st.write(f"**ID:** {selected_run_id}")
                        st.write(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** {datetime.fromtimestamp(selected_run.info.start_time / 1000)}")
                        
                        st.markdown("**Tham s·ªë hu·∫•n luy·ªán:**")
                        st.json(selected_run.data.params, expanded=True)
                        
                        st.markdown("**S·ªë li·ªáu hu·∫•n luy·ªán:**")
                        st.json(selected_run.data.metrics, expanded=True)

                        st.subheader("üìà L·ªãch s·ª≠ Hu·∫•n luy·ªán")
                        col_loss, col_acc = st.columns(2)
                        with col_loss:
                            if 'training_results' in st.session_state and selected_run_id == st.session_state['training_results']['run_id']:
                                results = st.session_state['training_results']
                                if 'loss_history' in results:
                                    fig, ax = plt.subplots(figsize=(6, 4))
                                    ax.plot(range(1, len(results['loss_history']) + 1), results['loss_history'], 
                                            label='Training Loss', color='blue', linewidth=2)
                                    ax.set_xlabel("V√≤ng", fontsize=10)
                                    ax.set_ylabel("Loss", fontsize=10)
                                    ax.set_title("L·ªãch s·ª≠ M·∫•t m√°t", fontsize=12)
                                    ax.legend()
                                    ax.grid(True, linestyle='--', alpha=0.7)
                                    plt.tight_layout()
                                    st.pyplot(fig)
                                    plt.close(fig)
                        with col_acc:
                            if 'training_results' in st.session_state and selected_run_id == st.session_state['training_results']['run_id']:
                                results = st.session_state['training_results']
                                if 'accuracy_history' in results:
                                    fig, ax = plt.subplots(figsize=(6, 4))
                                    ax.plot(range(1, len(results['accuracy_history']) + 1), results['accuracy_history'], 
                                            label='Training Accuracy', color='green', linewidth=2)
                                    ax.set_xlabel("V√≤ng", fontsize=10)
                                    ax.set_ylabel("Accuracy", fontsize=10)
                                    ax.set_title("L·ªãch s·ª≠ ƒê·ªô ch√≠nh x√°c", fontsize=12)
                                    ax.legend()
                                    ax.grid(True, linestyle='--', alpha=0.7)
                                    plt.tight_layout()
                                    st.pyplot(fig)
                                    plt.close(fig)

                        st.subheader("So s√°nh c√°c Run")
                        selected_runs = st.multiselect("Ch·ªçn c√°c run ƒë·ªÉ so s√°nh:", list(run_options.values()), default=[selected_run_name])
                        if selected_runs:
                            selected_run_ids = [k for k, v in run_options.items() if v in selected_runs]
                            comparison_data = []
                            for run_id in selected_run_ids:
                                run = client.get_run(run_id)
                                run_data = {
                                    "T√™n": run.data.tags.get('mlflow.runName', run_id),
                                    "Accuracy Test": run.data.metrics.get('accuracy_test', 'N/A'),
                                    "Th·ªùi gian": run.data.metrics.get('training_time', 'N/A'),
                                    "S·ªë l·ªõp ·∫©n": run.data.params.get('hidden_layer_sizes', 'N/A'),
                                    "Learning Rate": run.data.params.get('learning_rate', 'N/A'),
                                    "Epochs": run.data.params.get('epochs', 'N/A')
                                }
                                comparison_data.append(run_data)
                            st.table(pd.DataFrame(comparison_data))

            except Exception as e:
                st.error(f"L·ªói khi t·∫£i th√¥ng tin hu·∫•n luy·ªán: {e}. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi MLflow ho·∫∑c th√¥ng tin Experiment ID.")
            mlflow_ui_link = f"{mlflow_tracking_uri}/#/experiments/{EXPERIMENT_ID}"
            st.markdown("---")
            st.markdown(f"üìä **Xem chi ti·∫øt tr√™n MLflow UI**: [Nh·∫•n v√†o ƒë√¢y]({mlflow_ui_link})", unsafe_allow_html=True)

if __name__ == "__main__":
    run_mnist_pseudo_labeling_app()