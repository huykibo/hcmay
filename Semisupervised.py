import os
import mlflow
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from datetime import datetime
import time
import requests
import io
import sys
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
import gc

# H√†m ch·ªçn tham s·ªë t·ªëi ∆∞u d·ª±a tr√™n s·ªë m·∫´u
def get_optimal_params(num_samples):
    if num_samples <= 1000:
        return {
            "hidden_layer_sizes": (32,),
            "learning_rate": 0.001,
            "epochs": 30,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 32
        }
    elif num_samples <= 10000:
        return {
            "hidden_layer_sizes": (64, 32),
            "learning_rate": 0.0005,
            "epochs": 50,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 64
        }
    elif num_samples <= 50000:
        return {
            "hidden_layer_sizes": (128, 64),
            "learning_rate": 0.0003,
            "epochs": 70,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 128
        }
    else:  # > 50,000
        return {
            "hidden_layer_sizes": (128, 64, 32),
            "learning_rate": 0.0001,
            "epochs": 100,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 256
        }

def run_mnist_labelding_neural_network_app():
    # Thi·∫øt l·∫≠p MLflow
    mlflow_tracking_uri = "https://dagshub.com/huykibo/streamlit_mlflow.mlflow"
    try:
        os.environ["MLFLOW_TRACKING_USERNAME"] = st.secrets["mlflow"]["MLFLOW_TRACKING_USERNAME"]
        os.environ["MLFLOW_TRACKING_PASSWORD"] = st.secrets["mlflow"]["MLFLOW_TRACKING_PASSWORD"]
        mlflow.set_tracking_uri(mlflow_tracking_uri)
    except KeyError as e:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y kh√≥a {e} trong st.secrets.")
        st.stop()

    try:
        response = requests.get(mlflow_tracking_uri, timeout=5)
        if response.status_code != 200:
            st.error(f"K·∫øt n·ªëi MLflow th·∫•t b·∫°i. M√£ tr·∫°ng th√°i: {response.status_code}.")
            st.stop()
    except requests.exceptions.RequestException as e:
        st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi MLflow: {e}.")
        st.stop()

    EXPERIMENT_ID = "5"
    try:
        client = MlflowClient()
        experiment = client.get_experiment(EXPERIMENT_ID)
        if experiment is None:
            st.error(f"Experiment ID {EXPERIMENT_ID} kh√¥ng t·ªìn t·∫°i.")
            st.stop()
    except Exception as e:
        st.error(f"L·ªói truy xu·∫•t Experiment ID {EXPERIMENT_ID}: {e}.")
        st.stop()

    st.title("Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Neural Network")

    # CSS t√πy ch·ªânh
    st.markdown("""
        <style>
            .tooltip {
                position: relative;
                display: inline-block;
                cursor: pointer;
                color: #1f77b4;
                font-weight: bold;
                margin-left: 5px;
            }
            .tooltip .tooltiptext {
                visibility: hidden;
                width: 400px;
                background-color: #f9f9f9;
                color: #333;
                text-align: left;
                border-radius: 6px;
                padding: 10px;
                position: absolute;
                z-index: 1;
                right: 105%;
                top: 50%;
                transform: translateY(-50%);
                opacity: 0;
                transition: opacity 0.3s;
                border: 1px solid #ccc;
                font-size: 0.9em;
                line-height: 1.4;
            }
            .tooltip:hover .tooltiptext {
                visibility: visible;
                opacity: 1;
            }
            .section-title {
                font-size: 1.5em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 10px;
            }
            .info-box {
                background-color: #f8f9fa;
                padding: 10px;
                border-left: 4px solid #3498db;
                margin-bottom: 15px;
            }
            .action-container {
                background-color: #ffffff;
                padding: 15px;
                border-radius: 5px;
                box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
                margin-bottom: 20px;
            }
            .prediction-box {
                margin-top: 10px;
                padding: 10px;
                border: 1px solid #ccc;
                border-radius: 5px;
                background-color: #f9f9f9;
            }
            .mode-title {
                font-size: 1.2em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 10px;
            }
            .stCanvas {
                border: 1px solid #ddd;
                border-radius: 5px;
            }
        </style>
    """, unsafe_allow_html=True)

    tabs = st.tabs(["Th√¥ng tin", "T·∫£i d·ªØ li·ªáu", "X·ª≠ l√Ω d·ªØ li·ªáu", "Chia d·ªØ li·ªáu", "Hu·∫•n luy·ªán/ƒê√°nh gi√°", "Demo d·ª± ƒëo√°n", "Th√¥ng tin hu·∫•n luy·ªán"])
    tab_info, tab_load, tab_preprocess, tab_split, tab_train_eval, tab_demo, tab_log_info = tabs

    # Tab 1: Th√¥ng tin
    with tab_info:
        st.header("Gi·ªõi thi·ªáu v·ªÅ ·ª®ng d·ª•ng v√† M·∫°ng Neural Network")
        st.markdown("""
        Ch√†o b·∫°n! ƒê√¢y l√† ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay t·ª´ t·∫≠p d·ªØ li·ªáu **MNIST** b·∫±ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**. H√£y kh√°m ph√° c√°c t√≠nh nƒÉng v√† c√°ch ho·∫°t ƒë·ªông c·ªßa n√≥ nh√©!
        """, unsafe_allow_html=True)

        st.subheader("Ch·ªçn th√¥ng tin ƒë·ªÉ xem")
        info_option = st.selectbox(
            "",
            [
                "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?",
                "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a",
                "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o",
                "Pseudo Labeling ‚Äì G√°n nh√£n gi·∫£",
                "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)"
            ],
            label_visibility="collapsed",
            help="Ch·ªçn ƒë·ªÉ xem chi ti·∫øt v·ªÅ ·ª©ng d·ª•ng, d·ªØ li·ªáu, ho·∫∑c m√¥ h√¨nh."
        )

        if info_option == "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìò 1. ·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?")
                st.markdown("""
                ƒê√¢y l√† m·ªôt ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu **MNIST**, s·ª≠ d·ª•ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**.  
                - **MNIST**: T·∫≠p d·ªØ li·ªáu g·ªìm $70,000$ ·∫£nh ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$, m·ªói ·∫£nh k√≠ch th∆∞·ªõc $28 \\times 28$ pixel (t·ªïng c·ªông $784$ ƒë·∫∑c tr∆∞ng).  
                - **M·ª•c ti√™u**:  
                  - X√¢y d·ª±ng v√† hu·∫•n luy·ªán m·ªôt m·∫°ng n∆°-ron ƒë·ªÉ nh·∫≠n di·ªán ch√≠nh x√°c c√°c ch·ªØ s·ªë.  
                  - Cung c·∫•p c√¥ng c·ª• tr·ª±c quan ƒë·ªÉ h·ªçc t·∫≠p v√† ƒë√°nh gi√° hi·ªáu qu·∫£ c·ªßa thu·∫≠t to√°n.  

                **Th√¥ng tin c∆° b·∫£n**:  
                - **$784$ ƒë·∫∑c tr∆∞ng**: M·ªói ·∫£nh ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng vector $784$ chi·ªÅu (gi√° tr·ªã pixel t·ª´ $0$ ƒë·∫øn $255$).  
                - **$70,000$ m·∫´u**: T·ªïng s·ªë ·∫£nh, ƒë∆∞·ª£c chia th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra.  
                - **Nhi·ªám v·ª•**: D·ª± ƒëo√°n nh√£n ($0$-$9$) d·ª±a tr√™n ƒë·∫∑c tr∆∞ng pixel.  
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìò 2. T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a")
                st.markdown("""
                **MNIST** l√† t·∫≠p d·ªØ li·ªáu chu·∫©n trong h·ªçc m√°y, ƒë∆∞·ª£c t·∫°o b·ªüi Yann LeCun v√† c√°c c·ªông s·ª±.  
                - **ƒê·∫∑c ƒëi·ªÉm**:  
                  - G·ªìm c√°c ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ h·ªçc sinh trung h·ªçc v√† nh√¢n vi√™n ƒëi·ªÅu tra d√¢n s·ªë M·ªπ.  
                  - Chu·∫©n h√≥a th√†nh k√≠ch th∆∞·ªõc $28 \\times 28$ pixel, thang ƒë·ªô x√°m (gi√° tr·ªã t·ª´ $0$ ƒë·∫øn $255$).  

                **√ù nghƒ©a**:  
                - L√† b√†i to√°n c∆° b·∫£n ƒë·ªÉ ki·ªÉm tra kh·∫£ nƒÉng ph√¢n lo·∫°i c·ªßa c√°c m√¥ h√¨nh h·ªçc m√°y.  
                - ƒê∆°n gi·∫£n nh∆∞ng ƒë·ªß ph·ª©c t·∫°p ƒë·ªÉ ƒë√°nh gi√° kh·∫£ nƒÉng ph√¢n bi·ªát c√°c l·ªõp t∆∞∆°ng t·ª± (v√≠ d·ª•: "$4$" v√† "$9$").  
                - Ph√π h·ª£p cho c·∫£ ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu v√† nghi√™n c·ª©u m√¥ h√¨nh ph·ª©c t·∫°p.  
                """, unsafe_allow_html=True)

                st.subheader("üì∑ Minh h·ªça d·ªØ li·ªáu MNIST")
                st.markdown("""
                D∆∞·ªõi ƒë√¢y l√† ·∫£nh minh h·ªça $10$ ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$ t·ª´ t·∫≠p d·ªØ li·ªáu MNIST ƒë·ªÉ b·∫°n h√¨nh dung. M·ªói ch·ªØ s·ªë ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ma tr·∫≠n $28 \\times 28$ pixel.
                """, unsafe_allow_html=True)
                try:
                    mnist_image = Image.open("mnist.png")
                    st.image(mnist_image, caption="·∫¢nh minh h·ªça $10$ ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$ trong MNIST", width=800)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y file `mnist.png`. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìä 3. Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o")
                st.markdown("""
                **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o)** l√† m·ªôt m√¥ h√¨nh h·ªçc m√°y m√¥ ph·ªèng c√°ch ho·∫°t ƒë·ªông c·ªßa m·∫°ng n∆°-ron sinh h·ªçc trong n√£o ng∆∞·ªùi. N√≥ ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu, ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ v·ªõi b√†i to√°n nh·∫≠n di·ªán h√¨nh ·∫£nh nh∆∞ MNIST.
                """, unsafe_allow_html=True)

                st.subheader("üåê C·∫•u tr√∫c c∆° b·∫£n c·ªßa Neural Network")
                st.markdown("""
                - **L·ªõp ƒë·∫ßu v√†o (Input Layer)**: Nh·∫≠n d·ªØ li·ªáu th√¥ (v√≠ d·ª•: $784$ pixel t·ª´ ·∫£nh MNIST $28 \\times 28$).  
                - **L·ªõp ·∫©n (Hidden Layers)**: X·ª≠ l√Ω th√¥ng tin th√¥ng qua c√°c ph√©p t√≠nh tuy·∫øn t√≠nh v√† phi tuy·∫øn (s·ª≠ d·ª•ng h√†m k√≠ch ho·∫°t).  
                - **L·ªõp ƒë·∫ßu ra (Output Layer)**: ƒê∆∞a ra d·ª± ƒëo√°n (10 l·ªõp, t∆∞∆°ng ·ª©ng v·ªõi c√°c ch·ªØ s·ªë $0$-$9$).  
                """, unsafe_allow_html=True)

                st.subheader("üîß Quy tr√¨nh ho·∫°t ƒë·ªông")
                st.markdown("""
                Neural Network ho·∫°t ƒë·ªông qua c√°c b∆∞·ªõc sau, ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a d·ª±a tr√™n c√°c tham s·ªë b·∫°n c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh trong tab **Hu·∫•n luy·ªán/ƒê√°nh gi√°**:
                """, unsafe_allow_html=True)

                st.subheader("1. Kh·ªüi t·∫°o m√¥ h√¨nh")
                st.markdown("""
                - X√°c ƒë·ªãnh c·∫•u tr√∫c m·∫°ng (s·ªë l·ªõp ·∫©n, s·ªë n∆°-ron m·ªói l·ªõp) v√† kh·ªüi t·∫°o **tr·ªçng s·ªë** ($W$) v√† **bias** ($b$) ng·∫´u nhi√™n (th∆∞·ªùng t·ª´ ph√¢n ph·ªëi Gaussian).  
                - **Tham s·ªë li√™n quan**:  
                  - **S·ªë l·ªõp ·∫©n**: ƒê∆∞·ª£c ch·ªçn t·ª´ $1$ ƒë·∫øn $2$ trong giao di·ªán hu·∫•n luy·ªán.  
                  - **S·ªë n∆°-ron m·ªói l·ªõp**: C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh t·ª´ $16$ ƒë·∫øn $128$.  
                - M·ª•c ƒë√≠ch: Thi·∫øt l·∫≠p c·∫•u tr√∫c ban ƒë·∫ßu ƒë·ªÉ b·∫Øt ƒë·∫ßu qu√° tr√¨nh h·ªçc.
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step1_init.png"), caption="Minh h·ªça: Kh·ªüi t·∫°o m√¥ h√¨nh", width=600)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 1.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("2. Lan truy·ªÅn thu·∫≠n (Feedforward)")
                st.markdown("""
                - T√≠nh to√°n ƒë·∫ßu ra d·ª± ƒëo√°n ($\\hat{Y}$) t·ª´ ƒë·∫ßu v√†o $X$ qua c√°c l·ªõp:  
                  $$ Z^{(l)} = A^{(l-1)} \\cdot W^{(l)} + b^{(l)} $$  
                  $$ A^{(l)} = \\sigma(Z^{(l)}) $$  
                - **Gi·∫£i th√≠ch**:  
                  - $X$: Ma tr·∫≠n ƒë·∫ßu v√†o, k√≠ch th∆∞·ªõc $N \\times 784$ ($N$ l√† s·ªë m·∫´u).  
                  - $A^{(l-1)}$: ƒê·∫ßu ra c·ªßa l·ªõp tr∆∞·ªõc, v·ªõi $A^{(0)} = X$.  
                  - $W^{(l)}$: Ma tr·∫≠n tr·ªçng s·ªë c·ªßa l·ªõp $l$, k√≠ch th∆∞·ªõc ph·ª• thu·ªôc s·ªë n∆°-ron c·ªßa l·ªõp $l-1$ v√† $l$.  
                  - $b^{(l)}$: Vector bias c·ªßa l·ªõp $l$.  
                  - $Z^{(l)}$: T·ªïng tr·ªçng s·ªë tuy·∫øn t√≠nh c·ªßa l·ªõp $l$.  
                  - $\\sigma$: H√†m k√≠ch ho·∫°t (v√≠ d·ª•: ReLU, Sigmoid, Tanh).  
                  - $\\hat{Y}$: ƒê·∫ßu ra cu·ªëi c√πng, k√≠ch th∆∞·ªõc $N \\times 10$ (10 l·ªõp).  
                - **V√≠ d·ª• v·ªõi Sigmoid**:  
                  $$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$  
                - M·ª•c ƒë√≠ch: T·∫°o d·ª± ƒëo√°n ban ƒë·∫ßu t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o qua c√°c l·ªõp n∆°-ron.
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step2_feedforward.png"), caption="Minh h·ªça: Lan truy·ªÅn thu·∫≠n", width=600)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 2.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("3. T√≠nh h√†m m·∫•t m√°t (Loss Function)")
                st.markdown("""
                - ƒêo ƒë·ªô sai l·ªách gi·ªØa d·ª± ƒëo√°n ($\\hat{Y}$) v√† nh√£n th·ª±c ($Y$) b·∫±ng **Cross-Entropy**:  
                  $$ L = -\\frac{1}{N} \\sum_{i=1}^{N} \\sum_{j=0}^{9} y_{ij} \\cdot \\log(\\hat{y}_{ij}) $$  
                - **Gi·∫£i th√≠ch**:  
                  - $N$: S·ªë m·∫´u trong t·∫≠p d·ªØ li·ªáu.  
                  - $y_{ij}$: Nh√£n th·ª±c t·∫ø (one-hot encoded), $1$ n·∫øu m·∫´u $i$ thu·ªôc l·ªõp $j$, $0$ n·∫øu kh√¥ng.  
                  - $\\hat{y}_{ij}$: X√°c su·∫•t d·ª± ƒëo√°n m·∫´u $i$ thu·ªôc l·ªõp $j$.  
                  - $\\sum_{i=1}^{N}$: T·ªïng tr√™n t·∫•t c·∫£ m·∫´u.  
                  - $\\sum_{j=0}^{9}$: T·ªïng tr√™n t·∫•t c·∫£ l·ªõp (0 ƒë·∫øn 9).  
                - M·ª•c ƒë√≠ch: ƒê·ªãnh l∆∞·ª£ng sai l·ªách ƒë·ªÉ ƒëi·ªÅu ch·ªânh m√¥ h√¨nh trong b∆∞·ªõc ti·∫øp theo.
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step3_loss.png"), caption="Minh h·ªça: T√≠nh h√†m m·∫•t m√°t", width=600)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 3.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("4. Lan truy·ªÅn ng∆∞·ª£c (Backpropagation)")
                st.markdown("""
                - T√≠nh ƒë·∫°o h√†m c·ªßa $L$ ƒë·ªÉ c·∫≠p nh·∫≠t $W^{(l)}$ v√† $b^{(l)}$:  
                  - L·ªõp ƒë·∫ßu ra:  
                    $$ \\delta^{(L)} = \\hat{Y} - Y $$  
                  - L·ªõp ·∫©n:  
                    $$ \\delta^{(l)} = (\\delta^{(l+1)} \\cdot (W^{(l+1)})^T) \\odot \\sigma'(Z^{(l)}) $$  
                  - ƒê·∫°o h√†m:  
                    $$ \\frac{\\partial L}{\\partial W^{(l)}} = (A^{(l-1)})^T \\cdot \\delta^{(l)} $$  
                    $$ \\frac{\\partial L}{\\partial b^{(l)}} = \\sum_{i=1}^{N} \\delta^{(l)}_i $$  
                - **Gi·∫£i th√≠ch**:  
                  - $\\delta^{(L)}$: Sai s·ªë t·∫°i l·ªõp ƒë·∫ßu ra.  
                  - $\\delta^{(l)}$: Sai s·ªë t·∫°i l·ªõp $l$, lan truy·ªÅn ng∆∞·ª£c t·ª´ l·ªõp sau.  
                  - $(W^{(l+1)})^T$: Ma tr·∫≠n chuy·ªÉn v·ªã c·ªßa tr·ªçng s·ªë l·ªõp ti·∫øp theo.  
                  - $\\odot$: Nh√¢n t·ª´ng ph·∫ßn t·ª≠ (Hadamard product).  
                  - $\\sigma'(Z^{(l)})$: ƒê·∫°o h√†m c·ªßa h√†m k√≠ch ho·∫°t t·∫°i $Z^{(l)}$ (v√≠ d·ª•: Sigmoid: $\\sigma'(z) = \\sigma(z) \\cdot (1 - \\sigma(z))$).  
                  - $\\frac{\\partial L}{\\partial W^{(l)}}$: Gradient c·ªßa m·∫•t m√°t theo tr·ªçng s·ªë.  
                  - $\\frac{\\partial L}{\\partial b^{(l)}}$: Gradient c·ªßa m·∫•t m√°t theo bias.  
                - M·ª•c ƒë√≠ch: X√°c ƒë·ªãnh h∆∞·ªõng ƒëi·ªÅu ch·ªânh tham s·ªë d·ª±a tr√™n sai s·ªë.
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step4_backprop.png"), caption="Minh h·ªça: Lan truy·ªÅn ng∆∞·ª£c", width=600)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 4.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("5. C·∫≠p nh·∫≠t tham s·ªë (Gradient Descent)")
                st.markdown("""
                - ƒêi·ªÅu ch·ªânh $W^{(l)}$ v√† $b^{(l)}$ ƒë·ªÉ gi·∫£m m·∫•t m√°t:  
                  $$ W^{(l)} = W^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial W^{(l)}} $$  
                  $$ b^{(l)} = b^{(l)} - \\eta \\cdot \\frac{\\partial L}{\\partial b^{(l)}} $$  
                - **Gi·∫£i th√≠ch**:  
                  - $\\eta$: T·ªëc ƒë·ªô h·ªçc (learning rate), ƒëi·ªÅu ch·ªânh k√≠ch th∆∞·ªõc b∆∞·ªõc c·∫≠p nh·∫≠t.  
                  - $\\frac{\\partial L}{\\partial W^{(l)}}$: Gradient c·ªßa m·∫•t m√°t theo tr·ªçng s·ªë.  
                  - $\\frac{\\partial L}{\\partial b^{(l)}}$: Gradient c·ªßa m·∫•t m√°t theo bias.  
                - M·ª•c ƒë√≠ch: T·ªëi ∆∞u h√≥a tham s·ªë ƒë·ªÉ gi·∫£m sai s·ªë d·ª± ƒëo√°n.
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step5_gradient.png"), caption="Minh h·ªça: C·∫≠p nh·∫≠t tham s·ªë", width=600)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 5.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("6. L·∫∑p l·∫°i")
                st.markdown("""
                - L·∫∑p l·∫°i t·ª´ b∆∞·ªõc 2 qua nhi·ªÅu **epoch** (s·ªë l·∫ßn l·∫∑p t·ªëi ƒëa, t·ª´ $10$ ƒë·∫øn $100$) cho ƒë·∫øn khi m·∫•t m√°t $L$ h·ªôi t·ª•.  
                - M·ª•c ƒë√≠ch: Tinh ch·ªânh m√¥ h√¨nh qua nhi·ªÅu v√≤ng l·∫∑p ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t t·ªëi ∆∞u.
                """, unsafe_allow_html=True)
                try:
                    st.image(os.path.join("plnw", "step6_repeat_improved.png"), caption="Minh h·ªça: L·∫∑p l·∫°i", width=600)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça cho B∆∞·ªõc 6.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "Pseudo Labeling ‚Äì G√°n nh√£n gi·∫£":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìò 4. Pseudo Labeling ‚Äì G√°n Nh√£n Gi·∫£")

                st.markdown("""
                **Pseudo Labeling** (G√°n nh√£n gi·∫£) l√† m·ªôt k·ªπ thu·∫≠t trong h·ªçc b√°n gi√°m s√°t (semi-supervised learning), gi√∫p t·∫≠n d·ª•ng d·ªØ li·ªáu ch∆∞a c√≥ nh√£n ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t c·ªßa m√¥ h√¨nh Neural Network. ƒê√¢y l√† m·ªôt ph∆∞∆°ng ph√°p hi·ªáu qu·∫£ khi s·ªë l∆∞·ª£ng d·ªØ li·ªáu c√≥ nh√£n h·∫°n ch·∫ø, nh∆∞ trong b√†i to√°n MNIST v·ªõi 70,000 m·∫´u, trong ƒë√≥ ch·ªâ m·ªôt ph·∫ßn nh·ªè c√≥ th·ªÉ ƒë∆∞·ª£c g√°n nh√£n th·ªß c√¥ng.
                """, unsafe_allow_html=True)

                st.subheader("üåê C√°ch Ho·∫°t ƒë·ªông c·ªßa Pseudo Labeling")
                st.markdown("""
                Pseudo Labeling ho·∫°t ƒë·ªông theo m·ªôt quy tr√¨nh tu·∫ßn ho√†n, t·∫≠n d·ª•ng c·∫£ d·ªØ li·ªáu c√≥ nh√£n v√† ch∆∞a c√≥ nh√£n ƒë·ªÉ c·∫£i thi·ªán m√¥ h√¨nh qua c√°c b∆∞·ªõc l·∫∑p. D∆∞·ªõi ƒë√¢y l√† quy tr√¨nh chi ti·∫øt, ƒë∆∞·ª£c minh h·ªça r√µ r√†ng trong h√¨nh ·∫£nh:

                1. **Hu·∫•n luy·ªán Ban ƒê·∫ßu (B∆∞·ªõc 1)**  
                   S·ª≠ d·ª•ng m·ªôt t·∫≠p d·ªØ li·ªáu c√≥ nh√£n nh·ªè (v√≠ d·ª•: 1% m·∫´u t·ª´ m·ªói l·ªõp trong t·∫≠p hu·∫•n luy·ªán MNIST) ƒë·ªÉ hu·∫•n luy·ªán m·ªôt m·∫°ng n∆°-ron ban ƒë·∫ßu.  
                   - **M·ª•c ti√™u**: T·∫°o m·ªôt m√¥ h√¨nh c∆° b·∫£n c√≥ kh·∫£ nƒÉng d·ª± ƒëo√°n s∆° b·ªô.  
                   - **Trong h√¨nh ·∫£nh**: B∆∞·ªõc 1 ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng vi·ªác s·ª≠ d·ª•ng d·ªØ li·ªáu c√≥ nh√£n (c√°c ƒëi·ªÉm m√†u xanh d∆∞∆°ng) ƒë·ªÉ hu·∫•n luy·ªán m·ªôt **Initial Neural Network**.

                2. **D·ª± ƒêo√°n Nh√£n Gi·∫£ (B∆∞·ªõc 2)**  
                   S·ª≠ d·ª•ng m·∫°ng n∆°-ron ƒë√£ hu·∫•n luy·ªán ·ªü b∆∞·ªõc 1 ƒë·ªÉ d·ª± ƒëo√°n nh√£n cho d·ªØ li·ªáu ch∆∞a c√≥ nh√£n (unlabeled data). C√°c nh√£n d·ª± ƒëo√°n n√†y ƒë∆∞·ª£c g·ªçi l√† **pseudo-labels** (nh√£n gi·∫£).  
                   - **Chi ti·∫øt**:  
                     - D·ªØ li·ªáu ch∆∞a c√≥ nh√£n (c√°c ƒëi·ªÉm m√†u x√°m) ƒë∆∞·ª£c ƒë∆∞a v√†o m·∫°ng n∆°-ron ban ƒë·∫ßu.  
                     - M√¥ h√¨nh d·ª± ƒëo√°n nh√£n cho c√°c ƒëi·ªÉm d·ªØ li·ªáu n√†y, t·∫°o ra t·∫≠p nh√£n gi·∫£.  
                   - **Trong h√¨nh ·∫£nh**: B∆∞·ªõc 2 th·ªÉ hi·ªán d·ªØ li·ªáu ch∆∞a c√≥ nh√£n (c√°c ƒëi·ªÉm m√†u x√°m) ƒë∆∞·ª£c ƒë∆∞a v√†o **Initial Neural Network** ƒë·ªÉ d·ª± ƒëo√°n nh√£n gi·∫£ (pseudo-labels).

                3. **Hu·∫•n Luy·ªán L·∫°i v·ªõi Nh√£n Gi·∫£ (B∆∞·ªõc 3)**  
                   K·∫øt h·ª£p d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu (c√°c ƒëi·ªÉm m√†u xanh d∆∞∆°ng) v·ªõi d·ªØ li·ªáu v·ª´a ƒë∆∞·ª£c g√°n nh√£n gi·∫£ (c√°c ƒëi·ªÉm m√†u cam) ƒë·ªÉ hu·∫•n luy·ªán l·∫°i m·ªôt m·∫°ng n∆°-ron m·ªõi.  
                   - **L∆∞u √Ω**:  
                     - Ch·ªâ c√°c nh√£n gi·∫£ c√≥ ƒë·ªô tin c·∫≠y cao (v√≠ d·ª•: x√°c su·∫•t d·ª± ƒëo√°n > 0.95) th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ tr√°nh lan truy·ªÅn sai s√≥t.  
                     - Qu√° tr√¨nh n√†y gi√∫p m·ªü r·ªông t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán, c·∫£i thi·ªán kh·∫£ nƒÉng t·ªïng qu√°t h√≥a c·ªßa m√¥ h√¨nh.  
                   - **Trong h√¨nh ·∫£nh**: B∆∞·ªõc 3 ƒë∆∞·ª£c minh h·ªça b·∫±ng vi·ªác s·ª≠ d·ª•ng c·∫£ d·ªØ li·ªáu c√≥ nh√£n (xanh d∆∞∆°ng) v√† d·ªØ li·ªáu v·ªõi nh√£n gi·∫£ (cam) ƒë·ªÉ hu·∫•n luy·ªán m·ªôt **New Neural Network after round of pseudo-labeling**.

                4. **L·∫∑p L·∫°i (T√πy Ch·ªçn)**  
                   L·∫∑p l·∫°i c√°c b∆∞·ªõc 2 v√† 3 qua nhi·ªÅu v√≤ng ƒë·ªÉ ti·∫øp t·ª•c g√°n nh√£n gi·∫£ cho d·ªØ li·ªáu ch∆∞a nh√£n c√≤n l·∫°i, ho·∫∑c cho ƒë·∫øn khi ƒë·∫°t s·ªë v√≤ng l·∫∑p t·ªëi ƒëa (trong ·ª©ng d·ª•ng n√†y, tham s·ªë `max_iterations` ƒë∆∞·ª£c thi·∫øt l·∫≠p m·∫∑c ƒë·ªãnh l√† 5).  
                   - **M·ª•c ti√™u**: TƒÉng c∆∞·ªùng hi·ªáu su·∫•t m√¥ h√¨nh b·∫±ng c√°ch t·∫≠n d·ª•ng t·ªëi ƒëa d·ªØ li·ªáu ch∆∞a c√≥ nh√£n.

                **Minh h·ªça tr·ª±c quan**:  
                H√¨nh ·∫£nh d∆∞·ªõi ƒë√¢y t√≥m t·∫Øt quy tr√¨nh Pseudo Labeling m·ªôt c√°ch tr·ª±c quan:  
                - **B∆∞·ªõc 1**: D·ªØ li·ªáu c√≥ nh√£n (xanh d∆∞∆°ng) ƒë∆∞·ª£c d√πng ƒë·ªÉ hu·∫•n luy·ªán m·∫°ng ban ƒë·∫ßu.  
                - **B∆∞·ªõc 2**: M·∫°ng ban ƒë·∫ßu d·ª± ƒëo√°n nh√£n gi·∫£ cho d·ªØ li·ªáu ch∆∞a c√≥ nh√£n (x√°m).  
                - **B∆∞·ªõc 3**: D·ªØ li·ªáu c√≥ nh√£n v√† nh√£n gi·∫£ (cam) ƒë∆∞·ª£c k·∫øt h·ª£p ƒë·ªÉ hu·∫•n luy·ªán l·∫°i m·∫°ng n∆°-ron m·ªõi.  

                """, unsafe_allow_html=True)
                try:
                    labeling_image = Image.open("labelding.webp")
                    st.image(labeling_image, caption="H√¨nh 1: Minh h·ªça quy tr√¨nh Pseudo Labeling v·ªõi 3 b∆∞·ªõc ch√≠nh.", width=600)
                except FileNotFoundError:
                    st.error("Kh√¥ng t√¨m th·∫•y file `labelding.webp`. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n.")
                except Exception as e:
                    st.error(f"L·ªói khi t·∫£i ·∫£nh: {e}")

                st.subheader("üîß Th·ª±c Ti·ªÖn √Åp D·ª•ng")
                st.markdown("""
                - **∆Øu ƒëi·ªÉm**:  
                  - **Ti·∫øt ki·ªám chi ph√≠ g√°n nh√£n**: Gi·∫£m s·ª± ph·ª• thu·ªôc v√†o d·ªØ li·ªáu c√≥ nh√£n, t·∫≠n d·ª•ng l∆∞·ª£ng l·ªõn d·ªØ li·ªáu ch∆∞a nh√£n (nh∆∞ trong MNIST v·ªõi 70,000 m·∫´u).  
                  - **C·∫£i thi·ªán hi·ªáu su·∫•t**: TƒÉng c∆∞·ªùng kh·∫£ nƒÉng t·ªïng qu√°t h√≥a c·ªßa m√¥ h√¨nh khi d·ªØ li·ªáu c√≥ nh√£n h·∫°n ch·∫ø.  
                  - **Linh ho·∫°t**: D·ªÖ d√†ng t√≠ch h·ª£p v√†o c√°c b√†i to√°n h·ªçc m√°y, nh∆∞ nh·∫≠n di·ªán h√¨nh ·∫£nh (MNIST), ph√¢n lo·∫°i vƒÉn b·∫£n, ho·∫∑c c√°c ·ª©ng d·ª•ng trong y h·ªçc v√† t·ª± ƒë·ªông h√≥a.

                - **Nh∆∞·ª£c ƒëi·ªÉm**:  
                  - **Lan truy·ªÅn sai s√≥t**: N·∫øu nh√£n gi·∫£ kh√¥ng ch√≠nh x√°c, sai s√≥t c√≥ th·ªÉ lan truy·ªÅn qua c√°c v√≤ng l·∫∑p, l√†m gi·∫£m hi·ªáu su·∫•t m√¥ h√¨nh.  
                  - **Y√™u c·∫ßu ng∆∞·ª°ng tin c·∫≠y**: C·∫ßn ch·ªçn ng∆∞·ª°ng x√°c su·∫•t h·ª£p l√Ω (trong ·ª©ng d·ª•ng n√†y, tham s·ªë `pseudo_threshold` m·∫∑c ƒë·ªãnh l√† 0.95) ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng nh√£n gi·∫£.  
                  - **T·ªën t√†i nguy√™n t√≠nh to√°n**: Qu√° tr√¨nh l·∫∑p l·∫°i nhi·ªÅu v√≤ng c√≥ th·ªÉ l√†m tƒÉng th·ªùi gian hu·∫•n luy·ªán (ƒë∆∞·ª£c ghi nh·∫≠n trong `training_time` tr√™n MLflow).

                - **·ª®ng d·ª•ng Th·ª±c T·∫ø**:  
                  - **Nh·∫≠n di·ªán h√¨nh ·∫£nh**: Nh∆∞ b√†i to√°n ph√¢n lo·∫°i ch·ªØ s·ªë MNIST trong ·ª©ng d·ª•ng n√†y, n∆°i d·ªØ li·ªáu ch∆∞a nh√£n chi·∫øm ph·∫ßn l·ªõn.  
                  - **Ph√¢n lo·∫°i vƒÉn b·∫£n**: G√°n nh√£n cho c√°c t√†i li·ªáu ch∆∞a ƒë∆∞·ª£c ph√¢n lo·∫°i d·ª±a tr√™n m·ªôt t·∫≠p nh·ªè d·ªØ li·ªáu c√≥ nh√£n.  
                  - **Y h·ªçc**: S·ª≠ d·ª•ng d·ªØ li·ªáu y t·∫ø ch∆∞a nh√£n (h√¨nh ·∫£nh X-quang, MRI) ƒë·ªÉ c·∫£i thi·ªán m√¥ h√¨nh ch·∫©n ƒëo√°n b·ªánh v·ªõi l∆∞·ª£ng d·ªØ li·ªáu c√≥ nh√£n h·∫°n ch·∫ø.
                """, unsafe_allow_html=True)

                st.subheader("üîç T√≠ch H·ª£p trong ·ª®ng D·ª•ng N√†y")
                st.markdown("""
                Trong ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë MNIST, Pseudo Labeling ƒë∆∞·ª£c tri·ªÉn khai trong tab **Hu·∫•n luy·ªán/ƒê√°nh gi√°** v·ªõi c√°c tham s·ªë sau:  
                - **Ng∆∞·ª°ng g√°n nh√£n gi·∫£ (`pseudo_threshold`)**: Ng∆∞·ªùi d√πng c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh t·ª´ 0.5 ƒë·∫øn 1.0 (m·∫∑c ƒë·ªãnh: 0.95) ƒë·ªÉ quy·∫øt ƒë·ªãnh m·ª©c ƒë·ªô tin c·∫≠y c·ªßa nh√£n gi·∫£.  
                - **S·ªë v√≤ng l·∫∑p t·ªëi ƒëa (`max_iterations`)**: S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa ƒë·ªÉ g√°n nh√£n gi·∫£ (m·∫∑c ƒë·ªãnh: 5).  
                - **Quy tr√¨nh**:  
                  1. L·∫•y 1% m·∫´u t·ª´ m·ªói l·ªõp (0-9) trong t·∫≠p hu·∫•n luy·ªán l√†m d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu.  
                  2. Hu·∫•n luy·ªán m√¥ h√¨nh ban ƒë·∫ßu, d·ª± ƒëo√°n nh√£n gi·∫£ cho d·ªØ li·ªáu c√≤n l·∫°i, v√† l·∫∑p l·∫°i qu√° tr√¨nh theo c√°c b∆∞·ªõc ƒë√£ m√¥ t·∫£.  
                  3. K·∫øt qu·∫£ ƒë∆∞·ª£c ghi nh·∫≠n tr√™n MLflow, bao g·ªìm s·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n (`pseudo_labeled_samples`) v√† ƒë·ªô ch√≠nh x√°c tr√™n t·∫≠p validation/test.

                Pseudo Labeling gi√∫p c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c c·ªßa m√¥ h√¨nh Neural Network, ƒë·∫∑c bi·ªát khi d·ªØ li·ªáu c√≥ nh√£n b·ªã gi·ªõi h·∫°n, v√† ƒë∆∞·ª£c minh h·ªça tr·ª±c quan qua h√¨nh ·∫£nh tr√™n, ph√π h·ª£p v·ªõi quy tr√¨nh tri·ªÉn khai trong m√£ ngu·ªìn.
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìò 5. C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)")
                st.markdown("""
                - ƒê·ªô ch√≠nh x√°c (**Accuracy**) ƒëo t·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng:  
                  $$ \\text{Accuracy} = \\frac{\\text{S·ªë m·∫´u d·ª± ƒëo√°n ƒë√∫ng}}{\\text{T·ªïng s·ªë m·∫´u}} $$  
                - **Gi·∫£i th√≠ch**:  
                  - $\\text{S·ªë m·∫´u d·ª± ƒëo√°n ƒë√∫ng}$: S·ªë l·∫ßn m√¥ h√¨nh d·ª± ƒëo√°n nh√£n ch√≠nh x√°c so v·ªõi nh√£n th·ª±c t·∫ø.  
                  - $\\text{T·ªïng s·ªë m·∫´u}$: T·ªïng s·ªë m·∫´u trong t·∫≠p d·ªØ li·ªáu ki·ªÉm tra.  
                - **V√≠ d·ª•**: D·ª± ƒëo√°n ƒë√∫ng $92/100$ ·∫£nh ‚Üí $\\text{Accuracy} = 0.92$ (t·ª©c $92\%$).  
                - M·ª•c ƒë√≠ch: ƒêo l∆∞·ªùng kh·∫£ nƒÉng ph√¢n lo·∫°i ƒë√∫ng c√°c ch·ªØ s·ªë c·ªßa Neural Network d·ª±a tr√™n ƒë·∫∑c tr∆∞ng pixel h·ªçc ƒë∆∞·ª£c.
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

    # Tab 2: Ch·ªçn d·ªØ li·ªáu
    with tab_load:
        st.markdown('<div class="section-title">T·∫£i D·ªØ li·ªáu</div>', unsafe_allow_html=True)
        st.markdown("""
        """, unsafe_allow_html=True)

        if 'full_data' not in st.session_state:
            if st.button("T·∫£i d·ªØ li·ªáu MNIST ", type="primary"):
                with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu MNIST  ..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    try:
                        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
                        for i in range(0, 101, 20):
                            progress_bar.progress(i)
                            status_text.text(f"ƒêang t·∫£i d·ªØ li·ªáu... {i}%")
                            time.sleep(0.1)
                        X = np.concatenate([X_train, X_test], axis=0)
                        y = np.concatenate([y_train, y_test], axis=0)
                        X = X.reshape(-1, 784).astype(np.float64)
                        y = y.astype(np.int32)
                        st.session_state['full_data'] = (X, y)
                        progress_bar.progress(100)
                        status_text.text("ƒê√£ t·∫£i xong! 100%")
                        st.success("ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng!")
                        st.write(f"K√≠ch th∆∞·ªõc d·ªØ li·ªáu: {X.shape[0]} m·∫´u, m·ªói m·∫´u {X.shape[1]} ƒë·∫∑c tr∆∞ng")
                        time.sleep(0.5)
                        status_text.empty()
                        progress_bar.empty()
                        st.rerun()
                    except Exception as e:
                        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        else:
            X_full, y_full = st.session_state['full_data']
            st.subheader("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u")
            st.markdown("""
            - **1000 m·∫´u**: Hu·∫•n luy·ªán nhanh, ƒë·ªô ch√≠nh x√°c th·∫•p, ph√π h·ª£p ƒë·ªÉ th·ª≠ nghi·ªám.  
            - **10,000 m·∫´u**: Hu·∫•n luy·ªán kh√° nhanh, ƒë·ªô ch√≠nh x√°c trung b√¨nh, ph√π h·ª£p ƒë·ªÉ ki·ªÉm tra c∆° b·∫£n.  
            - **50,000 m·∫´u**: Hu·∫•n luy·ªán l√¢u h∆°n, ƒë·ªô ch√≠nh x√°c kh√°, c√¢n b·∫±ng gi·ªØa t·ªëc ƒë·ªô v√† hi·ªáu su·∫•t.  
            - **70,000 m·∫´u**: Hu·∫•n luy·ªán l√¢u nh·∫•t, ƒë·ªô ch√≠nh x√°c cao, ph√π h·ª£p cho hu·∫•n luy·ªán chuy√™n s√¢u.  
            """, unsafe_allow_html=True)

            col1, col_center, col2 = st.columns([2, 1, 2])
            with col1:
                sample_options = {
                    "1000 m·∫´u (Th·ª≠ nghi·ªám nhanh)": 1000,
                    "10,000 m·∫´u (Ki·ªÉm tra c∆° b·∫£n)": 10000,
                    "50,000 m·∫´u (C√¢n b·∫±ng hi·ªáu su·∫•t)": 50000,
                    "70,000 m·∫´u (Hu·∫•n luy·ªán chuy√™n s√¢u)": 70000
                }
                selected_option = st.selectbox("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u:", list(sample_options.keys()), help="Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u c√≥ s·∫µn")
                num_samples = min(sample_options[selected_option], len(X_full))

                if st.button("X√°c nh·∫≠n s·ªë l∆∞·ª£ng (t√πy ch·ªçn c√≥ s·∫µn)", type="primary"):
                    with st.spinner(f"ƒêang l·∫•y {num_samples} m·∫´u..."):
                        indices = np.random.choice(len(X_full), size=num_samples, replace=False)
                        X_sampled = X_full[indices]
                        y_sampled = y_full[indices]
                        st.session_state['data'] = (X_sampled.copy(), y_sampled.copy())
                        st.session_state['optimal_params'] = get_optimal_params(num_samples)
                        with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name="Data_Sample"):
                            mlflow.log_param("num_samples", num_samples)
                        st.success(f"ƒê√£ ch·ªçn {num_samples} m·∫´u!")
                        del X_full, y_full, X_sampled, y_sampled
                        gc.collect()

            with col_center:
                st.markdown("<h3 style='text-align: center; margin-top: 30px;'>ho·∫∑c</h3>", unsafe_allow_html=True)

            with col2:
                custom_num_samples = st.number_input("Nh·∫≠p s·ªë l∆∞·ª£ng t√πy √Ω (t·ªëi ƒëa 70,000):", min_value=1, max_value=70000, value=1000, step=100, help="Nh·∫≠p s·ªë l∆∞·ª£ng m·∫´u t√πy ch·ªânh")
                if st.button("X√°c nh·∫≠n s·ªë l∆∞·ª£ng (t√πy √Ω)", type="primary"):
                    if custom_num_samples <= len(X_full):
                        with st.spinner(f"ƒêang l·∫•y {custom_num_samples} m·∫´u..."):
                            indices = np.random.choice(len(X_full), size=custom_num_samples, replace=False)
                            X_sampled = X_full[indices]
                            y_sampled = y_full[indices]
                            st.session_state['data'] = (X_sampled.copy(), y_sampled.copy())
                            st.session_state['optimal_params'] = get_optimal_params(custom_num_samples)
                            with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name="Data_Sample_Custom"):
                                mlflow.log_param("num_samples", custom_num_samples)
                            st.success(f"ƒê√£ ch·ªçn {custom_num_samples} m·∫´u!")
                            del X_full, y_full, X_sampled, y_sampled
                            gc.collect()
                    else:
                        st.error("S·ªë l∆∞·ª£ng m·∫´u v∆∞·ª£t qu√° d·ªØ li·ªáu hi·ªán c√≥. Vui l√≤ng nh·∫≠p s·ªë nh·ªè h∆°n ho·∫∑c b·∫±ng 70,000!")

    # Tab 3: X·ª≠ l√Ω d·ªØ li·ªáu
    with tab_preprocess:
        st.markdown('<div class="section-title">X·ª≠ l√Ω D·ªØ li·ªáu</div>', unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui l√≤ng ch·ªçn s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc.")
        else:
            X, y = st.session_state['data']
            if "data_original" not in st.session_state:
                st.session_state["data_original"] = (X.copy(), y.copy())

            st.subheader("D·ªØ li·ªáu G·ªëc")
            fig, axes = plt.subplots(2, 5, figsize=(10, 4))
            for i, ax in enumerate(axes.flat):
                ax.imshow(X[i].reshape(28, 28), cmap='gray')
                ax.set_title(f"Label: {y[i]}")
                ax.axis("off")
            st.pyplot(fig)
            plt.close(fig)

            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("Chu·∫©n h√≥a d·ªØ li·ªáu (Normalization)", type="primary", help="Chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ thang [0, 1]"):
                    with st.spinner("ƒêang chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ [0, 1]..."):
                        X_norm = X / 255.0
                        st.session_state["data_processed"] = (X_norm.copy(), y.copy())
                        st.success("ƒê√£ x·ª≠ l√Ω d·ªØ li·ªáu!")
                        del X, y, X_norm
                        gc.collect()
                        st.rerun()
            with col2:
                st.markdown("""
                    <div class="tooltip">? (Norm)
                        <span class="tooltiptext">
                            ƒê∆∞a d·ªØ li·ªáu v·ªÅ $[0, 1]$ b·∫±ng c√°ch chia cho $255$.<br>
                            C√¥ng d·ª•ng: ƒê·∫£m b·∫£o thang ƒëo ƒë·ªìng nh·∫•t cho Neural Network.
                        </span>
                    </div>
                """, unsafe_allow_html=True)

            if "data_processed" in st.session_state:
                X_processed, y_processed = st.session_state["data_processed"]
                st.success("ƒê√£ x·ª≠ l√Ω d·ªØ li·ªáu!")

    # Tab 4: Chia d·ªØ li·ªáu
    with tab_split:
        st.markdown('<div class="section-title">Chia T·∫≠p D·ªØ li·ªáu</div>', unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui l√≤ng ch·ªçn v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            data_source = st.session_state.get('data_processed', st.session_state['data'])
            X, y = data_source
            total_samples = len(X)
            st.write(f"T·ªïng s·ªë m·∫´u: {total_samples}")

            col1, col2 = st.columns(2)
            with col1:
                test_pct = st.slider("T·ª∑ l·ªá Test (%)", 0, 50, 20, help="T·ª∑ l·ªá d·ªØ li·ªáu d√πng ƒë·ªÉ ki·ªÉm tra m√¥ h√¨nh")
            with col2:
                valid_pct = st.slider("T·ª∑ l·ªá Validation (%)", 0, 50, 20, help="T·ª∑ l·ªá d·ªØ li·ªáu d√πng ƒë·ªÉ x√°c th·ª±c m√¥ h√¨nh")

            test_size = test_pct / 100
            X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
            valid_size = (valid_pct / 100) / (1 - test_size) if test_size < 1 else 0
            X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=valid_size, random_state=42)

            st.write(f"**Ph√¢n b·ªï d·ªØ li·ªáu**: Train: {len(X_train)}, Validation: {len(X_valid)}, Test: {len(X_test)}")
            if st.button("X√°c nh·∫≠n ph√¢n chia", type="primary"):
                with st.spinner("ƒêang chia d·ªØ li·ªáu..."):
                    st.session_state['split_data'] = {
                        "X_train": X_train.copy(), "y_train": y_train.copy(),
                        "X_valid": X_valid.copy(), "y_valid": y_valid.copy(),
                        "X_test": X_test.copy(), "y_test": y_test.copy()
                    }
                    st.success("ƒê√£ chia d·ªØ li·ªáu th√†nh c√¥ng!")
                    del X, y, X_temp, y_temp, X_test, y_test, X_train, X_valid, y_train, y_valid
                    gc.collect()

    # Tab 5: Hu·∫•n luy·ªán/ƒê√°nh gi√°
    with tab_train_eval:
        st.markdown('<div class="section-title">Hu·∫•n luy·ªán v√† ƒê√°nh gi√° M√¥ h√¨nh</div>', unsafe_allow_html=True)

        if 'split_data' not in st.session_state:
            st.info("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            split_data = st.session_state['split_data'].copy()
            X_train = split_data["X_train"]
            y_train = split_data["y_train"]
            X_valid = split_data["X_valid"]
            y_valid = split_data["y_valid"]
            X_test = split_data["X_test"]
            y_test = split_data["y_test"]

            X_train = np.array(X_train, dtype=np.float32)
            y_train = np.array(y_train, dtype=np.int32)
            X_valid = np.array(X_valid, dtype=np.float32)
            y_valid = np.array(y_valid, dtype=np.int32)
            X_test = np.array(X_test, dtype=np.float32)
            y_test = np.array(y_test, dtype=np.int32)

            if np.any(np.isnan(X_train)) or np.any(np.isnan(y_train)):
                st.error("D·ªØ li·ªáu hu·∫•n luy·ªán ch·ª©a gi√° tr·ªã NaN. ƒêang x·ª≠ l√Ω...")
                X_train = np.nan_to_num(X_train, nan=0.0)
                y_train = np.nan_to_num(y_train, nan=0.0)
                st.success("ƒê√£ thay th·∫ø NaN b·∫±ng 0 trong d·ªØ li·ªáu hu·∫•n luy·ªán!")

            num_samples = len(X_train)
            st.write(f"**S·ªë m·∫´u hu·∫•n luy·ªán**: {num_samples}")
            if X_train.shape[0] != y_train.shape[0]:
                st.error("S·ªë m·∫´u c·ªßa X_train v√† y_train kh√¥ng kh·ªõp!")
                st.stop()

            if "optimal_params" not in st.session_state:
                st.session_state["optimal_params"] = get_optimal_params(num_samples)
            
            params = st.session_state.get("training_params", st.session_state["optimal_params"].copy())

            # Th√™m t√πy ch·ªçn ch·∫ø ƒë·ªô hu·∫•n luy·ªán
            training_mode = st.radio("Ch·ªçn ch·∫ø ƒë·ªô hu·∫•n luy·ªán:", ["Hu·∫•n luy·ªán th√¥ng th∆∞·ªùng", "Pseudo Labeling"],
                                     help="Ch·ªçn gi·ªØa hu·∫•n luy·ªán th√¥ng th∆∞·ªùng ho·∫∑c Pseudo Labeling v·ªõi d·ªØ li·ªáu ch∆∞a g√°n nh√£n.")

            st.subheader("‚öôÔ∏è C·∫•u h√¨nh tham kh·∫£o Tham s·ªë M√¥ h√¨nh")
            st.markdown("""
            | S·ªë m·∫´u       | S·ªë l·ªõp ·∫©n | K√≠ch th∆∞·ªõc l·ªõp ·∫©n | T·ªëc ƒë·ªô h·ªçc | S·ªë l·∫ßn l·∫∑p | H√†m k√≠ch ho·∫°t | Tr√¨nh t·ªëi ∆∞u | K√≠ch th∆∞·ªõc batch |
            |--------------|-----------|-------------------|------------|------------|---------------|--------------|------------------|
            | ‚â§ 1,000      | 1         | 32                | 0.001      | 30         | ReLU          | Adam         | 32               |
            | ‚â§ 10,000     | 2         | (64, 32)          | 0.0005     | 50         | ReLU          | Adam         | 64               |
            | ‚â§ 50,000     | 2         | (128, 64)         | 0.0003     | 70         | ReLU          | Adam         | 128              |
            | > 50,000     | 3         | (128, 64, 32)     | 0.0001     | 100        | ReLU          | Adam         | 256              |
            """, unsafe_allow_html=True)
            st.info(f"Tham s·ªë t·ªëi ∆∞u cho {num_samples} m·∫´u: {st.session_state['optimal_params']}")

            col_param1, col_param2 = st.columns(2)
            with col_param1:
                with st.expander("üß† C·∫•u tr√∫c M·∫°ng", expanded=True):
                    st.markdown("**T√πy ch·ªânh s·ªë l·ªõp ·∫©n v√† n∆°-ron**", unsafe_allow_html=True)
                    num_hidden_layers = st.number_input("S·ªë l·ªõp ·∫©n", min_value=1, max_value=3, value=len(params["hidden_layer_sizes"]), 
                                                       help="Ch·ªçn 1, 2 ho·∫∑c 3 l·ªõp ·∫©n ƒë·ªÉ ƒëi·ªÅu ch·ªânh ƒë·ªô ph·ª©c t·∫°p c·ªßa m√¥ h√¨nh.")
                    hidden_sizes = list(params["hidden_layer_sizes"])
                    
                    if num_hidden_layers == 1:
                        hidden_size_1 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 1", min_value=16, max_value=128, 
                                                        value=hidden_sizes[0] if len(hidden_sizes) > 0 else 32, 
                                                        help="S·ªë n∆°-ron cho l·ªõp ·∫©n duy nh·∫•t (16-128).")
                        hidden_sizes = [hidden_size_1]
                    elif num_hidden_layers == 2:
                        hidden_size_1 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 1", min_value=16, max_value=128, 
                                                        value=hidden_sizes[0] if len(hidden_sizes) > 0 else 64, 
                                                        help="S·ªë n∆°-ron cho l·ªõp ·∫©n ƒë·∫ßu ti√™n (16-128).")
                        hidden_size_2 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 2", min_value=16, max_value=128, 
                                                        value=hidden_sizes[1] if len(hidden_sizes) > 1 else 32, 
                                                        help="S·ªë n∆°-ron cho l·ªõp ·∫©n th·ª© hai (16-128).")
                        hidden_sizes = [hidden_size_1, hidden_size_2]
                    elif num_hidden_layers == 3:
                        hidden_size_1 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 1", min_value=16, max_value=128, 
                                                        value=hidden_sizes[0] if len(hidden_sizes) > 0 else 128, 
                                                        help="S·ªë n∆°-ron cho l·ªõp ·∫©n ƒë·∫ßu ti√™n (16-128).")
                        hidden_size_2 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 2", min_value=16, max_value=128, 
                                                        value=hidden_sizes[1] if len(hidden_sizes) > 1 else 64, 
                                                        help="S·ªë n∆°-ron cho l·ªõp ·∫©n th·ª© hai (16-128).")
                        hidden_size_3 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 3", min_value=16, max_value=128, 
                                                        value=hidden_sizes[2] if len(hidden_sizes) > 2 else 32, 
                                                        help="S·ªë n∆°-ron cho l·ªõp ·∫©n th·ª© ba (16-128).")
                        hidden_sizes = [hidden_size_1, hidden_size_2, hidden_size_3]
                    
                    params["hidden_layer_sizes"] = tuple(hidden_sizes)
                    params["activation"] = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "sigmoid", "tanh"], 
                                                        index=["relu", "sigmoid", "tanh"].index(params["activation"]),
                                                        help="Ch·ªçn h√†m k√≠ch ho·∫°t: ReLU (nhanh), Sigmoid (x√°c su·∫•t), Tanh (c√¢n b·∫±ng).")
            
            with col_param2:
                with st.expander("üîß T·ªëi ∆∞u h√≥a", expanded=True):
                    st.markdown("**C·∫•u h√¨nh hu·∫•n luy·ªán**", unsafe_allow_html=True)
                    params["learning_rate"] = st.selectbox("T·ªëc ƒë·ªô h·ªçc", [0.01, 0.005, 0.001, 0.0005, 0.0003, 0.0001], 
                                                           index=[0.01, 0.005, 0.001, 0.0005, 0.0003, 0.0001].index(params["learning_rate"]),
                                                           help="T·ªëc ƒë·ªô h·ªçc c√†ng nh·ªè c√†ng ·ªïn ƒë·ªãnh nh∆∞ng ch·∫≠m.")
                    params["epochs"] = st.number_input("S·ªë l·∫ßn l·∫∑p (Epochs)", min_value=10, max_value=100, value=params["epochs"], 
                                                       help="S·ªë l·∫ßn l·∫∑p qua to√†n b·ªô d·ªØ li·ªáu (10-100).")
                    params["batch_size"] = st.number_input("K√≠ch th∆∞·ªõc batch", min_value=32, max_value=256, value=params["batch_size"], 
                                                           help="S·ªë m·∫´u m·ªói l·∫ßn c·∫≠p nh·∫≠t tr·ªçng s·ªë (32-256).")
                    params["solver"] = st.selectbox("Tr√¨nh t·ªëi ∆∞u", ["adam", "sgd"], 
                                                    index=["adam", "sgd"].index(params["solver"]),
                                                    help="Adam (nhanh, hi·ªáu qu·∫£), SGD (ƒë∆°n gi·∫£n, ch·∫≠m h∆°n).")
                    early_stopping = st.checkbox("D·ª´ng s·ªõm (Early Stopping)", value=False, 
                                                 help="D·ª´ng hu·∫•n luy·ªán n·∫øu kh√¥ng c·∫£i thi·ªán tr√™n t·∫≠p validation sau 10 epochs.")
                    
                    # Th√™m tham s·ªë cho Pseudo Labeling
                    if training_mode == "Pseudo Labeling":
                        pseudo_threshold = st.slider("Ng∆∞·ª°ng g√°n nh√£n gi·∫£ (Threshold)", 0.5, 1.0, 0.95, step=0.01,
                                                     help="Ng∆∞·ª°ng x√°c su·∫•t ƒë·ªÉ g√°n nh√£n gi·∫£ (0.5-1.0).")
                        max_iterations = st.number_input("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa", min_value=1, max_value=10, value=5,
                                                         help="S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa cho Pseudo Labeling.")

            col_reset, col_train = st.columns([1, 3])
            with col_reset:
                if st.button("üîÑ Kh√¥i ph·ª•c tham s·ªë t·ªëi ∆∞u", key="reset_params"):
                    st.session_state["training_params"] = st.session_state["optimal_params"].copy()
                    st.success("ƒê√£ kh√¥i ph·ª•c tham s·ªë t·ªëi ∆∞u!")
                    st.rerun()

            st.session_state["training_params"] = params

            with col_train:
                if st.button("üöÄ B·∫Øt ƒë·∫ßu Hu·∫•n luy·ªán", type="primary", key="start_training"):
                    try:
                        with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
                            start_time = time.time()

                            if training_mode == "Hu·∫•n luy·ªán th√¥ng th∆∞·ªùng":
                                # Hu·∫•n luy·ªán th√¥ng th∆∞·ªùng
                                model = models.Sequential()
                                model.add(layers.Input(shape=(784,)))
                                for neurons in params["hidden_layer_sizes"]:
                                    model.add(layers.Dense(neurons, activation=params["activation"]))
                                model.add(layers.Dense(10, activation='softmax'))

                                optimizer = tf.keras.optimizers.Adam(learning_rate=params["learning_rate"]) if params["solver"] == "adam" else tf.keras.optimizers.SGD(learning_rate=params["learning_rate"])

                                model.compile(optimizer=optimizer,
                                              loss='sparse_categorical_crossentropy',
                                              metrics=['accuracy'])

                                progress_bar = st.progress(0)
                                status_text = st.empty()

                                class ProgressCallback(callbacks.Callback):
                                    def on_epoch_end(self, epoch, logs=None):
                                        progress = (epoch + 1) / params["epochs"] * 100
                                        progress_bar.progress(int(progress))
                                        status_text.text(f"Epoch {epoch+1}/{params['epochs']}, Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}, Val Loss: {logs.get('val_loss', 'N/A'):.4f}, Val Accuracy: {logs.get('val_accuracy', 'N/A'):.4f}")

                                callbacks_list = [ProgressCallback()]
                                if early_stopping:
                                    callbacks_list.append(callbacks.EarlyStopping(monitor='val_loss', patience=10))

                                history = model.fit(X_train, y_train, epochs=params["epochs"], batch_size=params["batch_size"],
                                                    validation_data=(X_valid, y_valid), callbacks=callbacks_list, verbose=0)

                                y_valid_pred = np.argmax(model.predict(X_valid, verbose=0), axis=1)
                                y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                                acc_valid = accuracy_score(y_valid, y_valid_pred)
                                acc_test = accuracy_score(y_test, y_test_pred)
                                cm_valid = confusion_matrix(y_valid, y_valid_pred)
                                cm_test = confusion_matrix(y_test, y_test_pred)

                                run_name = f"NeuralNetwork_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                                with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=run_name) as run:
                                    mlflow.log_params({k: v for k, v in params.items() if k in ['hidden_layer_sizes', 'learning_rate', 'epochs', 'batch_size', 'activation', 'solver']})
                                    mlflow.log_metric("accuracy_val", acc_valid)
                                    mlflow.log_metric("accuracy_test", acc_test)
                                    mlflow.log_metric("training_time", time.time() - start_time)
                                    mlflow.log_metric("n_iter_actual", len(history.history['loss']))

                                st.session_state['model'] = model
                                st.session_state['training_results'] = {
                                    'accuracy_val': acc_valid, 'accuracy_test': acc_test,
                                    'cm_valid': cm_valid, 'cm_test': cm_test,
                                    'run_name': run_name, 'run_id': run.info.run_id,
                                    'params': params, 'training_time': time.time() - start_time,
                                    'loss_history': history.history['loss'][-10:],
                                    'val_loss_history': history.history['val_loss'][-10:] if 'val_loss' in history.history else [],
                                    'accuracy_history': history.history['accuracy'][-10:],
                                    'val_accuracy_history': history.history['val_accuracy'][-10:] if 'val_accuracy' in history.history else [],
                                    'n_iter_actual': len(history.history['loss'])
                                }

                                st.success(f"ƒê√£ hu·∫•n luy·ªán xong! Th·ªùi gian: {time.time() - start_time:.2f} gi√¢y, S·ªë l·∫ßn l·∫∑p th·ª±c t·∫ø: {len(history.history['loss'])}")

                            elif training_mode == "Pseudo Labeling":
                                # B∆∞·ªõc 0: Chia t·∫≠p train/test ƒë√£ c√≥ t·ª´ split_data
                                st.write("B·∫Øt ƒë·∫ßu qu√° tr√¨nh Pseudo Labeling...")

                                # B∆∞·ªõc 1: L·∫•y 1% m·∫´u t·ª´ m·ªói class trong t·∫≠p train
                                labeled_X, labeled_y = [], []
                                unlabeled_X = []
                                for digit in range(10):
                                    digit_indices = np.where(y_train == digit)[0]
                                    num_labeled = max(1, int(len(digit_indices) * 0.01))  # L·∫•y 1% ho·∫∑c √≠t nh·∫•t 1 m·∫´u
                                    labeled_indices = np.random.choice(digit_indices, num_labeled, replace=False)
                                    unlabeled_indices = np.setdiff1d(digit_indices, labeled_indices)
                                    labeled_X.append(X_train[labeled_indices])
                                    labeled_y.append(y_train[labeled_indices])
                                    unlabeled_X.append(X_train[unlabeled_indices])

                                labeled_X = np.concatenate(labeled_X, axis=0)
                                labeled_y = np.concatenate(labeled_y, axis=0)
                                unlabeled_X = np.concatenate(unlabeled_X, axis=0)
                                st.write(f"T·∫≠p labeled ban ƒë·∫ßu: {len(labeled_X)} m·∫´u")
                                st.write(f"T·∫≠p unlabeled: {len(unlabeled_X)} m·∫´u")

                                # Kh·ªüi t·∫°o model
                                def create_model():
                                    model = models.Sequential()
                                    model.add(layers.Input(shape=(784,)))
                                    for neurons in params["hidden_layer_sizes"]:
                                        model.add(layers.Dense(neurons, activation=params["activation"]))
                                    model.add(layers.Dense(10, activation='softmax'))
                                    optimizer = tf.keras.optimizers.Adam(learning_rate=params["learning_rate"]) if params["solver"] == "adam" else tf.keras.optimizers.SGD(learning_rate=params["learning_rate"])
                                    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
                                    return model

                                model = create_model()
                                progress_bar = st.progress(0)
                                status_text = st.empty()

                                # V√≤ng l·∫∑p Pseudo Labeling
                                iteration = 0
                                total_unlabeled = len(unlabeled_X)
                                pseudo_labeled_X, pseudo_labeled_y = labeled_X.copy(), labeled_y.copy()

                                while iteration < max_iterations and len(unlabeled_X) > 0:
                                    iteration += 1
                                    st.write(f"**V√≤ng l·∫∑p {iteration}/{max_iterations}**")

                                    # B∆∞·ªõc 2: Hu·∫•n luy·ªán tr√™n t·∫≠p labeled hi·ªán t·∫°i
                                    history = model.fit(pseudo_labeled_X, pseudo_labeled_y, epochs=params["epochs"],
                                                        batch_size=params["batch_size"], validation_data=(X_valid, y_valid),
                                                        callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=10)] if early_stopping else [],
                                                        verbose=0)
                                    status_text.text(f"V√≤ng {iteration}: Hu·∫•n luy·ªán xong, Loss: {history.history['loss'][-1]:.4f}, Accuracy: {history.history['accuracy'][-1]:.4f}")

                                    # B∆∞·ªõc 3: D·ª± ƒëo√°n nh√£n cho t·∫≠p unlabeled
                                    pseudo_predictions = model.predict(unlabeled_X, verbose=0)
                                    pseudo_confidences = np.max(pseudo_predictions, axis=1)
                                    pseudo_labels = np.argmax(pseudo_predictions, axis=1)

                                    # B∆∞·ªõc 4: G√°n nh√£n gi·∫£ v·ªõi ng∆∞·ª°ng
                                    confident_mask = pseudo_confidences >= pseudo_threshold
                                    new_labeled_X = unlabeled_X[confident_mask]
                                    new_labeled_y = pseudo_labels[confident_mask]

                                    if len(new_labeled_X) > 0:
                                        pseudo_labeled_X = np.concatenate([pseudo_labeled_X, new_labeled_X], axis=0)
                                        pseudo_labeled_y = np.concatenate([pseudo_labeled_y, new_labeled_y], axis=0)
                                        unlabeled_X = unlabeled_X[~confident_mask]
                                        st.write(f"ƒê√£ g√°n nh√£n gi·∫£ cho {len(new_labeled_X)} m·∫´u, c√≤n l·∫°i {len(unlabeled_X)} m·∫´u ch∆∞a g√°n.")
                                    else:
                                        st.write("Kh√¥ng c√≥ m·∫´u n√†o ƒë·∫°t ng∆∞·ª°ng trong v√≤ng n√†y.")
                                        break

                                    progress_bar.progress(int((total_unlabeled - len(unlabeled_X)) / total_unlabeled * 100))

                                # ƒê√°nh gi√° cu·ªëi c√πng
                                y_valid_pred = np.argmax(model.predict(X_valid, verbose=0), axis=1)
                                y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                                acc_valid = accuracy_score(y_valid, y_valid_pred)
                                acc_test = accuracy_score(y_test, y_test_pred)
                                cm_valid = confusion_matrix(y_valid, y_valid_pred)
                                cm_test = confusion_matrix(y_test, y_test_pred)

                                run_name = f"PseudoLabeling_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                                with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=run_name) as run:
                                    mlflow.log_params({
                                        "hidden_layer_sizes": params["hidden_layer_sizes"],
                                        "learning_rate": params["learning_rate"],
                                        "epochs": params["epochs"],
                                        "batch_size": params["batch_size"],
                                        "activation": params["activation"],
                                        "solver": params["solver"],
                                        "pseudo_threshold": pseudo_threshold,
                                        "max_iterations": max_iterations
                                    })
                                    mlflow.log_metric("accuracy_val", acc_valid)
                                    mlflow.log_metric("accuracy_test", acc_test)
                                    mlflow.log_metric("training_time", time.time() - start_time)
                                    mlflow.log_metric("n_iter_actual", iteration)

                                st.session_state['model'] = model
                                st.session_state['training_results'] = {
                                    'accuracy_val': acc_valid, 'accuracy_test': acc_test,
                                    'cm_valid': cm_valid, 'cm_test': cm_test,
                                    'run_name': run_name, 'run_id': run.info.run_id,
                                    'params': params, 'training_time': time.time() - start_time,
                                    'loss_history': history.history['loss'][-10:],
                                    'val_loss_history': history.history['val_loss'][-10:] if 'val_loss' in history.history else [],
                                    'accuracy_history': history.history['accuracy'][-10:],
                                    'val_accuracy_history': history.history['val_accuracy'][-10:] if 'val_accuracy' in history.history else [],
                                    'n_iter_actual': iteration,
                                    'pseudo_labeled_samples': len(pseudo_labeled_X)
                                }

                                st.success(f"ƒê√£ ho√†n th√†nh Pseudo Labeling! Th·ªùi gian: {time.time() - start_time:.2f} gi√¢y, S·ªë v√≤ng l·∫∑p: {iteration}, S·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n: {len(pseudo_labeled_X)}")

                            tf.keras.backend.clear_session()
                            del X_train, y_train, X_valid, y_valid, X_test, y_test, split_data, history
                            gc.collect()
                            st.rerun()

                    except Exception as e:
                        st.error(f"L·ªói trong qu√° tr√¨nh hu·∫•n luy·ªán: {e}")

            if 'training_results' in st.session_state:
                results = st.session_state['training_results']
                st.subheader("üìä K·∫øt qu·∫£ Hu·∫•n luy·ªán")
                col_result1, col_result2, col_result3 = st.columns(3)
                with col_result1:
                    st.metric("Th·ªùi gian hu·∫•n luy·ªán", f"{results['training_time']:.2f} gi√¢y")
                with col_result2:
                    st.metric("ƒê·ªô ch√≠nh x√°c Validation", f"{results['accuracy_val']*100:.2f}%")
                with col_result3:
                    st.metric("ƒê·ªô ch√≠nh x√°c Test", f"{results['accuracy_test']*100:.2f}%")

                if training_mode == "Pseudo Labeling":
                    st.metric("S·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n", f"{results['pseudo_labeled_samples']}")
                    st.metric("S·ªë v√≤ng l·∫∑p th·ª±c t·∫ø", f"{results['n_iter_actual']}")

                st.subheader("üìà Ma tr·∫≠n Nh·∫ßm l·∫´n")
                st.markdown("""
                - Ma tr·∫≠n nh·∫ßm l·∫´n cho th·∫•y s·ªë l∆∞·ª£ng d·ª± ƒëo√°n ƒë√∫ng v√† sai c·ªßa m√¥ h√¨nh cho t·ª´ng l·ªõp ($0$-$9$):  
                  - **H√†ng**: Nh√£n th·ª±c t·∫ø.  
                  - **C·ªôt**: Nh√£n d·ª± ƒëo√°n.  
                  - **S·ªë tr√™n ƒë∆∞·ªùng ch√©o**: S·ªë m·∫´u d·ª± ƒëo√°n ƒë√∫ng.  
                  - **S·ªë ngo√†i ƒë∆∞·ªùng ch√©o**: S·ªë m·∫´u d·ª± ƒëo√°n sai (nh·∫ßm l·∫´n gi·ªØa c√°c l·ªõp).  
                """, unsafe_allow_html=True)
                col_cm1, col_cm2 = st.columns(2)
                with col_cm1:
                    fig, ax = plt.subplots(figsize=(6, 5))
                    sns.heatmap(results['cm_valid'], annot=True, fmt="d", cmap="Blues", ax=ax)
                    ax.set_title("Validation")
                    st.pyplot(fig)
                    plt.close(fig)
                with col_cm2:
                    fig, ax = plt.subplots(figsize=(6, 5))
                    sns.heatmap(results['cm_test'], annot=True, fmt="d", cmap="Blues", ax=ax)
                    ax.set_title("Test")
                    st.pyplot(fig)
                    plt.close(fig)

                st.subheader("üìâ Bi·ªÉu ƒë·ªì K·∫øt qu·∫£ Hu·∫•n luy·ªán")
                if results['loss_history']:
                    fig, ax = plt.subplots(figsize=(8, 4))
                    ax.plot(range(1, len(results['loss_history']) + 1), results['loss_history'], 
                            label='Training Loss', linestyle='-', color='blue', linewidth=2)
                    if results['val_loss_history']:
                        ax.plot(range(1, len(results['val_loss_history']) + 1), results['val_loss_history'], 
                                label='Validation Loss', linestyle='--', color='orange', linewidth=2)
                    ax.set_xlabel("Epochs")
                    ax.set_ylabel("Loss")
                    ax.set_title("Training & Validation Loss")
                    ax.legend()
                    ax.grid(True)
                    st.pyplot(fig)
                    plt.close(fig)
                    st.markdown("""
                    **Gi·∫£i th√≠ch bi·ªÉu ƒë·ªì Loss:**
                    - **Train Loss (M·∫•t m√°t hu·∫•n luy·ªán):** ƒê·∫°i di·ªán cho sai s·ªë gi·ªØa d·ª± ƒëo√°n v√† nh√£n th·ª±c t·∫ø tr√™n t·∫≠p hu·∫•n luy·ªán. Gi√° tr·ªã gi·∫£m d·∫ßn qua c√°c epoch cho th·∫•y m√¥ h√¨nh ƒëang h·ªçc t·ªët h∆°n.
                    - **Val Loss (M·∫•t m√°t validation):** ƒêo l∆∞·ªùng sai s·ªë tr√™n t·∫≠p validation (n·∫øu c√≥), gi√∫p ƒë√°nh gi√° kh·∫£ nƒÉng t·ªïng qu√°t h√≥a. N·∫øu Val Loss ·ªïn ƒë·ªãnh ho·∫∑c gi·∫£m ch·∫≠m, m√¥ h√¨nh kh√¥ng b·ªã overfitting.
                    - Hai ƒë∆∞·ªùng n√†y n√™n c√≥ xu h∆∞·ªõng t∆∞∆°ng t·ª±; n·∫øu Val Loss tƒÉng trong khi Train Loss gi·∫£m, ƒë√≥ l√† d·∫•u hi·ªáu c·ªßa overfitting.
                    """)

                if results['accuracy_history']:
                    fig, ax = plt.subplots(figsize=(8, 4))
                    ax.plot(range(1, len(results['accuracy_history']) + 1), results['accuracy_history'], 
                            label='Training Accuracy', linestyle='-', color='green', linewidth=2)
                    if results['val_accuracy_history'] and any(v is not None for v in results['val_accuracy_history']):
                        ax.plot(range(1, len(results['val_accuracy_history']) + 1), results['val_accuracy_history'], 
                                label='Validation Accuracy', linestyle='--', color='red', linewidth=2)
                    ax.set_xlabel("Epochs")
                    ax.set_ylabel("Accuracy")
                    ax.set_title("Training & Validation Accuracy")
                    ax.legend()
                    ax.grid(True)
                    st.pyplot(fig)
                    plt.close(fig)
                    st.markdown("""
                    **Gi·∫£i th√≠ch bi·ªÉu ƒë·ªì Accuracy:**
                    - **Train Accuracy (ƒê·ªô ch√≠nh x√°c hu·∫•n luy·ªán):** T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng tr√™n t·∫≠p hu·∫•n luy·ªán, th∆∞·ªùng tƒÉng qua c√°c epoch khi m√¥ h√¨nh h·ªçc.
                    - **Val Accuracy (ƒê·ªô ch√≠nh x√°c validation):** T·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng tr√™n t·∫≠p validation (n·∫øu c√≥), ph·∫£n √°nh kh·∫£ nƒÉng t·ªïng qu√°t h√≥a. Gi√° tr·ªã cao v√† ·ªïn ƒë·ªãnh cho th·∫•y m√¥ h√¨nh ho·∫°t ƒë·ªông t·ªët tr√™n d·ªØ li·ªáu m·ªõi.
                    - S·ª± kh√°c bi·ªát gi·ªØa Train Accuracy v√† Val Accuracy kh√¥ng qu√° l·ªõn l√† d·∫•u hi·ªáu c·ªßa m·ªôt m√¥ h√¨nh c√¢n b·∫±ng.
                    """)

                with st.expander("Xem chi ti·∫øt", expanded=False):
                    st.markdown("**Th√¥ng tin l·∫ßn ch·∫°y:**")
                    st.write(f"- T√™n: {results['run_name']}")
                    st.write(f"- ID: {results['run_id']}")
                    st.write(f"- Th·ªùi gian hu·∫•n luy·ªán: {results['training_time']:.2f} gi√¢y")
                    st.write(f"- S·ªë l·∫ßn l·∫∑p th·ª±c t·∫ø: {results['n_iter_actual']}")
                    st.write(f"- ƒê·ªô ch√≠nh x√°c Validation: {results['accuracy_val']*100:.2f}%")
                    st.write(f"- ƒê·ªô ch√≠nh x√°c Test: {results['accuracy_test']*100:.2f}%")
                    if training_mode == "Pseudo Labeling":
                        st.write(f"- S·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n: {results['pseudo_labeled_samples']}")
                    st.markdown("**Tham s·ªë ƒë√£ ch·ªçn:**")
                    params_display = {
                        "S·ªë l·ªõp ·∫©n": len(results['params']['hidden_layer_sizes']),
                        "S·ªë n∆°-ron m·ªói l·ªõp": results['params']['hidden_layer_sizes'],
                        "T·ªëc ƒë·ªô h·ªçc": results['params']['learning_rate'],
                        "S·ªë l·∫ßn l·∫∑p": results['params']['epochs'],
                        "K√≠ch th∆∞·ªõc batch": results['params']['batch_size'],
                        "H√†m k√≠ch ho·∫°t": results['params']['activation'],
                        "Tr√¨nh t·ªëi ∆∞u": results['params']['solver'],
                        "D·ª´ng s·ªõm": early_stopping
                    }
                    if training_mode == "Pseudo Labeling":
                        params_display["Ng∆∞·ª°ng g√°n nh√£n gi·∫£"] = pseudo_threshold
                        params_display["S·ªë v√≤ng l·∫∑p t·ªëi ƒëa"] = max_iterations
                    st.json(params_display)

    # Tab 6: Demo d·ª± ƒëo√°n
    with tab_demo:
        st.markdown('<div class="section-title">Demo D·ª± ƒëo√°n Ch·ªØ s·ªë</div>', unsafe_allow_html=True)
        st.header("D·ª± ƒëo√°n s·ªë vi·∫øt tay")
        st.write("Ch·ªçn c√°ch nh·∫≠p li·ªáu: t·∫£i l√™n h√¨nh ·∫£nh, s·ª≠ d·ª•ng d·ªØ li·ªáu Test ho·∫∑c v·∫Ω tr·ª±c ti·∫øp.")

        if 'split_data' not in st.session_state or 'model' not in st.session_state:
            st.warning("‚ö†Ô∏è Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc trong tab 'Hu·∫•n luy·ªán/ƒê√°nh gi√°'!")
        else:
            model = st.session_state['model']
            st.write("**M√¥ h√¨nh hi·ªán t·∫°i**: Neural Network")

            input_method = st.selectbox("Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p li·ªáu", ["T·∫£i ·∫£nh l√™n", "D·ªØ li·ªáu Test", "V·∫Ω tr·ª±c ti·∫øp"])
            is_normalized = 'data_processed' in st.session_state

            def preprocess_input(data, is_normalized):
                if not is_normalized:
                    data = data / 255.0
                return data

            if input_method == "T·∫£i ·∫£nh l√™n":
                st.markdown('<p class="mode-title">D·ª± ƒëo√°n t·ª´ ·∫¢nh T·∫£i l√™n</p>', unsafe_allow_html=True)
                uploaded_file = st.file_uploader("T·∫£i l√™n h√¨nh ·∫£nh", type=["png", "jpg", "jpeg"])
                if uploaded_file is not None:
                    image = Image.open(uploaded_file).convert('L')
                    image = image.resize((28, 28))
                    st.image(image, caption="H√¨nh ·∫£nh ƒë·∫ßu v√†o", width=100)

                    if st.button("D·ª± ƒëo√°n", key="predict_upload_button"):
                        with st.spinner("ƒêang x·ª≠ l√Ω ·∫£nh..."):
                            image_array = np.array(image, dtype=np.float32)
                            image_array = image_array.reshape(1, 784)
                            image_processed = preprocess_input(image_array, is_normalized)
                            prediction = model.predict(image_processed, verbose=0)
                            predicted_class = np.argmax(prediction[0])
                            confidence = prediction[0][predicted_class] * 100
                            st.markdown(f"""
                                <div>
                                    <strong>D·ª± ƒëo√°n:</strong> {predicted_class}<br>
                                    <strong>ƒê·ªô tin c·∫≠y:</strong> {confidence:.2f}%
                                </div>
                            """, unsafe_allow_html=True)
                            st.success("D·ª± ƒëo√°n ho√†n t·∫•t!")
                            del image, image_array, image_processed, prediction
                            gc.collect()

            elif input_method == "D·ªØ li·ªáu Test":
                st.markdown('<p class="mode-title">D·ª± ƒëo√°n t·ª´ D·ªØ li·ªáu Test</p>', unsafe_allow_html=True)
                X_test = st.session_state['split_data']["X_test"]
                y_test = st.session_state['split_data']["y_test"]
                if len(X_test) == 0:
                    st.warning("T·∫≠p Test r·ªóng. Vui l√≤ng chia l·∫°i d·ªØ li·ªáu v·ªõi t·ª∑ l·ªá Test > 0%.")
                else:
                    col_select, col_display = st.columns([3, 2])
                    with col_select:
                        idx = st.slider("Ch·ªçn m·∫´u Test", 0, min(len(X_test) - 1, 100), 0)
                    with col_display:
                        st.write("**·∫¢nh m·∫´u Test:**")
                        fig, ax = plt.subplots(figsize=(2, 2))
                        ax.imshow(X_test[idx].reshape(28, 28), cmap='gray')
                        ax.axis('off')
                        st.pyplot(fig)
                        plt.close(fig)
                        st.write(f"**Nh√£n th·ª±c t·∫ø:** {y_test[idx]}")

                    if st.button("üîç D·ª± ƒëo√°n", key="predict_test"):
                        with st.spinner("ƒêang d·ª± ƒëo√°n..."):
                            sample = X_test[idx].reshape(1, -1)
                            sample_processed = preprocess_input(sample, is_normalized)
                            prediction = model.predict(sample_processed, verbose=0)
                            predicted_class = np.argmax(prediction[0])
                            confidence = prediction[0][predicted_class] * 100
                            st.markdown(f"""
                                <div class="prediction-box">
                                    <strong>D·ª± ƒëo√°n:</strong> {predicted_class}<br>
                                    <strong>ƒê·ªô tin c·∫≠y:</strong> {confidence:.2f}%<br>
                                    <strong>Nh√£n th·ª±c t·∫ø:</strong> {y_test[idx]}
                                </div>
                            """, unsafe_allow_html=True)
                            st.success("D·ª± ƒëo√°n ho√†n t·∫•t!")
                            del sample, sample_processed, prediction
                            gc.collect()

            elif input_method == "V·∫Ω tr·ª±c ti·∫øp":
                st.markdown('<p class="mode-title">V·∫Ω tr·ª±c ti·∫øp</p>', unsafe_allow_html=True)
                st.write("V·∫Ω ch·ªØ s·ªë t·ª´ 0-9 (n√©t tr·∫Øng tr√™n n·ªÅn ƒëen):")

                if 'canvas_key' not in st.session_state:
                    st.session_state['canvas_key'] = 0

                canvas_result = st_canvas(
                    fill_color="rgba(255, 165, 0, 0.3)",
                    stroke_width=20,
                    stroke_color="#FFFFFF",
                    background_color="#000000",
                    height=280,
                    width=280,
                    drawing_mode="freedraw",
                    key=f"canvas_{st.session_state['canvas_key']}"
                )

                if canvas_result.image_data is not None:
                    image = Image.fromarray(canvas_result.image_data.astype('uint8'), 'RGBA').convert('L')
                    image_resized = image.resize((28, 28))

                    col_pred, col_clear = st.columns([2, 1])
                    with col_pred:
                        if st.button("D·ª± ƒëo√°n", key="predict_button"):
                            with st.spinner("ƒêang x·ª≠ l√Ω h√¨nh v·∫Ω..."):
                                image_array = np.array(image_resized, dtype=np.float32)
                                image_array = image_array.reshape(1, 784)
                                image_processed = preprocess_input(image_array, is_normalized)
                                prediction = model.predict(image_processed, verbose=0)
                                predicted_class = np.argmax(prediction[0])
                                confidence = prediction[0][predicted_class] * 100
                                st.markdown(f"""
                                    <div>
                                        <strong>D·ª± ƒëo√°n:</strong> {predicted_class}<br>
                                        <strong>ƒê·ªô tin c·∫≠y:</strong> {confidence:.2f}%
                                    </div>
                                """, unsafe_allow_html=True)
                                st.success("D·ª± ƒëo√°n ho√†n t·∫•t!")
                                del image, image_resized, image_array, image_processed, prediction
                                gc.collect()

                    with col_clear:
                        if st.button("X√≥a b·∫£n v·∫Ω", key="clear_button"):
                            st.session_state['canvas_key'] += 1
                            st.rerun()

    # Tab 7: Th√¥ng tin hu·∫•n luy·ªán
    with tab_log_info:
        st.markdown('<div class="section-title">Theo d√µi K·∫øt qu·∫£</div>', unsafe_allow_html=True)
        try:
            with st.spinner("ƒêang t·∫£i th√¥ng tin hu·∫•n luy·ªán..."):
                client = MlflowClient()
                runs = client.search_runs(experiment_ids=[EXPERIMENT_ID], order_by=["attributes.start_time DESC"])
                if not runs:
                    st.info(f"Ch∆∞a c√≥ l·∫ßn ch·∫°y n√†o trong Experiment ID {EXPERIMENT_ID}.")
                else:
                    run_options = {run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") for run in runs}
                    selected_run_name = st.selectbox("Ch·ªçn run:", list(run_options.values()))
                    selected_run_id = [k for k, v in run_options.items() if v == selected_run_name][0]
                    selected_run = client.get_run(selected_run_id)

                    st.subheader("ƒê·ªïi t√™n Run")
                    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", value=selected_run_name)
                    if st.button("C·∫≠p nh·∫≠t t√™n"):
                        client.set_tag(selected_run_id, "mlflow.runName", new_run_name.strip())
                        st.success(f"ƒê√£ ƒë·ªïi t√™n th√†nh: {new_run_name.strip()}")
                        st.rerun()

                    st.subheader("X√≥a Run")
                    if st.button("X√≥a l·∫ßn ch·∫°y"):
                        client.delete_run(selected_run_id)
                        st.success(f"ƒê√£ x√≥a: {selected_run_name}")
                        st.rerun()

                    st.subheader("Th√¥ng tin chi ti·∫øt")
                    st.write(f"**T√™n:** {selected_run_name}")
                    st.write(f"**ID:** {selected_run_id}")
                    st.write(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** {datetime.fromtimestamp(selected_run.info.start_time / 1000)}")
                    
                    st.markdown("**Tham s·ªë hu·∫•n luy·ªán:**")
                    st.json(selected_run.data.params, expanded=True)
                    
                    st.markdown("**S·ªë li·ªáu hu·∫•n luy·ªán:**")
                    st.json(selected_run.data.metrics, expanded=True)

                    st.subheader("üìà L·ªãch s·ª≠ Hu·∫•n luy·ªán")
                    history_metrics = client.get_metric_history(selected_run_id, "loss")
                    if history_metrics:
                        epochs = range(1, len(history_metrics) + 1)
                        loss_values = [metric.value for metric in history_metrics]
                        fig, ax = plt.subplots(figsize=(10, 5))
                        ax.plot(epochs, loss_values, label='Training Loss', linestyle='-', color='blue', linewidth=2)
                        ax.set_xlabel("Epochs")
                        ax.set_ylabel("Loss")
                        ax.set_title("L·ªãch s·ª≠ M·∫•t m√°t")
                        ax.legend()
                        ax.grid(True)
                        st.pyplot(fig)
                        plt.close(fig)
                    else:
                        if 'training_results' in st.session_state and selected_run_id == st.session_state['training_results']['run_id']:
                            results = st.session_state['training_results']
                            if results['loss_history']:
                                fig, ax = plt.subplots(figsize=(10, 5))
                                ax.plot(range(1, len(results['loss_history']) + 1), results['loss_history'], 
                                        label='Training Loss', linestyle='-', color='blue', linewidth=2)
                                if results['val_loss_history']:
                                    ax.plot(range(1, len(results['val_loss_history']) + 1), results['val_loss_history'], 
                                            label='Validation Loss', linestyle='--', color='orange', linewidth=2)
                                ax.set_xlabel("Epochs")
                                ax.set_ylabel("Loss")
                                ax.set_title("L·ªãch s·ª≠ M·∫•t m√°t")
                                ax.legend()
                                ax.grid(True)
                                st.pyplot(fig)
                                plt.close(fig)

                    history_accuracy = client.get_metric_history(selected_run_id, "accuracy")
                    if history_accuracy:
                        epochs = range(1, len(history_accuracy) + 1)
                        accuracy_values = [metric.value for metric in history_accuracy]
                        fig, ax = plt.subplots(figsize=(10, 5))
                        ax.plot(epochs, accuracy_values, label='Training Accuracy', linestyle='-', color='green', linewidth=2)
                        ax.set_xlabel("Epochs")
                        ax.set_ylabel("Accuracy")
                        ax.set_title("L·ªãch s·ª≠ ƒê·ªô ch√≠nh x√°c")
                        ax.legend()
                        ax.grid(True)
                        st.pyplot(fig)
                        plt.close(fig)
                    else:
                        if 'training_results' in st.session_state and selected_run_id == st.session_state['training_results']['run_id']:
                            results = st.session_state['training_results']
                            if results['accuracy_history']:
                                fig, ax = plt.subplots(figsize=(10, 5))
                                ax.plot(range(1, len(results['accuracy_history']) + 1), results['accuracy_history'], 
                                        label='Training Accuracy', linestyle='-', color='green', linewidth=2)
                                if results['val_accuracy_history']:
                                    ax.plot(range(1, len(results['val_accuracy_history']) + 1), results['val_accuracy_history'], 
                                            label='Validation Accuracy', linestyle='--', color='red', linewidth=2)
                                ax.set_xlabel("Epochs")
                                ax.set_ylabel("Accuracy")
                                ax.set_title("L·ªãch s·ª≠ ƒê·ªô ch√≠nh x√°c")
                                ax.legend()
                                ax.grid(True)
                                st.pyplot(fig)
                                plt.close(fig)

                    mlflow_ui_link = f"{mlflow_tracking_uri}/#/experiments/{EXPERIMENT_ID}"
                    st.markdown("---")
                    st.markdown(f"üìä **Xem chi ti·∫øt tr√™n MLflow UI**: [Nh·∫•n v√†o ƒë√¢y]({mlflow_ui_link})", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"L·ªói khi t·∫£i th√¥ng tin hu·∫•n luy·ªán: {e}")

if __name__ == "__main__":
    run_mnist_labelding_neural_network_app()