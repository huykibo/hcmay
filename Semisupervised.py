import os
import mlflow
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from mlflow.tracking import MlflowClient
from streamlit_drawable_canvas import st_canvas
from datetime import datetime
import time
import requests
import io
import sys
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
import gc

# H√†m ch·ªçn tham s·ªë t·ªëi ∆∞u d·ª±a tr√™n s·ªë m·∫´u
def get_optimal_params(num_samples):
    if num_samples <= 1000:
        return {
            "hidden_layer_sizes": (32,),
            "learning_rate": 0.001,
            "epochs": 30,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 32
        }
    elif num_samples <= 10000:
        return {
            "hidden_layer_sizes": (64, 32),
            "learning_rate": 0.0005,
            "epochs": 50,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 64
        }
    elif num_samples <= 50000:
        return {
            "hidden_layer_sizes": (128, 64),
            "learning_rate": 0.0003,
            "epochs": 70,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 128
        }
    else:  # > 50,000
        return {
            "hidden_layer_sizes": (128, 64, 32),
            "learning_rate": 0.0001,
            "epochs": 100,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 256
        }

def run_mnist_pseudo_labeling_app():
    # Thi·∫øt l·∫≠p MLflow
    mlflow_tracking_uri = "https://dagshub.com/huykibo/streamlit_mlflow.mlflow"
    try:
        os.environ["MLFLOW_TRACKING_USERNAME"] = st.secrets["mlflow"]["MLFLOW_TRACKING_USERNAME"]
        os.environ["MLFLOW_TRACKING_PASSWORD"] = st.secrets["mlflow"]["MLFLOW_TRACKING_PASSWORD"]
        mlflow.set_tracking_uri(mlflow_tracking_uri)
    except KeyError as e:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y kh√≥a {e} trong st.secrets.")
        st.stop()

    try:
        response = requests.get(mlflow_tracking_uri, timeout=5)
        if response.status_code != 200:
            st.error(f"K·∫øt n·ªëi MLflow th·∫•t b·∫°i. M√£ tr·∫°ng th√°i: {response.status_code}.")
            st.stop()
    except requests.exceptions.RequestException as e:
        st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi MLflow: {e}.")
        st.stop()

    EXPERIMENT_ID = "6"
    try:
        client = MlflowClient()
        experiment = client.get_experiment(EXPERIMENT_ID)
        if experiment is None:
            st.error(f"Experiment ID {EXPERIMENT_ID} kh√¥ng t·ªìn t·∫°i.")
            st.stop()
    except Exception as e:
        st.error(f"L·ªói truy xu·∫•t Experiment ID {EXPERIMENT_ID}: {e}.")
        st.stop()

    st.title("Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Neural Network v√† Pseudo-Labeling")

    # CSS t√πy ch·ªânh
    st.markdown("""
        <style>
            .tooltip {
                position: relative;
                display: inline-block;
                cursor: pointer;
                color: #1f77b4;
                font-weight: bold;
                margin-left: 5px;
            }
            .tooltip .tooltiptext {
                visibility: hidden;
                width: 400px;
                background-color: #f9f9f9;
                color: #333;
                text-align: left;
                border-radius: 6px;
                padding: 10px;
                position: absolute;
                z-index: 1;
                right: 105%;
                top: 50%;
                transform: translateY(-50%);
                opacity: 0;
                transition: opacity 0.3s;
                border: 1px solid #ccc;
                font-size: 0.9em;
                line-height: 1.4;
            }
            .tooltip:hover .tooltiptext {
                visibility: visible;
                opacity: 1;
            }
            .section-title {
                font-size: 1.5em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 10px;
            }
            .info-box {
                background-color: #f8f9fa;
                padding: 10px;
                border-left: 4px solid #3498db;
                margin-bottom: 15px;
            }
            .action-container {
                background-color: #ffffff;
                padding: 15px;
                border-radius: 5px;
                box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
                margin-bottom: 20px;
            }
            .prediction-box {
                margin-top: 10px;
                padding: 10px;
                border: 1px solid #ccc;
                border-radius: 5px;
                background-color: #f9f9f9;
            }
            .mode-title {
                font-size: 1.2em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 10px;
            }
            .stCanvas {
                border: 1px solid #ddd;
                border-radius: 5px;
            }
        </style>
    """, unsafe_allow_html=True)

    tabs = st.tabs(["Th√¥ng tin", "T·∫£i d·ªØ li·ªáu", "X·ª≠ l√Ω d·ªØ li·ªáu", "Chia d·ªØ li·ªáu", "Hu·∫•n luy·ªán/ƒê√°nh gi√°", "Demo d·ª± ƒëo√°n", "Th√¥ng tin hu·∫•n luy·ªán"])
    tab_info, tab_load, tab_preprocess, tab_split, tab_train_eval, tab_demo, tab_log_info = tabs

    # Tab 1: Th√¥ng tin
    with tab_info:
        st.header("Gi·ªõi thi·ªáu ·ª®ng d·ª•ng Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Neural Network v√† Pseudo-Labeling")
        st.markdown("""
        Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay t·ª´ t·∫≠p d·ªØ li·ªáu **MNIST** s·ª≠ d·ª•ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)** k·∫øt h·ª£p v·ªõi k·ªπ thu·∫≠t **Pseudo-Labeling**. ·ª®ng d·ª•ng n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ cung c·∫•p tr·∫£i nghi·ªám tr·ª±c quan, h·ªó tr·ª£ h·ªçc t·∫≠p v√† nghi√™n c·ª©u v·ªÅ c√°c thu·∫≠t to√°n h·ªçc m√°y hi·ªán ƒë·∫°i.
        """, unsafe_allow_html=True)

        st.subheader("Ch·ªçn n·ªôi dung ƒë·ªÉ kh√°m ph√°")
        info_option = st.selectbox(
            "",
            [
                "T·ªïng quan v·ªÅ ·ª©ng d·ª•ng v√† m·ª•c ti√™u",
                "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a",
                "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o",
                "Pseudo-Labeling ‚Äì K·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t"
            ],
            label_visibility="collapsed",
            help="Kh√°m ph√° chi ti·∫øt v·ªÅ ·ª©ng d·ª•ng, d·ªØ li·ªáu, m√¥ h√¨nh v√† k·ªπ thu·∫≠t Pseudo-Labeling."
        )

        if info_option == "T·ªïng quan v·ªÅ ·ª©ng d·ª•ng v√† m·ª•c ti√™u":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                    time.sleep(0.05)
                st.subheader("üìå T·ªïng quan v·ªÅ ·ª©ng d·ª•ng v√† m·ª•c ti√™u")
                st.markdown("""
                ·ª®ng d·ª•ng n√†y t·∫≠p trung v√†o vi·ªác ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu **MNIST**, m·ªôt b·ªô d·ªØ li·ªáu ti√™u chu·∫©n trong lƒ©nh v·ª±c h·ªçc m√°y. K·∫øt h·ª£p **Neural Network** v√† **Pseudo-Labeling**, ·ª©ng d·ª•ng kh√¥ng ch·ªâ t·ªëi ∆∞u h√≥a hi·ªáu su·∫•t m√¥ h√¨nh m√† c√≤n t·∫≠n d·ª•ng d·ªØ li·ªáu kh√¥ng c√≥ nh√£n ƒë·ªÉ n√¢ng cao kh·∫£ nƒÉng h·ªçc t·∫≠p.

                **M·ª•c ti√™u ch√≠nh:**
                - Ph√°t tri·ªÉn m·ªôt m√¥ h√¨nh Neural Network c√≥ kh·∫£ nƒÉng nh·∫≠n di·ªán ch√≠nh x√°c c√°c ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9.
                - √Åp d·ª•ng k·ªπ thu·∫≠t Pseudo-Labeling ƒë·ªÉ khai th√°c d·ªØ li·ªáu kh√¥ng c√≥ nh√£n, m√¥ ph·ªèng c√°c t√¨nh hu·ªëng th·ª±c t·∫ø khi d·ªØ li·ªáu c√≥ nh√£n h·∫°n ch·∫ø.
                - Cung c·∫•p giao di·ªán tr·ª±c quan ƒë·ªÉ ng∆∞·ªùi d√πng th·ª±c h√†nh, ƒë√°nh gi√° v√† t√πy ch·ªânh m√¥ h√¨nh.

                **Th√¥ng tin c∆° b·∫£n v·ªÅ d·ªØ li·ªáu:**
                - **Quy m√¥:** 70,000 ·∫£nh, m·ªói ·∫£nh k√≠ch th∆∞·ªõc 28x28 pixel (t·ªïng c·ªông 784 ƒë·∫∑c tr∆∞ng).
                - **ƒê·∫∑c tr∆∞ng:** Gi√° tr·ªã pixel t·ª´ 0 ƒë·∫øn 255, bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng vector 784 chi·ªÅu.
                - **Nhi·ªám v·ª•:** D·ª± ƒëo√°n nh√£n t∆∞∆°ng ·ª©ng v·ªõi t·ª´ng ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9.
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                    time.sleep(0.05)
                st.subheader("üìå T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a")
                st.markdown("""
                **MNIST** l√† m·ªôt t·∫≠p d·ªØ li·ªáu ti√™u chu·∫©n trong h·ªçc m√°y, ƒë∆∞·ª£c ph√°t tri·ªÉn b·ªüi Yann LeCun v√† c√°c c·ªông s·ª±, th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh ph√¢n lo·∫°i.

                **ƒê·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t:**
                - **Ngu·ªìn g·ªëc:** Bao g·ªìm ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ h·ªçc sinh trung h·ªçc v√† nh√¢n vi√™n ƒëi·ªÅu tra d√¢n s·ªë Hoa K·ª≥.
                - **K√≠ch th∆∞·ªõc:** M·ªói ·∫£nh c√≥ ƒë·ªô ph√¢n gi·∫£i 28x28 pixel, thang ƒë·ªô x√°m v·ªõi gi√° tr·ªã t·ª´ 0 ƒë·∫øn 255.
                - **Quy m√¥:** T·ªïng c·ªông 70,000 ·∫£nh, chia th√†nh t·∫≠p hu·∫•n luy·ªán (60,000 ·∫£nh) v√† t·∫≠p ki·ªÉm tra (10,000 ·∫£nh).

                **√ù nghƒ©a:**
                - L√† n·ªÅn t·∫£ng l√Ω t∆∞·ªüng ƒë·ªÉ th·ª≠ nghi·ªám c√°c thu·∫≠t to√°n h·ªçc m√°y, t·ª´ c∆° b·∫£n ƒë·∫øn n√¢ng cao.
                - Gi√∫p ƒë√°nh gi√° kh·∫£ nƒÉng ph√¢n bi·ªát c√°c l·ªõp t∆∞∆°ng t·ª± (v√≠ d·ª•: 4 v√† 9) trong c√°c m√¥ h√¨nh Neural Network.
                - H·ªó tr·ª£ nghi√™n c·ª©u v√† ƒë√†o t·∫°o cho c·∫£ ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu l·∫´n c√°c chuy√™n gia trong lƒ©nh v·ª±c h·ªçc s√¢u.
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìä Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o")
                st.markdown("""
                **Neural Network (M·∫°ng n∆°-ron nh√¢n t·∫°o)** l√† m·ªôt m√¥ h√¨nh h·ªçc m√°y m√¥ ph·ªèng c√°ch ho·∫°t ƒë·ªông c·ªßa m·∫°ng n∆°-ron sinh h·ªçc trong n√£o ng∆∞·ªùi. N√≥ ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ h·ªçc c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu, ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ v·ªõi b√†i to√°n nh·∫≠n di·ªán h√¨nh ·∫£nh nh∆∞ MNIST.

                **C·∫•u tr√∫c c∆° b·∫£n:**
                - **L·ªõp ƒë·∫ßu v√†o (Input Layer)**: Nh·∫≠n d·ªØ li·ªáu th√¥ (784 pixel t·ª´ ·∫£nh MNIST).
                - **L·ªõp ·∫©n (Hidden Layers)**: X·ª≠ l√Ω th√¥ng tin qua c√°c ph√©p t√≠nh tuy·∫øn t√≠nh v√† phi tuy·∫øn.
                - **L·ªõp ƒë·∫ßu ra (Output Layer)**: ƒê∆∞a ra d·ª± ƒëo√°n (10 l·ªõp, t·ª´ 0-9).

                **Quy tr√¨nh ho·∫°t ƒë·ªông:**
                - **Lan truy·ªÅn thu·∫≠n**: T√≠nh to√°n d·ª± ƒëo√°n t·ª´ ƒë·∫ßu v√†o qua c√°c l·ªõp.
                - **T√≠nh h√†m m·∫•t m√°t**: ƒêo ƒë·ªô sai l·ªách gi·ªØa d·ª± ƒëo√°n v√† nh√£n th·ª±c t·∫ø.
                - **Lan truy·ªÅn ng∆∞·ª£c**: C·∫≠p nh·∫≠t tr·ªçng s·ªë ƒë·ªÉ gi·∫£m m·∫•t m√°t.

                **∆Øu ƒëi·ªÉm:**
                - H·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p t·ª´ d·ªØ li·ªáu h√¨nh ·∫£nh.
                - Linh ho·∫°t v·ªõi nhi·ªÅu tham s·ªë ƒë·ªÉ t·ªëi ∆∞u h√≥a.

                **Nh∆∞·ª£c ƒëi·ªÉm:**
                - T·ªën th·ªùi gian hu·∫•n luy·ªán v·ªõi d·ªØ li·ªáu l·ªõn.
                - Y√™u c·∫ßu ƒëi·ªÅu ch·ªânh tham s·ªë c·∫©n th·∫≠n.
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "Pseudo-Labeling ‚Äì K·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i n·ªôi dung... {i}%")
                    time.sleep(0.05)
                st.subheader("üìå Pseudo-Labeling ‚Äì K·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t")
                st.markdown("""
                **Pseudo-Labeling** l√† m·ªôt ph∆∞∆°ng ph√°p h·ªçc b√°n gi√°m s√°t gi√∫p t·∫≠n d·ª•ng c·∫£ d·ªØ li·ªáu c√≥ nh√£n v√† kh√¥ng c√≥ nh√£n ƒë·ªÉ n√¢ng cao hi·ªáu su·∫•t m√¥ h√¨nh, ƒë·∫∑c bi·ªát khi d·ªØ li·ªáu c√≥ nh√£n khan hi·∫øm. K·ªπ thu·∫≠t n√†y s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n nh√£n gi·∫£ (pseudo-labels) cho d·ªØ li·ªáu kh√¥ng c√≥ nh√£n, sau ƒë√≥ k·∫øt h·ª£p ch√∫ng v√†o qu√° tr√¨nh hu·∫•n luy·ªán.

                **C√°c b∆∞·ªõc th·ª±c hi·ªán:**
                1. L·∫•y 1% d·ªØ li·ªáu c√≥ nh√£n ban ƒë·∫ßu t·ª´ m·ªói l·ªõp (0-9).
                2. Hu·∫•n luy·ªán m√¥ h√¨nh Neural Network tr√™n t·∫≠p d·ªØ li·ªáu ban ƒë·∫ßu.
                3. D·ª± ƒëo√°n nh√£n cho d·ªØ li·ªáu kh√¥ng c√≥ nh√£n.
                4. G√°n nh√£n gi·∫£ cho c√°c d·ª± ƒëo√°n c√≥ ƒë·ªô tin c·∫≠y cao (threshold m·∫∑c ƒë·ªãnh = 0.95).
                5. Hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh v·ªõi t·∫≠p d·ªØ li·ªáu m·ªõi (bao g·ªìm nh√£n th·∫≠t v√† nh√£n gi·∫£).
                6. L·∫∑p l·∫°i c√°c b∆∞·ªõc 3-5 cho ƒë·∫øn khi ƒë·∫°t s·ªë v√≤ng l·∫∑p t·ªëi ƒëa ho·∫∑c kh√¥ng c√≤n d·ªØ li·ªáu kh√¥ng nh√£n.

                **L·ª£i √≠ch:**
                - T·ªëi ∆∞u h√≥a hi·ªáu su·∫•t khi d·ªØ li·ªáu c√≥ nh√£n h·∫°n ch·∫ø.
                - Gi·∫£m chi ph√≠ g·∫Øn nh√£n th·ªß c√¥ng.

                **Th√°ch th·ª©c:**
                - Nh√£n gi·∫£ c√≥ th·ªÉ ch·ª©a nhi·ªÖu n·∫øu m√¥ h√¨nh ban ƒë·∫ßu kh√¥ng ch√≠nh x√°c.
                - Y√™u c·∫ßu ƒëi·ªÅu ch·ªânh ng∆∞·ª°ng tin c·∫≠y h·ª£p l√Ω ƒë·ªÉ c√¢n b·∫±ng ch·∫•t l∆∞·ª£ng v√† s·ªë l∆∞·ª£ng nh√£n gi·∫£.
                """, unsafe_allow_html=True)

                st.subheader("‚öôÔ∏è C√°c Tham s·ªë S·ª≠ d·ª•ng trong Hu·∫•n luy·ªán v·ªõi Pseudo-Labeling")
                st.markdown("""
                Trong qu√° tr√¨nh hu·∫•n luy·ªán v·ªõi Pseudo-Labeling, c√°c tham s·ªë sau ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ t·ªëi ∆∞u h√≥a m√¥ h√¨nh Neural Network. C√°c tham s·ªë n√†y c√≥ th·ªÉ ƒë∆∞·ª£c t√πy ch·ªânh trong tab **Hu·∫•n luy·ªán/ƒê√°nh gi√°**:

                - **S·ªë l·ªõp ·∫©n (Number of Hidden Layers)**: 1-3 (m·∫∑c ƒë·ªãnh: d·ª±a v√†o s·ªë m·∫´u).  
                - **S·ªë n∆°-ron m·ªói l·ªõp (Hidden Layer Sizes)**: 16-128 (m·∫∑c ƒë·ªãnh: d·ª±a v√†o s·ªë m·∫´u).  
                - **T·ªëc ƒë·ªô h·ªçc (Learning Rate)**: 0.01-0.0001 (m·∫∑c ƒë·ªãnh: d·ª±a v√†o s·ªë m·∫´u).  
                - **S·ªë l·∫ßn l·∫∑p m·ªói v√≤ng (Epochs)**: 10-100 (m·∫∑c ƒë·ªãnh: d·ª±a v√†o s·ªë m·∫´u).  
                - **K√≠ch th∆∞·ªõc batch (Batch Size)**: 32-256 (m·∫∑c ƒë·ªãnh: d·ª±a v√†o s·ªë m·∫´u).  
                - **H√†m k√≠ch ho·∫°t (Activation Function)**: ReLU, Sigmoid, Tanh (m·∫∑c ƒë·ªãnh: ReLU).  
                - **Tr√¨nh t·ªëi ∆∞u (Solver)**: Adam, SGD (m·∫∑c ƒë·ªãnh: Adam).  
                - **Ng∆∞·ª°ng tin c·∫≠y (Confidence Threshold)**: 0.5-1.0 (m·∫∑c ƒë·ªãnh: 0.95).  
                - **S·ªë v√≤ng l·∫∑p t·ªëi ƒëa (Max Iterations)**: 1-10 (m·∫∑c ƒë·ªãnh: 5).  
                """, unsafe_allow_html=True)

                st.subheader("‚≠ê G·ª£i √Ω Tham s·ªë T·ªëi ∆∞u Nh·∫•t cho B√†i to√°n MNIST")
                st.markdown("""
                D·ª±a tr√™n ƒë·∫∑c ƒëi·ªÉm c·ªßa t·∫≠p d·ªØ li·ªáu MNIST (70,000 m·∫´u, 10 l·ªõp, ·∫£nh 28x28), tham s·ªë t·ªëi ∆∞u ƒë∆∞·ª£c ƒë·ªÅ xu·∫•t l√† c·∫•u h√¨nh cho d·ªØ li·ªáu l·ªõn (> 50,000 m·∫´u) ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t cao nh·∫•t v·ªõi Pseudo-Labeling:
                - **S·ªë l·ªõp ·∫©n**: 3  
                - **S·ªë n∆°-ron m·ªói l·ªõp**: (128, 64, 32)  
                - **T·ªëc ƒë·ªô h·ªçc**: 0.0001  
                - **S·ªë l·∫ßn l·∫∑p m·ªói v√≤ng**: 100  
                - **K√≠ch th∆∞·ªõc batch**: 256  
                - **H√†m k√≠ch ho·∫°t**: ReLU  
                - **Tr√¨nh t·ªëi ∆∞u**: Adam  
                - **Ng∆∞·ª°ng tin c·∫≠y**: 0.95  
                - **S·ªë v√≤ng l·∫∑p t·ªëi ƒëa**: 5  

                **L√Ω do ch·ªçn:**
                - MNIST c√≥ s·ªë l∆∞·ª£ng m·∫´u l·ªõn v√† ƒë·∫∑c tr∆∞ng ph·ª©c t·∫°p, c·∫ßn m·∫°ng s√¢u (3 l·ªõp ·∫©n) v·ªõi s·ªë n∆°-ron gi·∫£m d·∫ßn ƒë·ªÉ h·ªçc t·ªët c√°c ƒë·∫∑c tr∆∞ng.
                - T·ªëc ƒë·ªô h·ªçc nh·ªè (0.0001) v√† s·ªë l·∫ßn l·∫∑p l·ªõn (100) ƒë·∫£m b·∫£o h·ªôi t·ª• ·ªïn ƒë·ªãnh.
                - Ng∆∞·ª°ng 0.95 ƒë·∫£m b·∫£o nh√£n gi·∫£ c√≥ ƒë·ªô tin c·∫≠y cao, gi·∫£m nhi·ªÖu.
                """, unsafe_allow_html=True)

                if 'data' in st.session_state:
                    X, _ = st.session_state['data']
                    num_samples = len(X)
                    optimal_params = get_optimal_params(num_samples)
                    st.markdown(f"""
                    **Tham s·ªë t·ªëi ∆∞u t·ª± ƒë·ªông ch·ªçn cho {num_samples} m·∫´u ƒë√£ t·∫£i:**
                    - **S·ªë l·ªõp ·∫©n**: {len(optimal_params['hidden_layer_sizes'])}  
                    - **S·ªë n∆°-ron m·ªói l·ªõp**: {optimal_params['hidden_layer_sizes']}  
                    - **T·ªëc ƒë·ªô h·ªçc**: {optimal_params['learning_rate']}  
                    - **S·ªë l·∫ßn l·∫∑p m·ªói v√≤ng**: {optimal_params['epochs']}  
                    - **K√≠ch th∆∞·ªõc batch**: {optimal_params['batch_size']}  
                    - **H√†m k√≠ch ho·∫°t**: {optimal_params['activation']}  
                    - **Tr√¨nh t·ªëi ∆∞u**: {optimal_params['solver']}  
                    - **Ng∆∞·ª°ng tin c·∫≠y**: 0.95 (khuy·∫øn ngh·ªã)  
                    - **S·ªë v√≤ng l·∫∑p t·ªëi ƒëa**: 5 (khuy·∫øn ngh·ªã)  
                    """, unsafe_allow_html=True)
                else:
                    st.info("Vui l√≤ng ch·ªçn s·ªë l∆∞·ª£ng m·∫´u trong tab 'T·∫£i d·ªØ li·ªáu' ƒë·ªÉ xem tham s·ªë t·ªëi ∆∞u t·ª± ƒë·ªông.")

                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

    # Tab 2: T·∫£i d·ªØ li·ªáu
    with tab_load:
        st.markdown('<div class="section-title">T·∫£i D·ªØ li·ªáu</div>', unsafe_allow_html=True)

        if 'full_data' not in st.session_state:
            if st.button("T·∫£i d·ªØ li·ªáu MNIST", type="primary"):
                with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu MNIST..."):
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    try:
                        (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()
                        for i in range(0, 101, 20):
                            progress_bar.progress(i)
                            status_text.text(f"ƒêang t·∫£i d·ªØ li·ªáu... {i}%")
                            time.sleep(0.1)
                        X = np.concatenate([X_train, X_test], axis=0)
                        y = np.concatenate([y_train, y_test], axis=0)
                        X = X.reshape(-1, 784).astype(np.float64)
                        y = y.astype(np.int32)
                        st.session_state['full_data'] = (X, y)
                        progress_bar.progress(100)
                        status_text.text("ƒê√£ t·∫£i xong! 100%")
                        st.success("ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng!")
                        st.write(f"K√≠ch th∆∞·ªõc d·ªØ li·ªáu: {X.shape[0]} m·∫´u, m·ªói m·∫´u {X.shape[1]} ƒë·∫∑c tr∆∞ng")
                        time.sleep(0.5)
                        status_text.empty()
                        progress_bar.empty()
                        st.rerun()
                    except Exception as e:
                        st.error(f"L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        else:
            X_full, y_full = st.session_state['full_data']
            st.subheader("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u")
            col1, col_center, col2 = st.columns([2, 1, 2])
            with col1:
                sample_options = {
                    "1000 m·∫´u (Th·ª≠ nghi·ªám nhanh)": 1000,
                    "10,000 m·∫´u (Ki·ªÉm tra c∆° b·∫£n)": 10000,
                    "50,000 m·∫´u (C√¢n b·∫±ng hi·ªáu su·∫•t)": 50000,
                    "70,000 m·∫´u (Hu·∫•n luy·ªán chuy√™n s√¢u)": 70000
                }
                selected_option = st.selectbox("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u:", list(sample_options.keys()))
                num_samples = min(sample_options[selected_option], len(X_full))

                if st.button("X√°c nh·∫≠n s·ªë l∆∞·ª£ng (t√πy ch·ªçn c√≥ s·∫µn)", type="primary"):
                    with st.spinner(f"ƒêang l·∫•y {num_samples} m·∫´u..."):
                        indices = np.random.choice(len(X_full), size=num_samples, replace=False)
                        X_sampled = X_full[indices]
                        y_sampled = y_full[indices]
                        st.session_state['data'] = (X_sampled.copy(), y_sampled.copy())
                        st.session_state['optimal_params'] = get_optimal_params(num_samples)
                        with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name="Data_Sample"):
                            mlflow.log_param("num_samples", num_samples)
                        st.success(f"ƒê√£ ch·ªçn {num_samples} m·∫´u!")
                        del X_sampled, y_sampled
                        gc.collect()

            with col_center:
                st.markdown("<h3 style='text-align: center; margin-top: 30px;'>ho·∫∑c</h3>", unsafe_allow_html=True)

            with col2:
                custom_num_samples = st.number_input("Nh·∫≠p s·ªë l∆∞·ª£ng t√πy √Ω (t·ªëi ƒëa 70,000):", min_value=1, max_value=70000, value=1000, step=100)
                if st.button("X√°c nh·∫≠n s·ªë l∆∞·ª£ng (t√πy √Ω)", type="primary"):
                    if custom_num_samples <= len(X_full):
                        with st.spinner(f"ƒêang l·∫•y {custom_num_samples} m·∫´u..."):
                            indices = np.random.choice(len(X_full), size=custom_num_samples, replace=False)
                            X_sampled = X_full[indices]
                            y_sampled = y_full[indices]
                            st.session_state['data'] = (X_sampled.copy(), y_sampled.copy())
                            st.session_state['optimal_params'] = get_optimal_params(custom_num_samples)
                            with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name="Data_Sample_Custom"):
                                mlflow.log_param("num_samples", custom_num_samples)
                            st.success(f"ƒê√£ ch·ªçn {custom_num_samples} m·∫´u!")
                            del X_sampled, y_sampled
                            gc.collect()
                    else:
                        st.error("S·ªë l∆∞·ª£ng m·∫´u v∆∞·ª£t qu√° d·ªØ li·ªáu hi·ªán c√≥!")

    # Tab 3: X·ª≠ l√Ω d·ªØ li·ªáu
    with tab_preprocess:
        st.markdown('<div class="section-title">X·ª≠ l√Ω D·ªØ li·ªáu</div>', unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui l√≤ng ch·ªçn s·ªë l∆∞·ª£ng m·∫´u tr∆∞·ªõc.")
        else:
            X, y = st.session_state['data']
            if "data_original" not in st.session_state:
                st.session_state["data_original"] = (X.copy(), y.copy())

            st.subheader("D·ªØ li·ªáu G·ªëc")
            fig, axes = plt.subplots(2, 5, figsize=(10, 4))
            for i, ax in enumerate(axes.flat):
                ax.imshow(X[i].reshape(28, 28), cmap='gray')
                ax.set_title(f"Label: {y[i]}")
                ax.axis("off")
            st.pyplot(fig)
            plt.close(fig)

            col1, col2 = st.columns([3, 1])
            with col1:
                if st.button("Chu·∫©n h√≥a d·ªØ li·ªáu (Normalization)", type="primary"):
                    with st.spinner("ƒêang chu·∫©n h√≥a d·ªØ li·ªáu v·ªÅ [0, 1]..."):
                        X_norm = X / 255.0
                        st.session_state["data_processed"] = (X_norm.copy(), y.copy())
                        st.success("ƒê√£ x·ª≠ l√Ω d·ªØ li·ªáu!")
                        del X_norm
                        gc.collect()
                        st.rerun()
            with col2:
                st.markdown("""
                    <div class="tooltip">? (Norm)
                        <span class="tooltiptext">
                            ƒê∆∞a d·ªØ li·ªáu v·ªÅ $[0, 1]$ b·∫±ng c√°ch chia cho $255$.<br>
                            C√¥ng d·ª•ng: ƒê·∫£m b·∫£o thang ƒëo ƒë·ªìng nh·∫•t cho Neural Network.
                        </span>
                    </div>
                """, unsafe_allow_html=True)

            if "data_processed" in st.session_state:
                X_processed, y_processed = st.session_state["data_processed"]
                st.success("ƒê√£ x·ª≠ l√Ω d·ªØ li·ªáu!")

    # Tab 4: Chia d·ªØ li·ªáu
    with tab_split:
        st.markdown('<div class="section-title">Chia T·∫≠p D·ªØ li·ªáu</div>', unsafe_allow_html=True)

        if 'data' not in st.session_state:
            st.info("Vui l√≤ng ch·ªçn v√† x·ª≠ l√Ω d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            data_source = st.session_state.get('data_processed', st.session_state['data'])
            X, y = data_source
            total_samples = len(X)
            st.write(f"T·ªïng s·ªë m·∫´u: {total_samples}")

            test_pct = st.slider("T·ª∑ l·ªá Test (%)", 0, 50, 20)
            test_size = test_pct / 100
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)

            st.write(f"**Ph√¢n b·ªï d·ªØ li·ªáu**: Train: {len(X_train)}, Test: {len(X_test)}")
            if st.button("X√°c nh·∫≠n ph√¢n chia", type="primary"):
                with st.spinner("ƒêang chia d·ªØ li·ªáu..."):
                    st.session_state['split_data'] = {
                        "X_train": X_train.copy(), "y_train": y_train.copy(),
                        "X_test": X_test.copy(), "y_test": y_test.copy()
                    }
                    st.success("ƒê√£ chia d·ªØ li·ªáu th√†nh c√¥ng!")
                    del X_train, X_test, y_train, y_test
                    gc.collect()

    # Tab 5: Hu·∫•n luy·ªán/ƒê√°nh gi√°
    with tab_train_eval:
        st.markdown('<div class="section-title">Hu·∫•n luy·ªán v√† ƒê√°nh gi√° M√¥ h√¨nh v·ªõi Pseudo-Labeling</div>', unsafe_allow_html=True)

        if 'split_data' not in st.session_state:
            st.info("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            split_data = st.session_state['split_data'].copy()
            X_train_full = split_data["X_train"]
            y_train_full = split_data["y_train"]
            X_test = split_data["X_test"]
            y_test = split_data["y_test"]

            X_train_full = np.array(X_train_full, dtype=np.float32)
            y_train_full = np.array(y_train_full, dtype=np.int32)
            X_test = np.array(X_test, dtype=np.float32)
            y_test = np.array(y_test, dtype=np.int32)

            if np.any(np.isnan(X_train_full)) or np.any(np.isnan(y_train_full)):
                st.error("D·ªØ li·ªáu hu·∫•n luy·ªán ch·ª©a gi√° tr·ªã NaN. ƒêang x·ª≠ l√Ω...")
                X_train_full = np.nan_to_num(X_train_full, nan=0.0)
                y_train_full = np.nan_to_num(y_train_full, nan=0.0)
                st.success("ƒê√£ thay th·∫ø NaN b·∫±ng 0 trong d·ªØ li·ªáu hu·∫•n luy·ªán!")

            num_samples = len(X_train_full)
            st.write(f"**T·ªïng s·ªë m·∫´u hu·∫•n luy·ªán ban ƒë·∫ßu**: {num_samples}")

            # B∆∞·ªõc 1: L·∫•y 1% s·ªë l∆∞·ª£ng ·∫£nh cho m·ªói class (0-9)
            st.subheader("B∆∞·ªõc 1: T·∫°o t·∫≠p d·ªØ li·ªáu ban ƒë·∫ßu (1% m·ªói l·ªõp)")
            classes = np.unique(y_train_full)
            X_train_initial = []
            y_train_initial = []
            X_unlabeled = []
            y_unlabeled_indices = []

            for cls in classes:
                cls_indices = np.where(y_train_full == cls)[0]
                num_cls_samples = len(cls_indices)
                num_initial = max(1, int(0.01 * num_cls_samples))  # L·∫•y 1% m·ªói l·ªõp
                initial_indices = np.random.choice(cls_indices, num_initial, replace=False)
                unlabeled_indices = np.setdiff1d(cls_indices, initial_indices)

                X_train_initial.append(X_train_full[initial_indices])
                y_train_initial.append(y_train_full[initial_indices])
                X_unlabeled.append(X_train_full[unlabeled_indices])
                y_unlabeled_indices.extend(unlabeled_indices)

            X_train_initial = np.concatenate(X_train_initial, axis=0)
            y_train_initial = np.concatenate(y_train_initial, axis=0)
            X_unlabeled = np.concatenate(X_unlabeled, axis=0)

            st.write(f"**T·∫≠p d·ªØ li·ªáu ban ƒë·∫ßu (1%)**: {len(X_train_initial)} m·∫´u")
            st.write(f"**T·∫≠p d·ªØ li·ªáu ch∆∞a g·∫Øn nh√£n (99%)**: {len(X_unlabeled)} m·∫´u")

            st.session_state['pseudo_data'] = {
                'X_train_initial': X_train_initial.copy(),
                'y_train_initial': y_train_initial.copy(),
                'X_unlabeled': X_unlabeled.copy(),
                'y_unlabeled_indices': y_unlabeled_indices,
                'X_test': X_test.copy(),
                'y_test': y_test.copy()
            }

            if "optimal_params" not in st.session_state:
                st.session_state["optimal_params"] = get_optimal_params(len(X_train_initial))
            
            params = st.session_state.get("training_params", st.session_state["optimal_params"].copy())

            st.subheader("‚öôÔ∏è C·∫•u h√¨nh Tham s·ªë M√¥ h√¨nh")
            st.info(f"Tham s·ªë t·ªëi ∆∞u t·ª± ƒë·ªông cho {len(X_train_initial)} m·∫´u: {st.session_state['optimal_params']}")

            col_param1, col_param2 = st.columns(2)
            with col_param1:
                num_hidden_layers = st.number_input("S·ªë l·ªõp ·∫©n", min_value=1, max_value=3, value=len(params["hidden_layer_sizes"]))
                hidden_sizes = list(params["hidden_layer_sizes"])
                
                if num_hidden_layers == 1:
                    hidden_size_1 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 1", min_value=16, max_value=128, value=hidden_sizes[0] if hidden_sizes else 32)
                    hidden_sizes = [hidden_size_1]
                elif num_hidden_layers == 2:
                    hidden_size_1 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 1", min_value=16, max_value=128, value=hidden_sizes[0] if hidden_sizes else 64)
                    hidden_size_2 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 2", min_value=16, max_value=128, value=hidden_sizes[1] if len(hidden_sizes) > 1 else 32)
                    hidden_sizes = [hidden_size_1, hidden_size_2]
                elif num_hidden_layers == 3:
                    hidden_size_1 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 1", min_value=16, max_value=128, value=hidden_sizes[0] if hidden_sizes else 128)
                    hidden_size_2 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 2", min_value=16, max_value=128, value=hidden_sizes[1] if len(hidden_sizes) > 1 else 64)
                    hidden_size_3 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 3", min_value=16, max_value=128, value=hidden_sizes[2] if len(hidden_sizes) > 2 else 32)
                    hidden_sizes = [hidden_size_1, hidden_size_2, hidden_size_3]
                
                params["hidden_layer_sizes"] = tuple(hidden_sizes)
                params["activation"] = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "sigmoid", "tanh"], index=["relu", "sigmoid", "tanh"].index(params["activation"]))
            
            with col_param2:
                params["learning_rate"] = st.selectbox("T·ªëc ƒë·ªô h·ªçc", [0.01, 0.005, 0.001, 0.0005, 0.0003, 0.0001], 
                                                       index=[0.01, 0.005, 0.001, 0.0005, 0.0003, 0.0001].index(params["learning_rate"]))
                params["epochs"] = st.number_input("S·ªë l·∫ßn l·∫∑p (Epochs)", min_value=10, max_value=100, value=params["epochs"])
                params["batch_size"] = st.number_input("K√≠ch th∆∞·ªõc batch", min_value=32, max_value=256, value=params["batch_size"])
                params["solver"] = st.selectbox("Tr√¨nh t·ªëi ∆∞u", ["adam", "sgd"], index=["adam", "sgd"].index(params["solver"]))
                threshold = st.slider("Ng∆∞·ª°ng tin c·∫≠y Pseudo-Label", 0.5, 1.0, 0.95)
                max_iterations = st.number_input("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa", min_value=1, max_value=10, value=5)

            col_reset, col_train = st.columns([1, 3])
            with col_reset:
                if st.button("üîÑ Kh√¥i ph·ª•c tham s·ªë t·ªëi ∆∞u"):
                    st.session_state["training_params"] = st.session_state["optimal_params"].copy()
                    st.success("ƒê√£ kh√¥i ph·ª•c tham s·ªë t·ªëi ∆∞u!")
                    st.rerun()

            st.session_state["training_params"] = params

            with col_train:
                if st.button("üöÄ B·∫Øt ƒë·∫ßu Hu·∫•n luy·ªán v·ªõi Pseudo-Labeling", type="primary"):
                    with st.spinner("ƒêang th·ª±c hi·ªán quy tr√¨nh Pseudo-Labeling..."):
                        start_time = time.time()

                        X_train = st.session_state['pseudo_data']['X_train_initial'].copy()
                        y_train = st.session_state['pseudo_data']['y_train_initial'].copy()
                        X_unlabeled = st.session_state['pseudo_data']['X_unlabeled'].copy()
                        X_test = st.session_state['pseudo_data']['X_test'].copy()
                        y_test = st.session_state['pseudo_data']['y_test'].copy()

                        iteration = 0
                        pseudo_labeled_history = []
                        accuracy_test_history = []

                        while iteration < max_iterations and len(X_unlabeled) > 0:
                            iteration += 1
                            st.write(f"**V√≤ng l·∫∑p {iteration}/{max_iterations}**")

                            model = models.Sequential()
                            model.add(layers.Input(shape=(784,)))
                            for neurons in params["hidden_layer_sizes"]:
                                model.add(layers.Dense(neurons, activation=params["activation"]))
                            model.add(layers.Dense(10, activation='softmax'))

                            optimizer = tf.keras.optimizers.Adam(learning_rate=params["learning_rate"]) if params["solver"] == "adam" else tf.keras.optimizers.SGD(learning_rate=params["learning_rate"])
                            model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

                            progress_bar = st.progress(0)
                            status_text = st.empty()

                            class ProgressCallback(callbacks.Callback):
                                def on_epoch_end(self, epoch, logs=None):
                                    progress = (epoch + 1) / params["epochs"] * 100
                                    progress_bar.progress(int(progress))
                                    status_text.text(f"Epoch {epoch+1}/{params['epochs']}, Loss: {logs['loss']:.4f}, Accuracy: {logs['accuracy']:.4f}")

                            history = model.fit(X_train, y_train, epochs=params["epochs"], batch_size=params["batch_size"], callbacks=[ProgressCallback()], verbose=0)

                            predictions = model.predict(X_unlabeled, verbose=0)
                            predicted_labels = np.argmax(predictions, axis=1)
                            confidences = np.max(predictions, axis=1)

                            pseudo_mask = confidences >= threshold
                            X_pseudo = X_unlabeled[pseudo_mask]
                            y_pseudo = predicted_labels[pseudo_mask]

                            st.write(f"**S·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n gi·∫£ trong v√≤ng {iteration}**: {len(X_pseudo)}")

                            X_train = np.concatenate([X_train, X_pseudo], axis=0)
                            y_train = np.concatenate([y_train, y_pseudo], axis=0)
                            X_unlabeled = X_unlabeled[~pseudo_mask]

                            pseudo_labeled_history.append(len(X_pseudo))
                            y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                            acc_test = accuracy_score(y_test, y_test_pred)
                            accuracy_test_history.append(acc_test)
                            st.write(f"**ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p Test sau v√≤ng {iteration}**: {acc_test*100:.2f}%")

                            tf.keras.backend.clear_session()
                            del model, predictions, predicted_labels, confidences, pseudo_mask, X_pseudo, y_pseudo
                            gc.collect()

                        st.write("**Hu·∫•n luy·ªán l·∫ßn cu·ªëi tr√™n to√†n b·ªô t·∫≠p d·ªØ li·ªáu ƒë√£ g·∫Øn nh√£n**")
                        model = models.Sequential()
                        model.add(layers.Input(shape=(784,)))
                        for neurons in params["hidden_layer_sizes"]:
                            model.add(layers.Dense(neurons, activation=params["activation"]))
                        model.add(layers.Dense(10, activation='softmax'))

                        optimizer = tf.keras.optimizers.Adam(learning_rate=params["learning_rate"]) if params["solver"] == "adam" else tf.keras.optimizers.SGD(learning_rate=params["learning_rate"])
                        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

                        history = model.fit(X_train, y_train, epochs=params["epochs"], batch_size=params["batch_size"], callbacks=[ProgressCallback()], verbose=0)

                        y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                        acc_test = accuracy_score(y_test, y_test_pred)
                        cm_test = confusion_matrix(y_test, y_test_pred)

                        run_name = f"PseudoLabeling_NN_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                        with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=run_name) as run:
                            mlflow.log_params(params)
                            mlflow.log_param("threshold", threshold)
                            mlflow.log_param("max_iterations", max_iterations)
                            mlflow.log_metric("accuracy_test", acc_test)
                            mlflow.log_metric("training_time", time.time() - start_time)
                            mlflow.log_metric("total_iterations", iteration)

                        st.session_state['model'] = model
                        st.session_state['training_results'] = {
                            'accuracy_test': acc_test,
                            'cm_test': cm_test,
                            'run_name': run_name,
                            'run_id': run.info.run_id,
                            'params': params,
                            'training_time': time.time() - start_time,
                            'loss_history': history.history['loss'][-10:],
                            'accuracy_history': history.history['accuracy'][-10:],
                            'pseudo_labeled_history': pseudo_labeled_history,
                            'accuracy_test_history': accuracy_test_history,
                            'total_iterations': iteration
                        }

                        st.success(f"ƒê√£ ho√†n th√†nh Pseudo-Labeling! Th·ªùi gian: {time.time() - start_time:.2f} gi√¢y")
                        tf.keras.backend.clear_session()
                        del X_train, y_train, X_unlabeled, X_test, y_test, history
                        gc.collect()
                        st.rerun()

            if 'training_results' in st.session_state:
                results = st.session_state['training_results']
                st.subheader("üìä K·∫øt qu·∫£ Hu·∫•n luy·ªán")
                col_result1, col_result2, col_result3 = st.columns(3)
                with col_result1:
                    st.metric("Th·ªùi gian hu·∫•n luy·ªán", f"{results['training_time']:.2f} gi√¢y")
                with col_result2:
                    st.metric("ƒê·ªô ch√≠nh x√°c Test", f"{results['accuracy_test']*100:.2f}%")
                with col_result3:
                    st.metric("T·ªïng s·ªë v√≤ng l·∫∑p", f"{results['total_iterations']}")

                st.subheader("üìà Ma tr·∫≠n Nh·∫ßm l·∫´n")
                fig, ax = plt.subplots(figsize=(6, 5))
                sns.heatmap(results['cm_test'], annot=True, fmt="d", cmap="Blues", ax=ax)
                st.pyplot(fig)
                plt.close(fig)

                st.subheader("üìâ Bi·ªÉu ƒë·ªì ƒê√°nh gi√°")
                col_chart1, col_chart2 = st.columns(2)
                with col_chart1:
                    if results['loss_history']:
                        fig, ax = plt.subplots(figsize=(5, 3))
                        ax.plot(range(1, len(results['loss_history']) + 1), results['loss_history'], label='Loss', color='blue')
                        ax.set_xlabel("Epochs")
                        ax.set_ylabel("Loss")
                        ax.set_title("Loss (10 Epochs Cu·ªëi)")
                        ax.grid(True)
                        st.pyplot(fig)
                        plt.close(fig)
                        st.markdown("*Bi·ªÉu ƒë·ªì Loss*: Gi·∫£m d·∫ßn cho th·∫•y m√¥ h√¨nh h·ªçc t·ªët, h·ªôi t·ª• ·ªïn ƒë·ªãnh.")
                    
                    if results['pseudo_labeled_history']:
                        fig, ax = plt.subplots(figsize=(5, 3))
                        ax.plot(range(1, len(results['pseudo_labeled_history']) + 1), results['pseudo_labeled_history'], label='Pseudo-Labeled', color='purple')
                        ax.set_xlabel("Iterations")
                        ax.set_ylabel("S·ªë m·∫´u")
                        ax.set_title("S·ªë m·∫´u Pseudo-Labeled")
                        ax.grid(True)
                        st.pyplot(fig)
                        plt.close(fig)
                        st.markdown("*S·ªë m·∫´u Pseudo-Labeled*: Th·ªÉ hi·ªán l∆∞·ª£ng d·ªØ li·ªáu kh√¥ng nh√£n ƒë∆∞·ª£c g√°n qua t·ª´ng v√≤ng.")

                with col_chart2:
                    if results['accuracy_history']:
                        fig, ax = plt.subplots(figsize=(5, 3))
                        ax.plot(range(1, len(results['accuracy_history']) + 1), results['accuracy_history'], label='Accuracy', color='green')
                        ax.set_xlabel("Epochs")
                        ax.set_ylabel("Accuracy")
                        ax.set_title("Accuracy (10 Epochs Cu·ªëi)")
                        ax.grid(True)
                        st.pyplot(fig)
                        plt.close(fig)
                        st.markdown("*Bi·ªÉu ƒë·ªì Accuracy*: TƒÉng d·∫ßn cho th·∫•y kh·∫£ nƒÉng ph√¢n lo·∫°i c·∫£i thi·ªán.")
                    
                    if results['accuracy_test_history']:
                        fig, ax = plt.subplots(figsize=(5, 3))
                        ax.plot(range(1, len(results['accuracy_test_history']) + 1), results['accuracy_test_history'], label='Test Accuracy', color='red')
                        ax.set_xlabel("Iterations")
                        ax.set_ylabel("Accuracy")
                        ax.set_title("Test Accuracy Qua V√≤ng L·∫∑p")
                        ax.grid(True)
                        st.pyplot(fig)
                        plt.close(fig)
                        st.markdown("*Test Accuracy*: ƒê√°nh gi√° hi·ªáu su·∫•t th·ª±c t·∫ø tr√™n t·∫≠p ki·ªÉm tra.")

    # Tab 6: Demo d·ª± ƒëo√°n
    with tab_demo:
        st.markdown('<div class="section-title">Demo D·ª± ƒëo√°n Ch·ªØ s·ªë</div>', unsafe_allow_html=True)

        if 'split_data' not in st.session_state or 'model' not in st.session_state:
            st.warning("Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc!")
        else:
            model = st.session_state['model']
            input_method = st.selectbox("Ch·ªçn ph∆∞∆°ng th·ª©c nh·∫≠p li·ªáu", ["T·∫£i ·∫£nh l√™n", "D·ªØ li·ªáu Test", "V·∫Ω tr·ª±c ti·∫øp"])
            is_normalized = 'data_processed' in st.session_state

            def preprocess_input(data, is_normalized):
                if not is_normalized:
                    data = data / 255.0
                return data

            if input_method == "T·∫£i ·∫£nh l√™n":
                uploaded_file = st.file_uploader("T·∫£i l√™n h√¨nh ·∫£nh", type=["png", "jpg", "jpeg"])
                if uploaded_file is not None:
                    image = Image.open(uploaded_file).convert('L').resize((28, 28))
                    st.image(image, caption="H√¨nh ·∫£nh ƒë·∫ßu v√†o", width=100)
                    if st.button("D·ª± ƒëo√°n"):
                        image_array = np.array(image, dtype=np.float32).reshape(1, 784)
                        image_processed = preprocess_input(image_array, is_normalized)
                        prediction = model.predict(image_processed, verbose=0)
                        predicted_class = np.argmax(prediction[0])
                        confidence = prediction[0][predicted_class] * 100
                        st.write(f"D·ª± ƒëo√°n: {predicted_class}, ƒê·ªô tin c·∫≠y: {confidence:.2f}%")

            elif input_method == "D·ªØ li·ªáu Test":
                X_test = st.session_state['split_data']["X_test"]
                y_test = st.session_state['split_data']["y_test"]
                idx = st.slider("Ch·ªçn m·∫´u Test", 0, len(X_test) - 1, 0)
                st.image(X_test[idx].reshape(28, 28), caption=f"Nh√£n th·ª±c t·∫ø: {y_test[idx]}", width=100)
                if st.button("D·ª± ƒëo√°n"):
                    sample = X_test[idx].reshape(1, -1)
                    sample_processed = preprocess_input(sample, is_normalized)
                    prediction = model.predict(sample_processed, verbose=0)
                    predicted_class = np.argmax(prediction[0])
                    confidence = prediction[0][predicted_class] * 100
                    st.write(f"D·ª± ƒëo√°n: {predicted_class}, ƒê·ªô tin c·∫≠y: {confidence:.2f}%")

            elif input_method == "V·∫Ω tr·ª±c ti·∫øp":
                canvas_result = st_canvas(
                    stroke_width=20,
                    stroke_color="#FFFFFF",
                    background_color="#000000",
                    height=280,
                    width=280,
                    drawing_mode="freedraw",
                    key="canvas"
                )
                if canvas_result.image_data is not None:
                    image = Image.fromarray(canvas_result.image_data.astype('uint8'), 'RGBA').convert('L').resize((28, 28))
                    st.image(image, caption="H√¨nh v·∫Ω", width=100)
                    if st.button("D·ª± ƒëo√°n"):
                        image_array = np.array(image, dtype=np.float32).reshape(1, 784)
                        image_processed = preprocess_input(image_array, is_normalized)
                        prediction = model.predict(image_processed, verbose=0)
                        predicted_class = np.argmax(prediction[0])
                        confidence = prediction[0][predicted_class] * 100
                        st.write(f"D·ª± ƒëo√°n: {predicted_class}, ƒê·ªô tin c·∫≠y: {confidence:.2f}%")

    # Tab 7: Th√¥ng tin hu·∫•n luy·ªán
    with tab_log_info:
        st.markdown('<div class="section-title">Th√¥ng tin Hu·∫•n luy·ªán</div>', unsafe_allow_html=True)
        if 'training_results' in st.session_state:
            results = st.session_state['training_results']
            st.write(f"T√™n l·∫ßn ch·∫°y: {results['run_name']}")
            st.write(f"ID l·∫ßn ch·∫°y: {results['run_id']}")
            st.write(f"Th·ªùi gian hu·∫•n luy·ªán: {results['training_time']:.2f} gi√¢y")
            st.write(f"ƒê·ªô ch√≠nh x√°c Test: {results['accuracy_test']*100:.2f}%")
            st.write("Tham s·ªë:", results['params'])
        else:
            st.info("Ch∆∞a c√≥ th√¥ng tin hu·∫•n luy·ªán. Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")

if __name__ == "__main__":
    run_mnist_pseudo_labeling_app()