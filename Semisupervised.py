import os
import mlflow
import streamlit as st
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from mlflow.tracking import MlflowClient
from datetime import datetime
import time
import requests
import io
import sys
import tensorflow as tf
from tensorflow.keras import layers, models, callbacks
import gc

# H√†m ch·ªçn tham s·ªë t·ªëi ∆∞u d·ª±a tr√™n s·ªë m·∫´u
def get_optimal_params(num_samples):
    if num_samples <= 1000:
        return {
            "hidden_layer_sizes": (32,),
            "learning_rate": 0.001,
            "epochs": 30,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 32
        }
    elif num_samples <= 10000:
        return {
            "hidden_layer_sizes": (64, 32),
            "learning_rate": 0.0005,
            "epochs": 50,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 64
        }
    elif num_samples <= 50000:
        return {
            "hidden_layer_sizes": (128, 64),
            "learning_rate": 0.0003,
            "epochs": 70,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 128
        }
    else:
        return {
            "hidden_layer_sizes": (128, 64, 32),
            "learning_rate": 0.0001,
            "epochs": 100,
            "activation": "relu",
            "solver": "adam",
            "batch_size": 256
        }

def run_mnist_pseudo_labeling_app():
    # Thi·∫øt l·∫≠p MLflow
    mlflow_tracking_uri = "https://dagshub.com/huykibo/MNIST_Pseudo_Labeling.mlflow"
    try:
        os.environ["MLFLOW_TRACKING_USERNAME"] = st.secrets["mlflow"]["MLFLOW_TRACKING_USERNAME"]
        os.environ["MLFLOW_TRACKING_PASSWORD"] = st.secrets["mlflow"]["MLFLOW_TRACKING_PASSWORD"]
        mlflow.set_tracking_uri(mlflow_tracking_uri)
    except KeyError as e:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y kh√≥a {e} trong st.secrets.")
        st.stop()

    try:
        response = requests.get(mlflow_tracking_uri, timeout=5)
        if response.status_code != 200:
            st.error(f"K·∫øt n·ªëi MLflow th·∫•t b·∫°i. M√£ tr·∫°ng th√°i: {response.status_code}.")
            st.stop()
    except requests.exceptions.RequestException as e:
        st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi MLflow: {e}.")
        st.stop()

    EXPERIMENT_ID = "6"

    st.title("Ph√¢n lo·∫°i Ch·ªØ s·ªë MNIST v·ªõi Pseudo Labeling v√† Neural Network")

    # CSS t√πy ch·ªânh
    st.markdown("""
        <style>
            .tooltip {
                position: relative;
                display: inline-block;
                cursor: pointer;
                color: #1f77b4;
                font-weight: bold;
                margin-left: 5px;
            }
            .tooltip .tooltiptext {
                visibility: hidden;
                width: 400px;
                background-color: #f9f9f9;
                color: #333;
                text-align: left;
                border-radius: 6px;
                padding: 10px;
                position: absolute;
                z-index: 1;
                right: 105%;
                top: 50%;
                transform: translateY(-50%);
                opacity: 0;
                transition: opacity 0.3s;
                border: 1px solid #ccc;
                font-size: 0.9em;
                line-height: 1.4;
            }
            .tooltip:hover .tooltiptext {
                visibility: visible;
                opacity: 1;
            }
            .section-title {
                font-size: 1.5em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 10px;
            }
            .info-box {
                background-color: #f8f9fa;
                padding: 10px;
                border-left: 4px solid #3498db;
                margin-bottom: 15px;
            }
            .action-container {
                background-color: #ffffff;
                padding: 15px;
                border-radius: 5px;
                box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
                margin-bottom: 20px;
            }
            .prediction-box {
                margin-top: 10px;
                padding: 10px;
                border: 1px solid #ccc;
                border-radius: 5px;
                background-color: #f9f9f9;
            }
            .mode-title {
                font-size: 1.2em;
                font-weight: bold;
                color: #2c3e50;
                margin-bottom: 10px;
            }
            .stCanvas {
                border: 1px solid #ddd;
                border-radius: 5px;
            }
        </style>
    """, unsafe_allow_html=True)

    # Th√™m tab "Th√¥ng tin hu·∫•n luy·ªán"
    tabs = st.tabs(["Th√¥ng tin", "T·∫£i v√† Chia D·ªØ li·ªáu", "Pseudo Labeling", "K·∫øt qu·∫£", "Th√¥ng tin hu·∫•n luy·ªán"])
    tab_info, tab_load_split, tab_pseudo_labeling, tab_results, tab_log_info = tabs

    # Tab 1: Th√¥ng tin (ƒë·∫ßy ƒë·ªß nh∆∞ m√£ g·ªëc)
    with tab_info:
        st.header("Gi·ªõi thi·ªáu v·ªÅ ·ª®ng d·ª•ng v√† M·∫°ng Neural Network")
        st.markdown("""
        Ch√†o b·∫°n! ƒê√¢y l√† ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay t·ª´ t·∫≠p d·ªØ li·ªáu **MNIST** b·∫±ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**. H√£y kh√°m ph√° c√°c t√≠nh nƒÉng v√† c√°ch ho·∫°t ƒë·ªông c·ªßa n√≥ nh√©!
        """, unsafe_allow_html=True)

        st.subheader("Ch·ªçn th√¥ng tin ƒë·ªÉ xem")
        info_option = st.selectbox(
            "",
            [
                "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?",
                "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a",
                "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o",
                "Pseudo Labeling ‚Äì G√°n nh√£n gi·∫£",
                "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)"
            ],
            label_visibility="collapsed",
            help="Ch·ªçn ƒë·ªÉ xem chi ti·∫øt v·ªÅ ·ª©ng d·ª•ng, d·ªØ li·ªáu, ho·∫∑c m√¥ h√¨nh."
        )

        if info_option == "·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìò 1. ·ª®ng d·ª•ng n√†y l√† g√¨ v√† m·ª•c ti√™u c·ªßa n√≥?")
                st.markdown("""
                ƒê√¢y l√† m·ªôt ·ª©ng d·ª•ng ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay d·ª±a tr√™n t·∫≠p d·ªØ li·ªáu **MNIST**, s·ª≠ d·ª•ng **M·∫°ng n∆°-ron nh√¢n t·∫°o (Neural Network)**.  
                - **MNIST**: T·∫≠p d·ªØ li·ªáu g·ªìm $70,000$ ·∫£nh ch·ªØ s·ªë t·ª´ $0$ ƒë·∫øn $9$, m·ªói ·∫£nh k√≠ch th∆∞·ªõc $28 \\times 28$ pixel (t·ªïng c·ªông $784$ ƒë·∫∑c tr∆∞ng).  
                - **M·ª•c ti√™u**:  
                  - X√¢y d·ª±ng v√† hu·∫•n luy·ªán m·ªôt m·∫°ng n∆°-ron ƒë·ªÉ nh·∫≠n di·ªán ch√≠nh x√°c c√°c ch·ªØ s·ªë.  
                  - Cung c·∫•p c√¥ng c·ª• tr·ª±c quan ƒë·ªÉ h·ªçc t·∫≠p v√† ƒë√°nh gi√° hi·ªáu qu·∫£ c·ªßa thu·∫≠t to√°n.  
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìò 2. T·∫≠p d·ªØ li·ªáu MNIST: ƒê·∫∑c ƒëi·ªÉm v√† √Ω nghƒ©a")
                st.markdown("""
                **MNIST** l√† t·∫≠p d·ªØ li·ªáu chu·∫©n trong h·ªçc m√°y, ƒë∆∞·ª£c t·∫°o b·ªüi Yann LeCun v√† c√°c c·ªông s·ª±.  
                - **ƒê·∫∑c ƒëi·ªÉm**:  
                  - G·ªìm c√°c ·∫£nh ch·ªØ s·ªë vi·∫øt tay t·ª´ h·ªçc sinh trung h·ªçc v√† nh√¢n vi√™n ƒëi·ªÅu tra d√¢n s·ªë M·ªπ.  
                  - Chu·∫©n h√≥a th√†nh k√≠ch th∆∞·ªõc $28 \\times 28$ pixel, thang ƒë·ªô x√°m (gi√° tr·ªã t·ª´ $0$ ƒë·∫øn $255$).  
                - **√ù nghƒ©a**:  
                  - L√† b√†i to√°n c∆° b·∫£n ƒë·ªÉ ki·ªÉm tra kh·∫£ nƒÉng ph√¢n lo·∫°i c·ªßa c√°c m√¥ h√¨nh h·ªçc m√°y.  
                  - ƒê∆°n gi·∫£n nh∆∞ng ƒë·ªß ph·ª©c t·∫°p ƒë·ªÉ ƒë√°nh gi√° kh·∫£ nƒÉng ph√¢n bi·ªát c√°c l·ªõp t∆∞∆°ng t·ª± (v√≠ d·ª•: "$4$" v√† "$9$").  
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìä 3. Neural Network ‚Äì M·∫°ng n∆°-ron nh√¢n t·∫°o")
                st.markdown("""
                **Neural Network** l√† m·ªôt m√¥ h√¨nh h·ªçc m√°y m√¥ ph·ªèng c√°ch ho·∫°t ƒë·ªông c·ªßa m·∫°ng n∆°-ron sinh h·ªçc trong n√£o ng∆∞·ªùi.  
                - **C·∫•u tr√∫c**:  
                  - **L·ªõp ƒë·∫ßu v√†o**: $784$ pixel t·ª´ ·∫£nh MNIST.  
                  - **L·ªõp ·∫©n**: X·ª≠ l√Ω th√¥ng tin qua c√°c ph√©p t√≠nh tuy·∫øn t√≠nh v√† phi tuy·∫øn.  
                  - **L·ªõp ƒë·∫ßu ra**: D·ª± ƒëo√°n 10 l·ªõp ($0$-$9$).  
                - **Quy tr√¨nh**: Lan truy·ªÅn thu·∫≠n, t√≠nh m·∫•t m√°t, lan truy·ªÅn ng∆∞·ª£c, c·∫≠p nh·∫≠t tr·ªçng s·ªë.  
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "Pseudo Labeling ‚Äì G√°n nh√£n gi·∫£":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìò 4. Pseudo Labeling ‚Äì G√°n Nh√£n Gi·∫£")
                st.markdown("""
                **Pseudo Labeling** l√† k·ªπ thu·∫≠t h·ªçc b√°n gi√°m s√°t, t·∫≠n d·ª•ng d·ªØ li·ªáu ch∆∞a c√≥ nh√£n ƒë·ªÉ c·∫£i thi·ªán m√¥ h√¨nh.  
                - **C√°ch th·ª±c hi·ªán**:  
                  1. Chia t·∫≠p train/test.  
                  2. L·∫•y 1% m·∫´u t·ª´ m·ªói l·ªõp (0-9) l√†m t·∫≠p train ban ƒë·∫ßu.  
                  3. Hu·∫•n luy·ªán Neural Network tr√™n t·∫≠p 1%.  
                  4. D·ª± ƒëo√°n nh√£n cho 99% c√≤n l·∫°i.  
                  5. G√°n nh√£n gi·∫£ v·ªõi ng∆∞·ª°ng (v√≠ d·ª•: 0.95).  
                  6. L·∫∑p l·∫°i t·ª´ b∆∞·ªõc 3 v·ªõi t·∫≠p d·ªØ li·ªáu m·ªõi cho ƒë·∫øn khi g√°n h·∫øt ho·∫∑c ƒë·∫°t s·ªë l·∫ßn l·∫∑p t·ªëi ƒëa.  
                - **∆Øu ƒëi·ªÉm**: TƒÉng c∆∞·ªùng hi·ªáu su·∫•t khi d·ªØ li·ªáu c√≥ nh√£n h·∫°n ch·∫ø.  
                - **Nh∆∞·ª£c ƒëi·ªÉm**: C√≥ th·ªÉ lan truy·ªÅn sai s√≥t n·∫øu nh√£n gi·∫£ kh√¥ng ch√≠nh x√°c.  
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

        elif info_option == "C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)":
            with st.spinner("ƒêang t·∫£i th√¥ng tin..."):
                progress_bar = st.progress(0)
                status_text = st.empty()
                for i in range(0, 101, 10):
                    progress_bar.progress(i)
                    status_text.text(f"ƒêang t·∫£i th√¥ng tin... {i}%")
                    time.sleep(0.05)
                st.subheader("üìò 5. C√¥ng th·ª©c ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c (Accuracy)")
                st.markdown("""
                - **Accuracy** ƒëo t·ª∑ l·ªá d·ª± ƒëo√°n ƒë√∫ng:  
                  $$ \\text{Accuracy} = \\frac{\\text{S·ªë m·∫´u d·ª± ƒëo√°n ƒë√∫ng}}{\\text{T·ªïng s·ªë m·∫´u}} $$  
                - **V√≠ d·ª•**: D·ª± ƒëo√°n ƒë√∫ng $92/100$ ·∫£nh ‚Üí $92\%$.  
                """, unsafe_allow_html=True)
                status_text.text("ƒê√£ t·∫£i xong! 100%")
                time.sleep(0.5)
                status_text.empty()
                progress_bar.empty()

    # Tab 2: T·∫£i v√† Chia D·ªØ li·ªáu
    with tab_load_split:
        st.markdown('<div class="section-title">T·∫£i v√† Chia D·ªØ li·ªáu MNIST</div>', unsafe_allow_html=True)

        if 'data' not in st.session_state:
            if st.button("T·∫£i d·ªØ li·ªáu MNIST", type="primary"):
                with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu..."):
                    (X_train_full, y_train_full), (X_test_full, y_test_full) = tf.keras.datasets.mnist.load_data()
                    X = np.concatenate([X_train_full, X_test_full], axis=0)
                    y = np.concatenate([y_train_full, y_test_full], axis=0)
                    X = X.reshape(-1, 784).astype(np.float32) / 255.0  # Chu·∫©n h√≥a
                    y = y.astype(np.int32)
                    st.session_state['data'] = (X, y)
                    st.success(f"ƒê√£ t·∫£i {X.shape[0]} m·∫´u!")
                    del X_train_full, X_test_full, y_train_full, y_test_full
                    gc.collect()
                    st.rerun()

        if 'data' in st.session_state and 'split_data' not in st.session_state:
            X, y = st.session_state['data']
            test_size = st.slider("T·ª∑ l·ªá Test (%)", 0, 50, 20) / 100
            if st.button("Chia d·ªØ li·ªáu", type="primary"):
                with st.spinner("ƒêang chia d·ªØ li·ªáu..."):
                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
                    st.session_state['split_data'] = {
                        "X_train": X_train, "y_train": y_train,
                        "X_test": X_test, "y_test": y_test
                    }
                    st.success(f"ƒê√£ chia: Train ({len(X_train)} m·∫´u), Test ({len(X_test)} m·∫´u)")
                    del X, y, X_train, X_test, y_train, y_test
                    gc.collect()
                    st.rerun()

        if 'split_data' in st.session_state:
            split_data = st.session_state['split_data']
            st.write(f"T·∫≠p train: {len(split_data['X_train'])} m·∫´u")
            st.write(f"T·∫≠p test: {len(split_data['X_test'])} m·∫´u")

    # Tab 3: Pseudo Labeling
    with tab_pseudo_labeling:
        st.markdown('<div class="section-title">Pseudo Labeling v·ªõi Neural Network</div>', unsafe_allow_html=True)
        if 'split_data' not in st.session_state:
            st.info("Vui l√≤ng t·∫£i v√† chia d·ªØ li·ªáu tr∆∞·ªõc.")
        else:
            split_data = st.session_state['split_data']
            X_train = split_data["X_train"]
            y_train = split_data["y_train"]
            X_test = split_data["X_test"]
            y_test = split_data["y_test"]

            num_samples = len(X_train)
            st.session_state['optimal_params'] = get_optimal_params(num_samples)
            params = st.session_state.get("training_params", st.session_state["optimal_params"].copy())

            st.subheader("‚öôÔ∏è C·∫•u h√¨nh Tham s·ªë M√¥ h√¨nh")
            col_param1, col_param2 = st.columns(2)
            with col_param1:
                with st.expander("üß† C·∫•u tr√∫c M·∫°ng", expanded=True):
                    num_hidden_layers = st.number_input("S·ªë l·ªõp ·∫©n", min_value=1, max_value=3, value=len(params["hidden_layer_sizes"]))
                    hidden_sizes = list(params["hidden_layer_sizes"])
                    if num_hidden_layers == 1:
                        hidden_size_1 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 1", min_value=16, max_value=128, value=hidden_sizes[0] if hidden_sizes else 32)
                        hidden_sizes = [hidden_size_1]
                    elif num_hidden_layers == 2:
                        hidden_size_1 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 1", min_value=16, max_value=128, value=hidden_sizes[0] if hidden_sizes else 64)
                        hidden_size_2 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 2", min_value=16, max_value=128, value=hidden_sizes[1] if len(hidden_sizes) > 1 else 32)
                        hidden_sizes = [hidden_size_1, hidden_size_2]
                    elif num_hidden_layers == 3:
                        hidden_size_1 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 1", min_value=16, max_value=128, value=hidden_sizes[0] if hidden_sizes else 128)
                        hidden_size_2 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 2", min_value=16, max_value=128, value=hidden_sizes[1] if len(hidden_sizes) > 1 else 64)
                        hidden_size_3 = st.number_input("S·ªë n∆°-ron l·ªõp ·∫©n 3", min_value=16, max_value=128, value=hidden_sizes[2] if len(hidden_sizes) > 2 else 32)
                        hidden_sizes = [hidden_size_1, hidden_size_2, hidden_size_3]
                    params["hidden_layer_sizes"] = tuple(hidden_sizes)
                    params["activation"] = st.selectbox("H√†m k√≠ch ho·∫°t", ["relu", "sigmoid", "tanh"], index=["relu", "sigmoid", "tanh"].index(params["activation"]))

            with col_param2:
                with st.expander("üîß T·ªëi ∆∞u h√≥a", expanded=True):
                    params["learning_rate"] = st.selectbox("T·ªëc ƒë·ªô h·ªçc", [0.01, 0.005, 0.001, 0.0005, 0.0003, 0.0001], index=[0.01, 0.005, 0.001, 0.0005, 0.0003, 0.0001].index(params["learning_rate"]))
                    params["epochs"] = st.number_input("S·ªë l·∫ßn l·∫∑p (Epochs)", min_value=10, max_value=100, value=params["epochs"])
                    params["batch_size"] = st.number_input("K√≠ch th∆∞·ªõc batch", min_value=32, max_value=256, value=params["batch_size"])
                    params["solver"] = st.selectbox("Tr√¨nh t·ªëi ∆∞u", ["adam", "sgd"], index=["adam", "sgd"].index(params["solver"]))
                    threshold = st.slider("Ng∆∞·ª°ng g√°n nh√£n gi·∫£ (Threshold)", 0.5, 1.0, 0.95, step=0.01)
                    max_iterations = st.number_input("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa", min_value=1, max_value=10, value=5)

            if st.button("üöÄ B·∫Øt ƒë·∫ßu Pseudo Labeling", type="primary"):
                with st.spinner("ƒêang th·ª±c hi·ªán Pseudo Labeling..."):
                    start_time = time.time()

                    # B∆∞·ªõc 1: L·∫•y 1% m·∫´u t·ª´ m·ªói class trong t·∫≠p train
                    labeled_X, labeled_y, unlabeled_X = [], [], []
                    for digit in range(10):
                        digit_indices = np.where(y_train == digit)[0]
                        num_labeled = max(1, int(len(digit_indices) * 0.01))  # 1% ho·∫∑c √≠t nh·∫•t 1 m·∫´u
                        labeled_indices = np.random.choice(digit_indices, num_labeled, replace=False)
                        unlabeled_indices = np.setdiff1d(digit_indices, labeled_indices)
                        labeled_X.append(X_train[labeled_indices])
                        labeled_y.append(y_train[labeled_indices])
                        unlabeled_X.append(X_train[unlabeled_indices])
                    labeled_X = np.concatenate(labeled_X, axis=0)
                    labeled_y = np.concatenate(labeled_y, axis=0)
                    unlabeled_X = np.concatenate(unlabeled_X, axis=0)
                    st.write(f"T·∫≠p labeled ban ƒë·∫ßu: {len(labeled_X)} m·∫´u")
                    st.write(f"T·∫≠p unlabeled: {len(unlabeled_X)} m·∫´u")

                    # Kh·ªüi t·∫°o m√¥ h√¨nh
                    def create_model():
                        model = models.Sequential()
                        model.add(layers.Input(shape=(784,)))
                        for neurons in params["hidden_layer_sizes"]:
                            model.add(layers.Dense(neurons, activation=params["activation"]))
                        model.add(layers.Dense(10, activation="softmax"))
                        optimizer = tf.keras.optimizers.Adam(learning_rate=params["learning_rate"]) if params["solver"] == "adam" else tf.keras.optimizers.SGD(learning_rate=params["learning_rate"])
                        model.compile(optimizer=optimizer, loss="sparse_categorical_crossentropy", metrics=["accuracy"])
                        return model

                    model = create_model()
                    pseudo_labeled_X, pseudo_labeled_y = labeled_X.copy(), labeled_y.copy()
                    iteration = 0
                    total_unlabeled = len(unlabeled_X)

                    # V√≤ng l·∫∑p Pseudo Labeling
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    while iteration < max_iterations and len(unlabeled_X) > 0:
                        iteration += 1
                        st.write(f"**V√≤ng l·∫∑p {iteration}/{max_iterations}**")

                        # B∆∞·ªõc 2: Hu·∫•n luy·ªán tr√™n t·∫≠p labeled hi·ªán t·∫°i
                        history = model.fit(pseudo_labeled_X, pseudo_labeled_y, epochs=params["epochs"],
                                            batch_size=params["batch_size"], verbose=0)
                        status_text.text(f"V√≤ng {iteration}: Loss: {history.history['loss'][-1]:.4f}, Accuracy: {history.history['accuracy'][-1]:.4f}")

                        # B∆∞·ªõc 3: D·ª± ƒëo√°n nh√£n cho t·∫≠p unlabeled
                        pseudo_predictions = model.predict(unlabeled_X, verbose=0)
                        pseudo_confidences = np.max(pseudo_predictions, axis=1)
                        pseudo_labels = np.argmax(pseudo_predictions, axis=1)

                        # B∆∞·ªõc 4: G√°n nh√£n gi·∫£ v·ªõi ng∆∞·ª°ng
                        confident_mask = pseudo_confidences >= threshold
                        new_labeled_X = unlabeled_X[confident_mask]
                        new_labeled_y = pseudo_labels[confident_mask]
                        if len(new_labeled_X) > 0:
                            pseudo_labeled_X = np.concatenate([pseudo_labeled_X, new_labeled_X], axis=0)
                            pseudo_labeled_y = np.concatenate([pseudo_labeled_y, new_labeled_y], axis=0)
                            unlabeled_X = unlabeled_X[~confident_mask]
                            st.write(f"ƒê√£ g√°n nh√£n gi·∫£ cho {len(new_labeled_X)} m·∫´u, c√≤n l·∫°i {len(unlabeled_X)} m·∫´u ch∆∞a g√°n.")
                        else:
                            st.write("Kh√¥ng c√≥ m·∫´u n√†o ƒë·∫°t ng∆∞·ª°ng trong v√≤ng n√†y.")
                            break

                        progress_bar.progress(int((total_unlabeled - len(unlabeled_X)) / total_unlabeled * 100))

                    # ƒê√°nh gi√° tr√™n t·∫≠p test
                    y_test_pred = np.argmax(model.predict(X_test, verbose=0), axis=1)
                    acc_test = accuracy_score(y_test, y_test_pred)
                    cm_test = confusion_matrix(y_test, y_test_pred)

                    # Ghi log MLflow
                    run_name = f"PseudoLabeling_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                    with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name=run_name) as run:
                        mlflow.log_params({
                            "hidden_layer_sizes": params["hidden_layer_sizes"],
                            "learning_rate": params["learning_rate"],
                            "epochs": params["epochs"],
                            "batch_size": params["batch_size"],
                            "activation": params["activation"],
                            "solver": params["solver"],
                            "threshold": threshold,
                            "max_iterations": max_iterations
                        })
                        mlflow.log_metric("accuracy_test", acc_test)
                        mlflow.log_metric("training_time", time.time() - start_time)
                        mlflow.log_metric("n_iter_actual", iteration)
                        mlflow.log_metric("pseudo_labeled_samples", len(pseudo_labeled_X))

                        # Ghi log l·ªãch s·ª≠ loss v√† accuracy
                        for epoch, (loss, acc) in enumerate(zip(history.history['loss'], history.history['accuracy']), 1):
                            mlflow.log_metric("loss", loss, step=epoch)
                            mlflow.log_metric("accuracy", acc, step=epoch)

                    st.session_state['results'] = {
                        'model': model,
                        'accuracy_test': acc_test,
                        'cm_test': cm_test,
                        'training_time': time.time() - start_time,
                        'n_iter_actual': iteration,
                        'pseudo_labeled_samples': len(pseudo_labeled_X),
                        'loss_history': history.history['loss'],
                        'accuracy_history': history.history['accuracy'],
                        'run_id': run.info.run_id
                    }
                    st.success(f"ƒê√£ ho√†n th√†nh Pseudo Labeling! Th·ªùi gian: {time.time() - start_time:.2f} gi√¢y")
                    tf.keras.backend.clear_session()
                    del X_train, y_train, X_test, y_test, split_data, history
                    gc.collect()
                    st.rerun()

    # Tab 4: K·∫øt qu·∫£
    with tab_results:
        st.markdown('<div class="section-title">K·∫øt qu·∫£ Pseudo Labeling</div>', unsafe_allow_html=True)
        if 'results' not in st.session_state:
            st.info("Vui l√≤ng th·ª±c hi·ªán Pseudo Labeling tr∆∞·ªõc.")
        else:
            results = st.session_state['results']
            st.subheader("S·ªë li·ªáu")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Th·ªùi gian hu·∫•n luy·ªán", f"{results['training_time']:.2f} gi√¢y")
            with col2:
                st.metric("ƒê·ªô ch√≠nh x√°c Test", f"{results['accuracy_test']*100:.2f}%")
            with col3:
                st.metric("S·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n", f"{results['pseudo_labeled_samples']}")

            st.subheader("Ma tr·∫≠n Nh·∫ßm l·∫´n (Test)")
            fig, ax = plt.subplots(figsize=(6, 5))
            sns.heatmap(results['cm_test'], annot=True, fmt="d", cmap="Blues", ax=ax)
            st.pyplot(fig)
            plt.close(fig)

            st.subheader("Bi·ªÉu ƒë·ªì K·∫øt qu·∫£ Hu·∫•n luy·ªán")
            if results['loss_history']:
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.plot(range(1, len(results['loss_history']) + 1), results['loss_history'], label='Training Loss', color='blue')
                ax.set_xlabel("Epochs")
                ax.set_ylabel("Loss")
                ax.set_title("Training Loss")
                ax.legend()
                ax.grid(True)
                st.pyplot(fig)
                plt.close(fig)

            if results['accuracy_history']:
                fig, ax = plt.subplots(figsize=(8, 4))
                ax.plot(range(1, len(results['accuracy_history']) + 1), results['accuracy_history'], label='Training Accuracy', color='green')
                ax.set_xlabel("Epochs")
                ax.set_ylabel("Accuracy")
                ax.set_title("Training Accuracy")
                ax.legend()
                ax.grid(True)
                st.pyplot(fig)
                plt.close(fig)

    # Tab 5: Th√¥ng tin hu·∫•n luy·ªán
    with tab_log_info:
        st.markdown('<div class="section-title">Theo d√µi K·∫øt qu·∫£</div>', unsafe_allow_html=True)
        try:
            with st.spinner("ƒêang t·∫£i th√¥ng tin hu·∫•n luy·ªán..."):
                client = MlflowClient()
                runs = client.search_runs(experiment_ids=[EXPERIMENT_ID], order_by=["attributes.start_time DESC"])
                if not runs:
                    st.info(f"Ch∆∞a c√≥ l·∫ßn ch·∫°y n√†o trong Experiment ID {EXPERIMENT_ID}.")
                else:
                    run_options = {run.info.run_id: run.data.tags.get('mlflow.runName', f"Run_{run.info.run_id}") for run in runs}
                    selected_run_name = st.selectbox("Ch·ªçn run:", list(run_options.values()))
                    selected_run_id = [k for k, v in run_options.items() if v == selected_run_name][0]
                    selected_run = client.get_run(selected_run_id)

                    st.subheader("ƒê·ªïi t√™n Run")
                    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", value=selected_run_name)
                    if st.button("C·∫≠p nh·∫≠t t√™n"):
                        client.set_tag(selected_run_id, "mlflow.runName", new_run_name.strip())
                        st.success(f"ƒê√£ ƒë·ªïi t√™n th√†nh: {new_run_name.strip()}")
                        st.rerun()

                    st.subheader("X√≥a Run")
                    if st.button("X√≥a l·∫ßn ch·∫°y"):
                        client.delete_run(selected_run_id)
                        st.success(f"ƒê√£ x√≥a: {selected_run_name}")
                        st.rerun()

                    st.subheader("Th√¥ng tin chi ti·∫øt")
                    st.write(f"**T√™n:** {selected_run_name}")
                    st.write(f"**ID:** {selected_run_id}")
                    st.write(f"**Th·ªùi gian b·∫Øt ƒë·∫ßu:** {datetime.fromtimestamp(selected_run.info.start_time / 1000)}")
                    
                    st.markdown("**Tham s·ªë hu·∫•n luy·ªán:**")
                    st.json(selected_run.data.params, expanded=True)
                    
                    st.markdown("**S·ªë li·ªáu hu·∫•n luy·ªán:**")
                    st.json(selected_run.data.metrics, expanded=True)

                    st.subheader("üìà L·ªãch s·ª≠ Hu·∫•n luy·ªán")
                    # Bi·ªÉu ƒë·ªì Loss
                    history_metrics = client.get_metric_history(selected_run_id, "loss")
                    if history_metrics:
                        epochs = range(1, len(history_metrics) + 1)
                        loss_values = [metric.value for metric in history_metrics]
                        fig, ax = plt.subplots(figsize=(10, 5))
                        ax.plot(epochs, loss_values, label='Training Loss', linestyle='-', color='blue', linewidth=2)
                        ax.set_xlabel("Epochs")
                        ax.set_ylabel("Loss")
                        ax.set_title("L·ªãch s·ª≠ M·∫•t m√°t")
                        ax.legend()
                        ax.grid(True)
                        st.pyplot(fig)
                        plt.close(fig)
                    else:
                        if 'results' in st.session_state and selected_run_id == st.session_state['results']['run_id']:
                            results = st.session_state['results']
                            if results['loss_history']:
                                fig, ax = plt.subplots(figsize=(10, 5))
                                ax.plot(range(1, len(results['loss_history']) + 1), results['loss_history'], 
                                        label='Training Loss', linestyle='-', color='blue', linewidth=2)
                                ax.set_xlabel("Epochs")
                                ax.set_ylabel("Loss")
                                ax.set_title("L·ªãch s·ª≠ M·∫•t m√°t")
                                ax.legend()
                                ax.grid(True)
                                st.pyplot(fig)
                                plt.close(fig)
                        else:
                            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu l·ªãch s·ª≠ Loss ƒë·ªÉ hi·ªÉn th·ªã.")

                    # Bi·ªÉu ƒë·ªì Accuracy
                    history_accuracy = client.get_metric_history(selected_run_id, "accuracy")
                    if history_accuracy:
                        epochs = range(1, len(history_accuracy) + 1)
                        accuracy_values = [metric.value for metric in history_accuracy]
                        fig, ax = plt.subplots(figsize=(10, 5))
                        ax.plot(epochs, accuracy_values, label='Training Accuracy', linestyle='-', color='green', linewidth=2)
                        ax.set_xlabel("Epochs")
                        ax.set_ylabel("Accuracy")
                        ax.set_title("L·ªãch s·ª≠ ƒê·ªô ch√≠nh x√°c")
                        ax.legend()
                        ax.grid(True)
                        st.pyplot(fig)
                        plt.close(fig)
                    else:
                        if 'results' in st.session_state and selected_run_id == st.session_state['results']['run_id']:
                            results = st.session_state['results']
                            if results['accuracy_history']:
                                fig, ax = plt.subplots(figsize=(10, 5))
                                ax.plot(range(1, len(results['accuracy_history']) + 1), results['accuracy_history'], 
                                        label='Training Accuracy', linestyle='-', color='green', linewidth=2)
                                ax.set_xlabel("Epochs")
                                ax.set_ylabel("Accuracy")
                                ax.set_title("L·ªãch s·ª≠ ƒê·ªô ch√≠nh x√°c")
                                ax.legend()
                                ax.grid(True)
                                st.pyplot(fig)
                                plt.close(fig)
                        else:
                            st.info("Kh√¥ng c√≥ d·ªØ li·ªáu l·ªãch s·ª≠ Accuracy ƒë·ªÉ hi·ªÉn th·ªã.")

                    mlflow_ui_link = f"{mlflow_tracking_uri}/#/experiments/{EXPERIMENT_ID}"
                    st.markdown("---")
                    st.markdown(f"üìä **Xem chi ti·∫øt tr√™n MLflow UI**: [Nh·∫•n v√†o ƒë√¢y]({mlflow_ui_link})", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"L·ªói khi t·∫£i th√¥ng tin hu·∫•n luy·ªán: {e}")

if __name__ == "__main__":
    run_mnist_pseudo_labeling_app()